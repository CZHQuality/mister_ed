{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 3/27/18 \n",
    "With a functional mister_ed package, it's time to run the madry challenge.\n",
    "\n",
    "Step 1 is to build a defended network that can transfer to their tensorflow nets.\n",
    "Because Madry uses tensorflow, transferability is a must. \n",
    "\n",
    "From Madry:\n",
    "The model is a residual convolutional neural network consisting of five residual units and a fully connected layer. \n",
    "This architecture is derived from the \"w32-10 wide\" variant of the Tensorflow model repository. \n",
    "The network was trained against an iterative adversary that is allowed to perturb each pixel by at most epsilon=8.0.\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os\n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import config\n",
    "import prebuilt_loss_functions as plf\n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_attacks as aa\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step -1: load the classifier, data_loader, and the normalizer \n",
    "use_gpu = True\n",
    "classifier_net = cifar_loader.load_pretrained_cifar_resnet(flavor=32,\n",
    "                                                           use_gpu=use_gpu)\n",
    "classifier_net.eval()\n",
    "\n",
    "val_loader = cifar_loader.load_cifar_data('val', normalize=False, \n",
    "                                          use_gpu=use_gpu)\n",
    "\n",
    "cifar_normer = utils.DifferentiableNormalize(mean=config.CIFAR10_MEANS,\n",
    "                                             std=config.CIFAR10_STDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: initialize hyperparams for attack and training \n",
    "PGD_L_INF = 8.0 / 255.0\n",
    "PGD_STEP_SIZE = 1.0 / 255.0\n",
    "PGD_NUM_ITER = 16\n",
    "PGD_TRAINING_PROP = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: setup loss object \n",
    "standard_xentropy = plf.VanillaXentropy(classifier_net, normalizer=cifar_normer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: build attack object and its parameters\n",
    "pgd_attack_object = aa.LInfPGD(classifier_net, cifar_normer, standard_xentropy)\n",
    "pgd_attack_params = advtrain.AdversarialAttackParameters(\n",
    "                            pgd_attack_object, \n",
    "                            PGD_TRAINING_PROP,\n",
    "                            {'attack_kwargs': \n",
    "                                {'l_inf_bound': PGD_L_INF,\n",
    "                                 'step_size': PGD_STEP_SIZE,\n",
    "                                 'num_iterations': PGD_NUM_ITER,\n",
    "                                 'random_init': True,\n",
    "                                 'signed': True,\n",
    "                                 'verbose': False}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step 3: build training object, training loss, data loader\n",
    "\n",
    "pgd_cifar_training = advtrain.AdversarialTraining(classifier_net, \n",
    "                                                  cifar_normer, \n",
    "                                                  'full_pgd_cifar_madry_params',\n",
    "                                                  'cifar_resnet32')\n",
    "train_loss = nn.CrossEntropyLoss()\n",
    "train_loader = cifar_loader.load_cifar_data('train', normalize=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pgd_cifar_training.train(train_loader, 256, train_loss, \\n                         attack_parameters=pgd_attack_params,\\n                         use_gpu=True, verbosity='high')\\n                         \\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Do the training \n",
    "'''pgd_cifar_training.train(train_loader, 256, train_loss, \n",
    "                         attack_parameters=pgd_attack_params,\n",
    "                         use_gpu=True, verbosity='high')\n",
    "                         \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_pgd_cifar_madry_params.cifar_resnet32.000100.path.tar\n",
      "/home/mjordan/git_repos/mister_ed/pretrained_models/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"3/28/18 \n",
    "Load and verify the adversarially trained model \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import checkpoints\n",
    "base_model = cifar_resnets.resnet32()\n",
    "experiment_name = 'full_pgd_cifar_madry_params'\n",
    "architecture_name = 'cifar_resnet32'\n",
    "epoch = 100\n",
    "print checkpoints.params_to_filename(experiment_name, architecture_name, epoch)\n",
    "print checkpoints.CHECKPOINT_DIR\n",
    "adv_trained_net = checkpoints.load_state_dict(experiment_name, architecture_name, epoch, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "reload(adveval)\n",
    "# Now run the evaluation script on the eval set \n",
    "\n",
    "#0) initialize the classifier/normalizer/data loader \n",
    "cifar_normer = utils.DifferentiableNormalize(mean=config.CIFAR10_MEANS, std=config.CIFAR10_STDS)\n",
    "val_loader = cifar_loader.load_cifar_data('val', normalize=False)\n",
    "\n",
    "#1) Build some attack objects \n",
    "L_INF_BOUND = 8.0 / 255.0\n",
    "# --- FGSM attack\n",
    "fgsm_xentropy_loss = plf.VanillaXentropy(adv_trained_net,\n",
    "                                         normalizer=cifar_normer)\n",
    "fgsm_attack_obj = aa.FGSM(adv_trained_net, cifar_normer,\n",
    "                          fgsm_xentropy_loss)\n",
    "fgsm_spec_params = {'attack_kwargs': {'l_inf_bound': L_INF_BOUND, 'verbose': False}}\n",
    "fgsm_attack_params = advtrain.AdversarialAttackParameters(\n",
    "                            fgsm_attack_obj, 0.5, fgsm_spec_params)\n",
    "\n",
    "# --- PGD attack \n",
    "pgd_xentropy_loss = plf.VanillaXentropy(adv_trained_net, normalizer=cifar_normer)\n",
    "pgd_attack_obj = aa.LInfPGD(adv_trained_net, cifar_normer, pgd_xentropy_loss)\n",
    "pgd_spec_params = {'attack_kwargs': {'l_inf_bound': L_INF_BOUND,\n",
    "                                     'step_size': 1.0/255.0,\n",
    "                                     'num_iterations': 16,\n",
    "                                     'random_init': True,\n",
    "                                     'signed': True,\n",
    "                                     'verbose': False}}\n",
    "pgd_attack_params = advtrain.AdversarialAttackParameters(\n",
    "                        pgd_attack_obj, 0.5, pgd_spec_params)\n",
    "\n",
    "# 2) Run the evaluation and print outpus \n",
    "eval_obj = adveval.AdversarialEvaluation(adv_trained_net, cifar_normer)\n",
    "#eval_obj.evaluate_ensemble(val_loader, {'fgsm': fgsm_attack_params, 'pgd': pgd_attack_params}, \n",
    "#                  use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Minibatch 00000/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00001/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00002/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00003/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00004/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00005/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00006/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00007/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00008/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00009/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00010/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00011/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00012/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00013/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00014/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00015/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00016/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00017/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00018/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00019/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00020/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00021/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00022/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00023/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00024/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00025/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00026/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00027/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00028/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00029/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00030/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00031/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00032/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00033/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00034/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00035/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00036/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00037/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00038/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00039/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00040/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00041/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00042/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00043/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00044/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00045/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00046/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00047/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00048/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00049/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00050/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00051/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00052/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00053/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00054/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00055/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00056/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00057/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00058/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00059/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00060/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00061/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00062/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00063/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00064/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00065/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00066/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00067/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00068/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00069/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00070/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00071/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00072/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00073/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00074/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00075/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00076/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00077/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "Minibatch 00078/10000\n",
      "TYPE:\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.cuda.FloatTensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[6.23529434e-01, 6.23529434e-01, 6.31372571e-01, ...,\n",
       "          2.79396772e-09, 2.35294122e-02, 7.84313865e-03],\n",
       "         [6.31372571e-01, 6.07843161e-01, 6.31372571e-01, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 7.84313865e-03],\n",
       "         [6.03921592e-01, 6.15686297e-01, 6.23529434e-01, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 2.35294122e-02],\n",
       "         ...,\n",
       "         [3.13725509e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 0.00000000e+00, 1.96078457e-02],\n",
       "         [3.13725509e-02, 0.00000000e+00, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 1.96078438e-02, 2.74509825e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          2.74509825e-02, 1.56862754e-02, 0.00000000e+00]],\n",
       "\n",
       "        [[4.62745100e-01, 4.90196079e-01, 5.01960814e-01, ...,\n",
       "          0.00000000e+00, 3.13725509e-02, 3.13725509e-02],\n",
       "         [4.78431374e-01, 4.74509805e-01, 5.01960814e-01, ...,\n",
       "          1.56862754e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [4.39215690e-01, 4.74509805e-01, 4.86274511e-01, ...,\n",
       "          2.35294141e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         ...,\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 1.96078438e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          1.17647070e-02, 2.74509825e-02, 0.00000000e+00]],\n",
       "\n",
       "        [[2.00000003e-01, 2.11764708e-01, 1.90501988e-01, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 2.35294122e-02],\n",
       "         [2.00000003e-01, 1.88235298e-01, 2.03921571e-01, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [1.92156866e-01, 1.72549024e-01, 1.76470593e-01, ...,\n",
       "          0.00000000e+00, 3.13725509e-02, 3.13725509e-02],\n",
       "         ...,\n",
       "         [3.13725509e-02, 1.96078457e-02, 1.17647089e-02, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 2.74509806e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          2.74509825e-02, 2.74509825e-02, 1.96078438e-02]]],\n",
       "\n",
       "\n",
       "       [[[8.90196085e-01, 8.90196085e-01, 8.86274517e-01, ...,\n",
       "          9.52941179e-01, 9.64705884e-01, 0.00000000e+00],\n",
       "         [8.94117653e-01, 8.94117653e-01, 8.90196085e-01, ...,\n",
       "          9.49019611e-01, 9.60784316e-01, 0.00000000e+00],\n",
       "         [8.98039222e-01, 8.98039222e-01, 8.94117653e-01, ...,\n",
       "          9.56862748e-01, 9.68627453e-01, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.56862773e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          3.92156979e-03, 0.00000000e+00, 3.13725509e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          0.00000000e+00, 3.13725509e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          0.00000000e+00, 1.96078457e-02, 0.00000000e+00]],\n",
       "\n",
       "        [[8.90196085e-01, 8.90196085e-01, 8.86274517e-01, ...,\n",
       "          9.49202597e-01, 9.64705884e-01, 3.13725509e-02],\n",
       "         [8.94117653e-01, 8.94117653e-01, 8.94117653e-01, ...,\n",
       "          9.49019611e-01, 9.60784316e-01, 3.13725509e-02],\n",
       "         [8.98039222e-01, 8.98039222e-01, 8.94117653e-01, ...,\n",
       "          9.52941179e-01, 9.68627453e-01, 3.13725509e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 7.84313772e-03, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.13725509e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.13725509e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.56862773e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[8.90196085e-01, 8.90196085e-01, 8.88164222e-01, ...,\n",
       "          9.52941179e-01, 9.64705884e-01, 3.13725509e-02],\n",
       "         [9.01328683e-01, 8.94117653e-01, 8.94117653e-01, ...,\n",
       "          9.49019611e-01, 9.60784316e-01, 3.13725509e-02],\n",
       "         [8.98039222e-01, 8.98039222e-01, 8.94117653e-01, ...,\n",
       "          9.52941179e-01, 9.64705884e-01, 3.13725509e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 3.13725509e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.13725509e-02],\n",
       "         [0.00000000e+00, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.92157165e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[8.62745106e-01, 9.01960790e-01, 1.00000000e+00, ...,\n",
       "          6.74509823e-01, 0.00000000e+00, 3.13725509e-02],\n",
       "         [8.98039222e-01, 9.41176474e-01, 9.96078432e-01, ...,\n",
       "          6.98039234e-01, 3.13725509e-02, 0.00000000e+00],\n",
       "         [9.37254906e-01, 9.25490201e-01, 9.76470590e-01, ...,\n",
       "          7.25490212e-01, 1.17647089e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 1.96078438e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 9.31322575e-10, 3.13725509e-02, ...,\n",
       "          0.00000000e+00, 3.13725509e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02]],\n",
       "\n",
       "        [[8.58823538e-01, 8.98039222e-01, 9.68627453e-01, ...,\n",
       "          7.64705896e-01, 0.00000000e+00, 3.13725509e-02],\n",
       "         [8.74509811e-01, 9.37254906e-01, 9.96078432e-01, ...,\n",
       "          7.80392170e-01, 3.92156886e-03, 3.13725509e-02],\n",
       "         [9.33333337e-01, 9.14410889e-01, 9.68627453e-01, ...,\n",
       "          7.84313738e-01, 3.13725509e-02, 3.13725509e-02],\n",
       "         ...,\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          0.00000000e+00, 1.56862754e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02]],\n",
       "\n",
       "        [[8.62745106e-01, 9.01960790e-01, 1.00000000e+00, ...,\n",
       "          8.39215696e-01, 0.00000000e+00, 3.13725509e-02],\n",
       "         [9.31576490e-01, 9.37254906e-01, 9.92156863e-01, ...,\n",
       "          8.43137264e-01, 0.00000000e+00, 3.13725509e-02],\n",
       "         [9.37254906e-01, 8.78431380e-01, 8.78431380e-01, ...,\n",
       "          8.31372559e-01, 0.00000000e+00, 3.13725509e-02],\n",
       "         ...,\n",
       "         [1.56862754e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.13725509e-02, 1.56862754e-02],\n",
       "         [3.13725509e-02, 0.00000000e+00, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [3.13725509e-02, 2.74509806e-02, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 3.13725509e-02, 7.84313865e-03, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.13725509e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 9.01960880e-02, ...,\n",
       "          1.56862736e-02, 1.56862736e-02, 7.84313679e-03],\n",
       "         [3.13725509e-02, 3.13725509e-02, 1.13725498e-01, ...,\n",
       "          1.70197338e-02, 3.87956426e-02, 7.84313679e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 3.13725509e-02, 1.60784319e-01, ...,\n",
       "          7.84313679e-02, 8.23529363e-02, 7.84313679e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 1.60784319e-01, ...,\n",
       "          8.23529363e-02, 7.84313679e-02, 7.84313679e-02],\n",
       "         [3.13725509e-02, 2.74509806e-02, 1.60784319e-01, ...,\n",
       "          8.23529363e-02, 7.84313679e-02, 7.45097995e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [0.00000000e+00, 3.13725509e-02, 9.01960805e-02, ...,\n",
       "          3.92156839e-02, 4.70588207e-02, 2.74509862e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 9.41176564e-02, ...,\n",
       "          5.26175722e-02, 5.09643555e-02, 3.92156839e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.56862773e-02, 1.29411772e-01, ...,\n",
       "          9.62423310e-02, 7.05882311e-02, 6.66666627e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 1.29411772e-01, ...,\n",
       "          7.05882311e-02, 6.66666627e-02, 6.66666627e-02],\n",
       "         [3.13725509e-02, 2.74509806e-02, 1.29411772e-01, ...,\n",
       "          7.05882311e-02, 6.66666627e-02, 6.27450943e-02]],\n",
       "\n",
       "        [[2.74509825e-02, 3.13725509e-02, 3.13725509e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.35294141e-02, 0.00000000e+00, 7.29149580e-02, ...,\n",
       "          1.13760680e-02, 1.20100975e-02, 0.00000000e+00],\n",
       "         [3.13725509e-02, 3.13725509e-02, 8.23529437e-02, ...,\n",
       "          6.66666701e-02, 2.66906135e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [3.13725509e-02, 0.00000000e+00, 8.56857970e-02, ...,\n",
       "          1.80392161e-01, 1.80392161e-01, 1.76470593e-01],\n",
       "         [3.13725509e-02, 0.00000000e+00, 8.23529437e-02, ...,\n",
       "          1.96078435e-01, 1.76470593e-01, 1.72549024e-01],\n",
       "         [3.13725509e-02, 2.74509806e-02, 8.62745121e-02, ...,\n",
       "          1.93014145e-01, 1.77087635e-01, 1.72549024e-01]]],\n",
       "\n",
       "\n",
       "       [[[4.70588244e-02, 9.77998897e-02, 5.88235334e-02, ...,\n",
       "          5.33333361e-01, 4.90196109e-01, 4.43137258e-01],\n",
       "         [5.09803928e-02, 8.38435739e-02, 3.92156877e-02, ...,\n",
       "          3.68627459e-01, 3.49019617e-01, 3.07188451e-01],\n",
       "         [8.23529437e-02, 4.81321923e-02, 4.31372523e-02, ...,\n",
       "          1.60784319e-01, 1.71882227e-01, 1.29411772e-01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.92156886e-03, ...,\n",
       "          3.13725509e-02, 0.00000000e+00, 3.13725509e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 1.17647070e-02],\n",
       "         [3.13725509e-02, 3.13725509e-02, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02]],\n",
       "\n",
       "        [[1.01960793e-01, 1.72549024e-01, 7.45098069e-02, ...,\n",
       "          6.03921592e-01, 5.64705908e-01, 5.09803951e-01],\n",
       "         [9.80392247e-02, 1.56862751e-01, 9.01960805e-02, ...,\n",
       "          4.47885871e-01, 4.35294122e-01, 3.90769362e-01],\n",
       "         [1.45098045e-01, 1.17647067e-01, 7.84313753e-02, ...,\n",
       "          2.31372550e-01, 2.50980407e-01, 2.22384095e-01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 5.80558507e-03, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02],\n",
       "         [0.00000000e+00, 1.17647070e-02, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02]],\n",
       "\n",
       "        [[2.35294104e-02, 3.75451744e-02, 3.92156839e-03, ...,\n",
       "          6.50980413e-01, 6.03921592e-01, 5.72261393e-01],\n",
       "         [3.92156839e-03, 2.35294104e-02, 7.05882385e-02, ...,\n",
       "          4.82352972e-01, 4.58823562e-01, 3.96078438e-01],\n",
       "         [7.84313753e-02, 3.52941230e-02, 7.45098069e-02, ...,\n",
       "          2.23529413e-01, 2.27450982e-01, 2.03921571e-01],\n",
       "         ...,\n",
       "         [0.00000000e+00, 3.13725509e-02, 1.96078438e-02, ...,\n",
       "          3.13725509e-02, 0.00000000e+00, 3.13725509e-02],\n",
       "         [0.00000000e+00, 3.13725509e-02, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 0.00000000e+00, 9.31322575e-10],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.13725509e-02, 3.13725509e-02, 3.13725509e-02]]],\n",
       "\n",
       "\n",
       "       [[[3.52941185e-01, 3.56862754e-01, 2.70588249e-01, ...,\n",
       "          4.98039246e-01, 7.64705896e-01, 3.13725509e-02],\n",
       "         [2.98039228e-01, 2.35294133e-01, 3.09803933e-01, ...,\n",
       "          2.47058839e-01, 4.39215690e-01, 0.00000000e+00],\n",
       "         [3.21568638e-01, 2.11764708e-01, 3.18697453e-01, ...,\n",
       "          2.38297135e-01, 2.15686277e-01, 3.13725509e-02],\n",
       "         ...,\n",
       "         [4.86274540e-01, 4.74509835e-01, 4.54901963e-01, ...,\n",
       "          2.58655667e-01, 1.37254909e-01, 3.13725509e-02],\n",
       "         [4.50980395e-01, 4.74509835e-01, 4.62745100e-01, ...,\n",
       "          2.90196091e-01, 1.37254909e-01, 3.13725509e-02],\n",
       "         [4.43137258e-01, 4.74509835e-01, 4.62745100e-01, ...,\n",
       "          2.90576249e-01, 1.37254909e-01, 3.13725509e-02]],\n",
       "\n",
       "        [[3.72549027e-01, 3.84313732e-01, 2.98039228e-01, ...,\n",
       "          5.52941203e-01, 8.11764717e-01, 3.13725509e-02],\n",
       "         [3.17647070e-01, 2.62745112e-01, 2.74509817e-01, ...,\n",
       "          2.90196091e-01, 4.90196109e-01, 3.13725509e-02],\n",
       "         [3.41176480e-01, 2.47058839e-01, 3.43989730e-01, ...,\n",
       "          2.74509817e-01, 2.73792982e-01, 2.35294122e-02],\n",
       "         ...,\n",
       "         [4.99273121e-01, 4.90196109e-01, 4.58823532e-01, ...,\n",
       "          2.39894629e-01, 1.37254909e-01, 3.13725509e-02],\n",
       "         [4.54901963e-01, 4.62745100e-01, 4.54901963e-01, ...,\n",
       "          2.86274523e-01, 1.37254909e-01, 3.13725509e-02],\n",
       "         [4.47058827e-01, 4.70588267e-01, 4.54901963e-01, ...,\n",
       "          2.82352954e-01, 1.33333340e-01, 3.13725509e-02]],\n",
       "\n",
       "        [[4.11764711e-01, 4.15686280e-01, 3.17647070e-01, ...,\n",
       "          5.72549045e-01, 8.50980401e-01, 3.13725509e-02],\n",
       "         [3.49019617e-01, 2.86274523e-01, 3.56862754e-01, ...,\n",
       "          3.45098048e-01, 4.98039246e-01, 3.13725509e-02],\n",
       "         [3.60784322e-01, 2.58823544e-01, 3.72549027e-01, ...,\n",
       "          2.43137255e-01, 3.00308436e-01, 3.13725509e-02],\n",
       "         ...,\n",
       "         [3.68627459e-01, 3.60784322e-01, 3.72239202e-01, ...,\n",
       "          2.00299352e-01, 1.41176477e-01, 3.13725509e-02],\n",
       "         [3.41176480e-01, 3.56862754e-01, 3.56862754e-01, ...,\n",
       "          2.24240407e-01, 1.37254909e-01, 3.13725509e-02],\n",
       "         [3.37254912e-01, 3.64705890e-01, 3.80392164e-01, ...,\n",
       "          2.48453677e-01, 1.33333340e-01, 3.13725509e-02]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build madry challenge npy \n",
    "# 1) Build data loader and new attack params \n",
    "reload(adveval)\n",
    "deterministic_loader = cifar_loader.load_cifar_data('val', normalize=False, shuffle=False)\n",
    "\n",
    "pgd_xentropy_loss = plf.VanillaXentropy(adv_trained_net, normalizer=cifar_normer)\n",
    "pgd_attack_obj = aa.LInfPGD(adv_trained_net, cifar_normer, pgd_xentropy_loss)\n",
    "pgd_spec_params = {'attack_kwargs': {'l_inf_bound': L_INF_BOUND,\n",
    "                                     'step_size': 1.0/255.0,\n",
    "                                     'num_iterations': 16,\n",
    "                                     'random_init': True,\n",
    "                                     'signed': True,\n",
    "                                     'verbose': False}}\n",
    "pgd_attack_params = advtrain.AdversarialAttackParameters(\n",
    "                        pgd_attack_obj, 1.0, pgd_spec_params)\n",
    "\n",
    "# 2) Run attack\n",
    "\n",
    "eval_obj.full_attack(deterministic_loader, pgd_attack_params, 'pgd_trained', use_gpu=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deterministic_loader.dataset)\n",
    "deterministic_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 32, 32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "foo = np.load(os.path.join(config.OUTPUT_IMAGE_PATH, 'pgd_trained.npy'))\n",
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
