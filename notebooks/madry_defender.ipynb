{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 3/27/18 \n",
    "With a functional mister_ed package, it's time to run the madry challenge.\n",
    "\n",
    "Step 1 is to build a defended network that can transfer to their tensorflow nets.\n",
    "Because Madry uses tensorflow, transferability is a must. \n",
    "\n",
    "From Madry:\n",
    "The model is a residual convolutional neural network consisting of five residual units and a fully connected layer. \n",
    "This architecture is derived from the \"w32-10 wide\" variant of the Tensorflow model repository. \n",
    "The network was trained against an iterative adversary that is allowed to perturb each pixel by at most epsilon=8.0.\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os\n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import config\n",
    "import prebuilt_loss_functions as plf\n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_attacks as aa\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step -1: load the classifier, data_loader, and the normalizer \n",
    "use_gpu = True\n",
    "classifier_net = cifar_loader.load_pretrained_cifar_resnet(flavor=32,\n",
    "                                                           use_gpu=use_gpu)\n",
    "classifier_net.eval()\n",
    "\n",
    "val_loader = cifar_loader.load_cifar_data('val', normalize=False, \n",
    "                                          use_gpu=use_gpu)\n",
    "\n",
    "cifar_normer = utils.DifferentiableNormalize(mean=config.CIFAR10_MEANS,\n",
    "                                             std=config.CIFAR10_STDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: initialize hyperparams for attack and training \n",
    "PGD_L_INF = 8.0 / 255.0\n",
    "PGD_STEP_SIZE = 1.0 / 255.0\n",
    "PGD_NUM_ITER = 16\n",
    "PGD_TRAINING_PROP = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: setup loss object \n",
    "standard_xentropy = plf.VanillaXentropy(classifier_net, normalizer=cifar_normer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: build attack object and its parameters\n",
    "pgd_attack_object = aa.LInfPGD(classifier_net, cifar_normer, standard_xentropy)\n",
    "pgd_attack_params = advtrain.AdversarialAttackParameters(\n",
    "                            pgd_attack_object, \n",
    "                            PGD_TRAINING_PROP,\n",
    "                            {'attack_kwargs': \n",
    "                                {'l_inf_bound': PGD_L_INF,\n",
    "                                 'step_size': PGD_STEP_SIZE,\n",
    "                                 'num_iterations': PGD_NUM_ITER,\n",
    "                                 'random_init': True,\n",
    "                                 'signed': True,\n",
    "                                 'verbose': False}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step 3: build training object, training loss, data loader\n",
    "\n",
    "pgd_cifar_training = advtrain.AdversarialTraining(classifier_net, \n",
    "                                                  cifar_normer, \n",
    "                                                  'full_pgd_cifar_madry_params',\n",
    "                                                  'cifar_resnet32')\n",
    "train_loss = nn.CrossEntropyLoss()\n",
    "train_loader = cifar_loader.load_cifar_data('train', normalize=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pgd_cifar_training.train(train_loader, 256, train_loss, \\n                         attack_parameters=pgd_attack_params,\\n                         use_gpu=True, verbosity='high')\\n                         \\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Do the training \n",
    "'''pgd_cifar_training.train(train_loader, 256, train_loss, \n",
    "                         attack_parameters=pgd_attack_params,\n",
    "                         use_gpu=True, verbosity='high')\n",
    "                         \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_pgd_cifar_madry_params.cifar_resnet32.000100.path.tar\n",
      "/home/mjordan/git_repos/mister_ed/pretrained_models/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"3/28/18 \n",
    "Load and verify the adversarially trained model \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import checkpoints\n",
    "base_model = cifar_resnets.resnet32()\n",
    "experiment_name = 'full_pgd_cifar_madry_params'\n",
    "architecture_name = 'cifar_resnet32'\n",
    "epoch = 100\n",
    "print checkpoints.params_to_filename(experiment_name, architecture_name, epoch)\n",
    "print checkpoints.CHECKPOINT_DIR\n",
    "adv_trained_net = checkpoints.load_state_dict(experiment_name, architecture_name, epoch, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "reload(adveval)\n",
    "# Now run the evaluation script on the eval set \n",
    "\n",
    "#0) initialize the classifier/normalizer/data loader \n",
    "cifar_normer = utils.DifferentiableNormalize(mean=config.CIFAR10_MEANS, std=config.CIFAR10_STDS)\n",
    "val_loader = cifar_loader.load_cifar_data('val', normalize=False)\n",
    "\n",
    "#1) Build some attack objects \n",
    "L_INF_BOUND = 8.0 / 255.0\n",
    "# --- FGSM attack\n",
    "fgsm_xentropy_loss = plf.VanillaXentropy(adv_trained_net,\n",
    "                                         normalizer=cifar_normer)\n",
    "fgsm_attack_obj = aa.FGSM(adv_trained_net, cifar_normer,\n",
    "                          fgsm_xentropy_loss)\n",
    "fgsm_spec_params = {'attack_kwargs': {'l_inf_bound': L_INF_BOUND, 'verbose': False}}\n",
    "fgsm_attack_params = advtrain.AdversarialAttackParameters(\n",
    "                            fgsm_attack_obj, 0.5, fgsm_spec_params)\n",
    "\n",
    "# --- PGD attack \n",
    "pgd_xentropy_loss = plf.VanillaXentropy(adv_trained_net, normalizer=cifar_normer)\n",
    "pgd_attack_obj = aa.LInfPGD(adv_trained_net, cifar_normer, pgd_xentropy_loss)\n",
    "pgd_spec_params = {'attack_kwargs': {'l_inf_bound': L_INF_BOUND,\n",
    "                                     'step_size': 1.0/255.0,\n",
    "                                     'num_iterations': 16,\n",
    "                                     'random_init': True,\n",
    "                                     'signed': True,\n",
    "                                     'verbose': False}}\n",
    "pgd_attack_params = advtrain.AdversarialAttackParameters(\n",
    "                        pgd_attack_obj, 0.5, pgd_spec_params)\n",
    "\n",
    "# 2) Run the evaluation and print outpus \n",
    "eval_obj = adveval.AdversarialEvaluation(adv_trained_net, cifar_normer)\n",
    "#eval_obj.evaluate_ensemble(val_loader, {'fgsm': fgsm_attack_params, 'pgd': pgd_attack_params}, \n",
    "#                  use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Minibatch 00/78\n",
      "Minibatch 01/78\n",
      "Minibatch 02/78\n",
      "Minibatch 03/78\n",
      "Minibatch 04/78\n",
      "Minibatch 05/78\n",
      "Minibatch 06/78\n",
      "Minibatch 07/78\n",
      "Minibatch 08/78\n",
      "Minibatch 09/78\n",
      "Minibatch 10/78\n",
      "Minibatch 11/78\n",
      "Minibatch 12/78\n",
      "Minibatch 13/78\n",
      "Minibatch 14/78\n",
      "Minibatch 15/78\n",
      "Minibatch 16/78\n",
      "Minibatch 17/78\n",
      "Minibatch 18/78\n",
      "Minibatch 19/78\n",
      "Minibatch 20/78\n",
      "Minibatch 21/78\n",
      "Minibatch 22/78\n",
      "Minibatch 23/78\n",
      "Minibatch 24/78\n",
      "Minibatch 25/78\n",
      "Minibatch 26/78\n",
      "Minibatch 27/78\n",
      "Minibatch 28/78\n",
      "Minibatch 29/78\n",
      "Minibatch 30/78\n",
      "Minibatch 31/78\n",
      "Minibatch 32/78\n",
      "Minibatch 33/78\n",
      "Minibatch 34/78\n",
      "Minibatch 35/78\n",
      "Minibatch 36/78\n",
      "Minibatch 37/78\n",
      "Minibatch 38/78\n",
      "Minibatch 39/78\n",
      "Minibatch 40/78\n",
      "Minibatch 41/78\n",
      "Minibatch 42/78\n",
      "Minibatch 43/78\n",
      "Minibatch 44/78\n",
      "Minibatch 45/78\n",
      "Minibatch 46/78\n",
      "Minibatch 47/78\n",
      "Minibatch 48/78\n",
      "Minibatch 49/78\n",
      "Minibatch 50/78\n",
      "Minibatch 51/78\n",
      "Minibatch 52/78\n",
      "Minibatch 53/78\n",
      "Minibatch 54/78\n",
      "Minibatch 55/78\n",
      "Minibatch 56/78\n",
      "Minibatch 57/78\n",
      "Minibatch 58/78\n",
      "Minibatch 59/78\n",
      "Minibatch 60/78\n",
      "Minibatch 61/78\n",
      "Minibatch 62/78\n",
      "Minibatch 63/78\n",
      "Minibatch 64/78\n",
      "Minibatch 65/78\n",
      "Minibatch 66/78\n",
      "Minibatch 67/78\n",
      "Minibatch 68/78\n",
      "Minibatch 69/78\n",
      "Minibatch 70/78\n",
      "Minibatch 71/78\n",
      "Minibatch 72/78\n",
      "Minibatch 73/78\n",
      "Minibatch 74/78\n",
      "Minibatch 75/78\n",
      "Minibatch 76/78\n",
      "Minibatch 77/78\n",
      "Minibatch 78/78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[150.        , 151.        , 157.        , ..., 129.        ,\n",
       "          118.        , 119.388565  ],\n",
       "         [144.        , 143.        , 151.        , ..., 128.        ,\n",
       "          117.        , 111.        ],\n",
       "         [143.        , 143.        , 150.        , ..., 132.57864   ,\n",
       "          122.00001   , 112.        ],\n",
       "         ...,\n",
       "         [ 76.        ,  34.        ,  22.999998  , ...,  30.27347   ,\n",
       "            4.9999995 ,  41.        ],\n",
       "         [ 60.41706   ,  41.        ,  27.000002  , ...,  22.320187  ,\n",
       "           20.999998  ,  28.000002  ],\n",
       "         [ 46.        ,  48.        ,  38.574524  , ...,  15.999999  ,\n",
       "           26.000002  ,  24.444199  ]],\n",
       "\n",
       "        [[120.        , 119.        , 124.        , ..., 102.929     ,\n",
       "           99.        ,  93.        ],\n",
       "         [120.        , 118.        , 122.        , ..., 103.        ,\n",
       "           99.        ,  96.        ],\n",
       "         [118.        , 117.        , 119.        , ..., 106.        ,\n",
       "          100.730286  ,  84.        ],\n",
       "         ...,\n",
       "         [124.54517   , 108.        ,  86.24098   , ..., 102.065315  ,\n",
       "           71.25811   ,  93.        ],\n",
       "         [120.587135  , 110.        ,  87.        , ...,  90.        ,\n",
       "           84.09813   ,  72.        ],\n",
       "         [115.        , 113.        ,  97.        , ...,  85.        ,\n",
       "           92.        ,  75.        ]],\n",
       "\n",
       "        [[ 57.        ,  55.        ,  59.        , ...,  39.        ,\n",
       "           44.        ,  40.        ],\n",
       "         [ 59.        ,  48.        ,  53.        , ...,  26.999998  ,\n",
       "           30.543339  ,  26.000002  ],\n",
       "         [ 55.        ,  41.        ,  44.        , ...,  32.76361   ,\n",
       "           27.786016  ,  25.000002  ],\n",
       "         ...,\n",
       "         [183.46976   , 156.        , 145.        , ..., 154.        ,\n",
       "          116.        , 135.        ],\n",
       "         [165.        , 156.        , 140.        , ..., 138.        ,\n",
       "          134.        , 115.        ],\n",
       "         [168.        , 157.        , 140.        , ..., 132.        ,\n",
       "          137.        , 118.        ]]],\n",
       "\n",
       "\n",
       "       [[[227.        , 223.        , 240.        , ..., 225.        ,\n",
       "          225.        , 232.06984   ],\n",
       "         [233.        , 236.51245   , 227.        , ..., 228.        ,\n",
       "          228.        , 227.        ],\n",
       "         [245.        , 226.96034   , 231.        , ..., 227.        ,\n",
       "          227.        , 226.        ],\n",
       "         ...,\n",
       "         [ 79.        ,  35.        ,  27.000002  , ..., 177.        ,\n",
       "          190.        , 196.        ],\n",
       "         [ 74.        ,  38.        ,  44.        , ..., 169.        ,\n",
       "          193.        , 195.        ],\n",
       "         [ 77.        ,  54.        ,  50.        , ..., 160.        ,\n",
       "          188.        , 194.        ]],\n",
       "\n",
       "        [[227.        , 223.        , 240.        , ..., 225.        ,\n",
       "          225.        , 240.        ],\n",
       "         [230.        , 227.        , 227.        , ..., 228.        ,\n",
       "          228.        , 227.        ],\n",
       "         [245.        , 226.        , 242.        , ..., 227.        ,\n",
       "          227.        , 226.        ],\n",
       "         ...,\n",
       "         [ 91.        ,  43.        ,  31.000002  , ..., 176.        ,\n",
       "          204.3908    , 207.30505   ],\n",
       "         [ 88.        ,  49.        ,  44.        , ..., 181.        ,\n",
       "          208.        , 203.        ],\n",
       "         [ 93.        ,  67.        ,  59.000004  , ..., 175.        ,\n",
       "          200.2665    , 204.0587    ]],\n",
       "\n",
       "        [[227.        , 223.        , 237.        , ..., 225.        ,\n",
       "          225.        , 225.        ],\n",
       "         [230.        , 227.        , 227.        , ..., 228.        ,\n",
       "          228.        , 227.        ],\n",
       "         [245.        , 226.        , 226.        , ..., 227.        ,\n",
       "          227.        , 226.        ],\n",
       "         ...,\n",
       "         [ 81.        ,  29.000002  ,  19.        , ..., 171.        ,\n",
       "          185.        , 193.        ],\n",
       "         [ 74.        ,  28.000002  ,  21.213423  , ..., 175.        ,\n",
       "          191.        , 199.        ],\n",
       "         [ 75.        ,  40.        ,  30.000002  , ..., 170.        ,\n",
       "          185.        , 200.        ]]],\n",
       "\n",
       "\n",
       "       [[[150.        , 166.        , 131.        , ..., 236.        ,\n",
       "          245.        , 246.        ],\n",
       "         [174.        , 180.        , 143.        , ..., 240.        ,\n",
       "          254.        , 254.        ],\n",
       "         [176.        , 184.        , 149.        , ..., 238.        ,\n",
       "          255.        , 253.        ],\n",
       "         ...,\n",
       "         [ 22.999998  ,  38.        ,  34.        , ...,  45.        ,\n",
       "           17.        ,  12.000001  ],\n",
       "         [ 15.        ,  35.        ,  33.        , ...,  27.000002  ,\n",
       "            5.9999995 ,  13.000001  ],\n",
       "         [ 22.225939  ,  38.        ,  40.        , ...,   8.298711  ,\n",
       "           12.000001  ,  15.000001  ]],\n",
       "\n",
       "        [[182.        , 195.        , 158.        , ..., 229.83688   ,\n",
       "          247.        , 249.        ],\n",
       "         [195.35873   , 207.        , 168.        , ..., 240.        ,\n",
       "          252.69626   , 255.        ],\n",
       "         [203.        , 208.        , 171.        , ..., 237.        ,\n",
       "          255.        , 252.        ],\n",
       "         ...,\n",
       "         [ 32.        ,  31.000002  ,  38.        , ...,  48.        ,\n",
       "           21.        ,  15.000001  ],\n",
       "         [ 26.000002  ,  46.        ,  44.        , ...,  28.000002  ,\n",
       "           14.000001  ,  15.000001  ],\n",
       "         [ 33.        ,  41.        ,  53.        , ...,  14.000001  ,\n",
       "           13.000001  ,  16.        ]],\n",
       "\n",
       "        [[214.        , 215.        , 186.        , ..., 242.        ,\n",
       "          251.        , 254.        ],\n",
       "         [222.93379   , 234.        , 193.        , ..., 244.        ,\n",
       "          242.        , 255.        ],\n",
       "         [224.        , 230.        , 191.        , ..., 240.        ,\n",
       "          246.        , 255.        ],\n",
       "         ...,\n",
       "         [ 37.        ,  36.        ,  33.11371   , ...,  38.        ,\n",
       "           11.000001  ,  13.000001  ],\n",
       "         [ 31.000002  ,  35.        ,  42.81895   , ...,  15.999999  ,\n",
       "           11.        ,  11.        ],\n",
       "         [ 39.        ,  47.739136  ,  53.        , ...,   9.689163  ,\n",
       "           11.        ,  15.000001  ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 22.873812  ,  12.514663  ,  11.000001  , ...,   1.9999999 ,\n",
       "            3.9999998 ,   4.9999995 ],\n",
       "         [ 13.        ,  12.        ,  10.        , ...,   1.9999999 ,\n",
       "            1.9999999 ,   3.9999998 ],\n",
       "         [ 21.044619  ,  14.        ,  12.        , ...,   9.489706  ,\n",
       "            3.9999998 ,   4.9999995 ],\n",
       "         ...,\n",
       "         [ 25.000002  ,  26.000002  ,  26.000002  , ...,  19.999998  ,\n",
       "           20.999998  ,  15.        ],\n",
       "         [ 29.480387  ,  26.000002  ,  26.000002  , ...,  18.999998  ,\n",
       "           27.000002  ,  16.999998  ],\n",
       "         [ 22.999998  ,  24.168861  ,  25.000002  , ...,  15.999999  ,\n",
       "           17.999998  ,  16.999998  ]],\n",
       "\n",
       "        [[ 21.        ,  10.961726  ,  10.000001  , ...,  10.826304  ,\n",
       "            2.9999998 ,   3.9999998 ],\n",
       "         [  8.        ,   9.521464  ,  13.000003  , ...,   2.6924262 ,\n",
       "           12.155456  ,   4.416771  ],\n",
       "         [  8.        ,   9.        ,  18.000002  , ...,  15.803065  ,\n",
       "            5.7955885 ,   3.9999998 ],\n",
       "         ...,\n",
       "         [ 16.999998  ,  17.999998  ,  17.999998  , ...,  31.000002  ,\n",
       "           18.016212  ,  12.        ],\n",
       "         [ 22.002203  ,  17.999998  ,  17.999998  , ...,  15.999999  ,\n",
       "           17.162243  ,  14.        ],\n",
       "         [ 15.        ,  15.999999  ,  16.999998  , ...,  15.        ,\n",
       "           15.        ,  12.        ]],\n",
       "\n",
       "        [[ 16.675364  ,  19.        ,   4.692454  , ...,   7.0000014 ,\n",
       "            0.99999994,   1.9999999 ],\n",
       "         [  4.9999995 ,   4.9999995 ,   8.929122  , ...,  14.000001  ,\n",
       "           12.894492  ,   0.99999994],\n",
       "         [  4.9999995 ,   5.9999995 ,   4.9999995 , ...,   6.9451284 ,\n",
       "           14.224939  ,   1.9999999 ],\n",
       "         ...,\n",
       "         [  4.9999995 ,   6.9999995 ,   6.9999995 , ...,  44.        ,\n",
       "           50.        ,  34.        ],\n",
       "         [  5.9999995 ,   6.9999995 ,   6.9999995 , ...,  44.        ,\n",
       "           48.        ,  39.        ],\n",
       "         [  3.9999998 ,   4.9999995 ,   5.9999995 , ...,  42.        ,\n",
       "           45.25654   ,  39.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 33.        ,  23.        ,  31.000002  , ...,  69.        ,\n",
       "          100.        ,  83.        ],\n",
       "         [ 20.        ,  28.000002  ,  15.999999  , ..., 123.        ,\n",
       "          141.        , 112.        ],\n",
       "         [ 20.        ,  23.        ,  26.000002  , ..., 146.        ,\n",
       "          149.        , 108.        ],\n",
       "         ...,\n",
       "         [108.        , 108.53385   , 112.        , ...,  89.        ,\n",
       "           90.        ,  83.        ],\n",
       "         [111.        , 111.        , 115.        , ...,  93.        ,\n",
       "           91.        ,  84.        ],\n",
       "         [103.        , 103.        , 108.        , ...,  85.        ,\n",
       "           87.        ,  84.        ]],\n",
       "\n",
       "        [[ 48.        ,  44.        ,  49.        , ...,  90.        ,\n",
       "          121.        ,  97.        ],\n",
       "         [ 33.        ,  45.        ,  44.        , ..., 142.        ,\n",
       "          160.        , 125.        ],\n",
       "         [ 33.        ,  37.        ,  47.        , ..., 164.        ,\n",
       "          167.        , 121.00001   ],\n",
       "         ...,\n",
       "         [137.        , 124.78026   , 130.29955   , ..., 120.00001   ,\n",
       "          118.        , 113.        ],\n",
       "         [140.        , 139.        , 140.07567   , ..., 124.00001   ,\n",
       "          119.        , 113.        ],\n",
       "         [134.        , 131.        , 136.        , ..., 116.        ,\n",
       "          115.        , 112.        ]],\n",
       "\n",
       "        [[ 20.        ,  11.        ,  26.000002  , ...,  86.        ,\n",
       "          120.        , 100.        ],\n",
       "         [ 14.000001  ,  15.000001  ,   6.9999995 , ..., 130.        ,\n",
       "          169.        , 131.646     ],\n",
       "         [ 19.        ,  14.000001  ,  15.999999  , ..., 174.        ,\n",
       "          184.        , 143.        ],\n",
       "         ...,\n",
       "         [ 77.20539   ,  76.        ,  79.        , ...,  76.        ,\n",
       "           76.        ,  71.        ],\n",
       "         [ 91.        ,  75.        ,  79.        , ...,  79.        ,\n",
       "           76.        ,  71.        ],\n",
       "         [ 86.        ,  68.        ,  73.        , ...,  72.        ,\n",
       "           73.        ,  72.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 65.        ,  90.        ,  91.        , ..., 143.        ,\n",
       "          143.        , 195.        ],\n",
       "         [ 61.000004  ,  76.        ,  60.000004  , ...,  93.        ,\n",
       "           79.        , 112.        ],\n",
       "         [ 61.000004  ,  82.        ,  64.        , ...,  66.        ,\n",
       "           56.        ,  54.        ],\n",
       "         ...,\n",
       "         [115.        , 124.00001   , 121.00001   , ..., 100.        ,\n",
       "           70.        ,  35.        ],\n",
       "         [107.        , 115.        , 121.00001   , ..., 123.        ,\n",
       "           74.        ,  34.        ],\n",
       "         [108.        , 113.        , 121.00001   , ..., 108.        ,\n",
       "           60.000004  ,  35.        ]],\n",
       "\n",
       "        [[ 70.        ,  95.        ,  98.        , ..., 158.        ,\n",
       "          156.42177   , 213.        ],\n",
       "         [ 65.        ,  81.        ,  67.        , ..., 103.        ,\n",
       "           90.        , 125.00001   ],\n",
       "         [ 65.        ,  87.        ,  78.        , ...,  87.        ,\n",
       "           70.        ,  79.18819   ],\n",
       "         ...,\n",
       "         [120.0357    , 140.        , 131.        , ...,  99.        ,\n",
       "           68.        ,  35.        ],\n",
       "         [113.        , 116.        , 118.        , ..., 112.        ,\n",
       "           71.        ,  31.000002  ],\n",
       "         [112.        , 114.        , 120.00001   , ..., 107.        ,\n",
       "           57.000004  ,  32.        ]],\n",
       "\n",
       "        [[ 67.        , 105.        , 106.        , ..., 160.        ,\n",
       "          162.        , 225.7755    ],\n",
       "         [ 62.000004  ,  89.        ,  73.        , ...,  97.        ,\n",
       "           88.        , 127.00001   ],\n",
       "         [ 62.000004  ,  92.        ,  69.94175   , ...,  78.        ,\n",
       "           62.        ,  68.05359   ],\n",
       "         ...,\n",
       "         [ 88.        ,  94.        ,  92.        , ...,  80.        ,\n",
       "           63.        ,  36.        ],\n",
       "         [ 83.        ,  87.        ,  91.        , ...,  93.        ,\n",
       "           64.        ,  33.        ],\n",
       "         [ 82.        ,  86.        ,  93.        , ...,  86.        ,\n",
       "           50.        ,  34.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build madry challenge npy \n",
    "# 1) Build data loader and new attack params \n",
    "reload(adveval)\n",
    "deterministic_loader = cifar_loader.load_cifar_data('val', normalize=False, shuffle=False, no_transform=True)\n",
    "\n",
    "pgd_xentropy_loss = plf.VanillaXentropy(adv_trained_net, normalizer=cifar_normer)\n",
    "pgd_attack_obj = aa.LInfPGD(adv_trained_net, cifar_normer, pgd_xentropy_loss)\n",
    "pgd_spec_params = {'attack_kwargs': {'l_inf_bound': L_INF_BOUND,\n",
    "                                     'step_size': 1.0/255.0,\n",
    "                                     'num_iterations': 16,\n",
    "                                     'random_init': True,\n",
    "                                     'signed': True,\n",
    "                                     'verbose': False}}\n",
    "pgd_attack_params = advtrain.AdversarialAttackParameters(\n",
    "                        pgd_attack_obj, 1.0, pgd_spec_params)\n",
    "\n",
    "# 2) Run attack\n",
    "\n",
    "eval_obj.full_attack(deterministic_loader, pgd_attack_params, 'pgd_trained', use_gpu=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deterministic_loader.dataset)\n",
    "deterministic_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "foo = np.load(os.path.join(config.OUTPUT_IMAGE_PATH, 'pgd_trained.npy'))\n",
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
