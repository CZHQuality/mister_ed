{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training with `mister_ed`\n",
    "This file will contain the basics on how to perform adversarial training under the `mister_ed` framework. It's highly recommended that you have walked through tutorial_1 before going through this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we'll start by importing everything we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTERNAL LIBRARY IMPORTS\n",
    "import numpy as np \n",
    "import scipy \n",
    "\n",
    "import torch # Need torch version >=0.3\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "assert float(torch.__version__[:3]) >= 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISTER ED SPECIFIC IMPORT BLOCK\n",
    "# (here we do things so relative imports work )\n",
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os\n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import config\n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import utils.checkpoints as checkpoints\n",
    "import adversarial_perturbations as ap \n",
    "import adversarial_attacks as aa\n",
    "import spatial_transformers as st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define what we want to do here:\n",
    "\n",
    "Our goal is to run through a few training epochs of a pretrained classifier where we augment the training data with a set of adversarial examples. For simplicity's sake, let's just try and train a few epochs of a 20-layer ResNet trained on CIFAR-10, defended against an FGSM attack of $\\epsilon=8$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's instatiate our pretrained classifier and our training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_trainset = cifar_loader.load_cifar_data('train')\n",
    "model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20, return_normalizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's build the attack parameters: an object that contains all the information to perform an attack on a minibatch. So first let's build an attack object and then furnish it with the necessary kwargs. \n",
    "\n",
    "Like in tutorial 1, to create an attack object, we'll need to create a threat model and a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              {'lp_style': 'inf', \n",
    "                               'lp_bound': 8.0 / 255})\n",
    "attack_loss = plf.VanillaXentropy(model, normalizer)\n",
    "attack_object = aa.FGSM(model, normalizer, delta_threat, attack_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we build the `AttackParameters` object, which just wraps the attack object with the kwargs needed to call the `attack(...)` method on attack. For FGSM attacks, we just want to turn the verbosity off, but for more complicated attacks, this will be more involved. Typically in training, we generate a single adversarial example per training point, but to be speedy here, let's only create 1 example per every 5 training points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_kwargs = {'verbose': False} # kwargs to be called in attack_object.attack(...)\n",
    "attack_params = advtrain.AdversarialAttackParameters(attack_object, proportion_attacked=0.2, \n",
    "                                                     attack_specific_params={'attack_kwargs': attack_kwargs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our attack parameters built, we can build the object that handles training for us: this is instatiated with knowledge of the classifier, normalizer and some identifying features such as the *name* of the experiment and architecture. It's worthwhile to be informative with these so you keep which attacks this model is trained against straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'tutorial_fgsm'\n",
    "architecture = 'resnet20'\n",
    "training_obj = advtrain.AdversarialTraining(model, normalizer, experiment_name, architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you start training though, you'll need to furnish the trainer with some extra arguments:\n",
    "    - the data loader \n",
    "    - the number of epochs to train for \n",
    "    - a loss function (not one of the `mister_ed` custom loss functions though!)\n",
    "    - which optimizer to use (defaults to Adam with decent hyperparams)\n",
    "    - the attack parameters object \n",
    "    - whether or not to use the gpu (defaults to not using GPU)\n",
    "    - the verbosity level (ranging from ['low', 'medium', 'high', 'snoop'] (defaults to 'medium')\n",
    "    - whether or not to save the generated adversarial examples as images (defaults to false)\n",
    "    \n",
    "To be cute, we'll just train for two epochs so you get the picture. Also note that unless the verbosity is set to `low`, a checkpoint will be saved after every epoch. By default, these checkpoints are named like `<experiment_name>.<architecture_name>.<epoch>.path.tar`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] accuracy: (16.000, 96.000)\n",
      "[1,     1] loss: 1.679921\n",
      "[1,     2] accuracy: (16.000, 100.000)\n",
      "[1,     2] loss: 1.499435\n",
      "[1,     3] accuracy: (12.000, 96.000)\n",
      "[1,     3] loss: 1.398791\n",
      "[1,     4] accuracy: (4.000, 100.000)\n",
      "[1,     4] loss: 1.342947\n",
      "[1,     5] accuracy: (8.000, 92.000)\n",
      "[1,     5] loss: 1.218291\n",
      "[1,     6] accuracy: (24.000, 92.000)\n",
      "[1,     6] loss: 0.858278\n",
      "[1,     7] accuracy: (24.000, 100.000)\n",
      "[1,     7] loss: 0.664698\n",
      "[1,     8] accuracy: (40.000, 96.000)\n",
      "[1,     8] loss: 0.475440\n",
      "[1,     9] accuracy: (28.000, 92.000)\n",
      "[1,     9] loss: 0.762293\n",
      "[1,    10] accuracy: (32.000, 96.000)\n",
      "[1,    10] loss: 0.554364\n",
      "[1,    11] accuracy: (12.000, 92.000)\n",
      "[1,    11] loss: 0.699505\n",
      "[1,    12] accuracy: (12.000, 92.000)\n",
      "[1,    12] loss: 0.613425\n",
      "[1,    13] accuracy: (32.000, 92.000)\n",
      "[1,    13] loss: 0.460727\n",
      "[1,    14] accuracy: (20.000, 92.000)\n",
      "[1,    14] loss: 0.523724\n",
      "[1,    15] accuracy: (20.000, 88.000)\n",
      "[1,    15] loss: 0.490963\n",
      "[1,    16] accuracy: (28.000, 92.000)\n",
      "[1,    16] loss: 0.481884\n",
      "[1,    17] accuracy: (12.000, 84.000)\n",
      "[1,    17] loss: 0.612687\n",
      "[1,    18] accuracy: (20.000, 96.000)\n",
      "[1,    18] loss: 0.545408\n",
      "[1,    19] accuracy: (12.000, 88.000)\n",
      "[1,    19] loss: 0.552574\n",
      "[1,    20] accuracy: (8.000, 88.000)\n",
      "[1,    20] loss: 0.665762\n",
      "[1,    21] accuracy: (16.000, 88.000)\n",
      "[1,    21] loss: 0.518575\n",
      "[1,    22] accuracy: (40.000, 88.000)\n",
      "[1,    22] loss: 0.535117\n",
      "[1,    23] accuracy: (40.000, 88.000)\n",
      "[1,    23] loss: 0.537961\n",
      "[1,    24] accuracy: (8.000, 96.000)\n",
      "[1,    24] loss: 0.561981\n",
      "[1,    25] accuracy: (12.000, 100.000)\n",
      "[1,    25] loss: 0.472115\n",
      "[1,    26] accuracy: (16.000, 80.000)\n",
      "[1,    26] loss: 0.638003\n",
      "[1,    27] accuracy: (16.000, 88.000)\n",
      "[1,    27] loss: 0.511101\n",
      "[1,    28] accuracy: (16.000, 92.000)\n",
      "[1,    28] loss: 0.527145\n",
      "[1,    29] accuracy: (16.000, 88.000)\n",
      "[1,    29] loss: 0.408746\n",
      "[1,    30] accuracy: (44.000, 100.000)\n",
      "[1,    30] loss: 0.322421\n",
      "[1,    31] accuracy: (24.000, 80.000)\n",
      "[1,    31] loss: 0.416930\n",
      "[1,    32] accuracy: (20.000, 84.000)\n",
      "[1,    32] loss: 0.619477\n",
      "[1,    33] accuracy: (32.000, 84.000)\n",
      "[1,    33] loss: 0.392423\n",
      "[1,    34] accuracy: (20.000, 92.000)\n",
      "[1,    34] loss: 0.444906\n",
      "[1,    35] accuracy: (8.000, 96.000)\n",
      "[1,    35] loss: 0.437289\n",
      "[1,    36] accuracy: (24.000, 96.000)\n",
      "[1,    36] loss: 0.438634\n",
      "[1,    37] accuracy: (24.000, 96.000)\n",
      "[1,    37] loss: 0.572830\n",
      "[1,    38] accuracy: (32.000, 96.000)\n",
      "[1,    38] loss: 0.450946\n",
      "[1,    39] accuracy: (20.000, 92.000)\n",
      "[1,    39] loss: 0.435488\n",
      "[1,    40] accuracy: (28.000, 88.000)\n",
      "[1,    40] loss: 0.480422\n",
      "[1,    41] accuracy: (16.000, 92.000)\n",
      "[1,    41] loss: 0.487241\n",
      "[1,    42] accuracy: (36.000, 100.000)\n",
      "[1,    42] loss: 0.483685\n",
      "[1,    43] accuracy: (16.000, 88.000)\n",
      "[1,    43] loss: 0.474192\n",
      "[1,    44] accuracy: (20.000, 96.000)\n",
      "[1,    44] loss: 0.489333\n",
      "[1,    45] accuracy: (28.000, 100.000)\n",
      "[1,    45] loss: 0.422929\n",
      "[1,    46] accuracy: (40.000, 92.000)\n",
      "[1,    46] loss: 0.442156\n",
      "[1,    47] accuracy: (28.000, 92.000)\n",
      "[1,    47] loss: 0.386388\n",
      "[1,    48] accuracy: (28.000, 92.000)\n",
      "[1,    48] loss: 0.482744\n",
      "[1,    49] accuracy: (32.000, 96.000)\n",
      "[1,    49] loss: 0.420326\n",
      "[1,    50] accuracy: (36.000, 88.000)\n",
      "[1,    50] loss: 0.381161\n",
      "[1,    51] accuracy: (36.000, 96.000)\n",
      "[1,    51] loss: 0.345355\n",
      "[1,    52] accuracy: (36.000, 96.000)\n",
      "[1,    52] loss: 0.410487\n",
      "[1,    53] accuracy: (16.000, 96.000)\n",
      "[1,    53] loss: 0.382163\n",
      "[1,    54] accuracy: (48.000, 92.000)\n",
      "[1,    54] loss: 0.306239\n",
      "[1,    55] accuracy: (12.000, 88.000)\n",
      "[1,    55] loss: 0.471366\n",
      "[1,    56] accuracy: (32.000, 96.000)\n",
      "[1,    56] loss: 0.421800\n",
      "[1,    57] accuracy: (28.000, 96.000)\n",
      "[1,    57] loss: 0.412343\n",
      "[1,    58] accuracy: (24.000, 88.000)\n",
      "[1,    58] loss: 0.525323\n",
      "[1,    59] accuracy: (28.000, 96.000)\n",
      "[1,    59] loss: 0.444486\n",
      "[1,    60] accuracy: (28.000, 92.000)\n",
      "[1,    60] loss: 0.460354\n",
      "[1,    61] accuracy: (20.000, 96.000)\n",
      "[1,    61] loss: 0.527803\n",
      "[1,    62] accuracy: (36.000, 100.000)\n",
      "[1,    62] loss: 0.321600\n",
      "[1,    63] accuracy: (20.000, 100.000)\n",
      "[1,    63] loss: 0.368087\n",
      "[1,    64] accuracy: (12.000, 100.000)\n",
      "[1,    64] loss: 0.457397\n",
      "[1,    65] accuracy: (12.000, 100.000)\n",
      "[1,    65] loss: 0.387485\n",
      "[1,    66] accuracy: (32.000, 100.000)\n",
      "[1,    66] loss: 0.383041\n",
      "[1,    67] accuracy: (36.000, 96.000)\n",
      "[1,    67] loss: 0.450938\n",
      "[1,    68] accuracy: (20.000, 96.000)\n",
      "[1,    68] loss: 0.437455\n",
      "[1,    69] accuracy: (20.000, 88.000)\n",
      "[1,    69] loss: 0.465178\n",
      "[1,    70] accuracy: (36.000, 96.000)\n",
      "[1,    70] loss: 0.404314\n",
      "[1,    71] accuracy: (28.000, 92.000)\n",
      "[1,    71] loss: 0.321175\n",
      "[1,    72] accuracy: (40.000, 100.000)\n",
      "[1,    72] loss: 0.394681\n",
      "[1,    73] accuracy: (36.000, 92.000)\n",
      "[1,    73] loss: 0.368535\n",
      "[1,    74] accuracy: (28.000, 84.000)\n",
      "[1,    74] loss: 0.456274\n",
      "[1,    75] accuracy: (40.000, 92.000)\n",
      "[1,    75] loss: 0.382358\n",
      "[1,    76] accuracy: (28.000, 96.000)\n",
      "[1,    76] loss: 0.343264\n",
      "[1,    77] accuracy: (32.000, 96.000)\n",
      "[1,    77] loss: 0.353774\n",
      "[1,    78] accuracy: (32.000, 100.000)\n",
      "[1,    78] loss: 0.383284\n",
      "[1,    79] accuracy: (28.000, 96.000)\n",
      "[1,    79] loss: 0.359960\n",
      "[1,    80] accuracy: (36.000, 100.000)\n",
      "[1,    80] loss: 0.414816\n",
      "[1,    81] accuracy: (44.000, 100.000)\n",
      "[1,    81] loss: 0.292143\n",
      "[1,    82] accuracy: (16.000, 100.000)\n",
      "[1,    82] loss: 0.393227\n",
      "[1,    83] accuracy: (28.000, 100.000)\n",
      "[1,    83] loss: 0.440341\n",
      "[1,    84] accuracy: (20.000, 100.000)\n",
      "[1,    84] loss: 0.422921\n",
      "[1,    85] accuracy: (28.000, 92.000)\n",
      "[1,    85] loss: 0.357866\n",
      "[1,    86] accuracy: (32.000, 92.000)\n",
      "[1,    86] loss: 0.398533\n",
      "[1,    87] accuracy: (36.000, 92.000)\n",
      "[1,    87] loss: 0.519657\n",
      "[1,    88] accuracy: (32.000, 96.000)\n",
      "[1,    88] loss: 0.363267\n",
      "[1,    89] accuracy: (36.000, 100.000)\n",
      "[1,    89] loss: 0.340154\n",
      "[1,    90] accuracy: (36.000, 88.000)\n",
      "[1,    90] loss: 0.427990\n",
      "[1,    91] accuracy: (28.000, 88.000)\n",
      "[1,    91] loss: 0.422700\n",
      "[1,    92] accuracy: (32.000, 96.000)\n",
      "[1,    92] loss: 0.450926\n",
      "[1,    93] accuracy: (48.000, 96.000)\n",
      "[1,    93] loss: 0.376098\n",
      "[1,    94] accuracy: (28.000, 96.000)\n",
      "[1,    94] loss: 0.312198\n",
      "[1,    95] accuracy: (48.000, 96.000)\n",
      "[1,    95] loss: 0.375929\n",
      "[1,    96] accuracy: (20.000, 100.000)\n",
      "[1,    96] loss: 0.354824\n",
      "[1,    97] accuracy: (36.000, 96.000)\n",
      "[1,    97] loss: 0.352536\n",
      "[1,    98] accuracy: (32.000, 100.000)\n",
      "[1,    98] loss: 0.403372\n",
      "[1,    99] accuracy: (32.000, 100.000)\n",
      "[1,    99] loss: 0.310419\n",
      "[1,   100] accuracy: (36.000, 100.000)\n",
      "[1,   100] loss: 0.383915\n",
      "[1,   101] accuracy: (32.000, 96.000)\n",
      "[1,   101] loss: 0.381129\n",
      "[1,   102] accuracy: (28.000, 100.000)\n",
      "[1,   102] loss: 0.357742\n",
      "[1,   103] accuracy: (20.000, 92.000)\n",
      "[1,   103] loss: 0.449700\n",
      "[1,   104] accuracy: (28.000, 100.000)\n",
      "[1,   104] loss: 0.382369\n",
      "[1,   105] accuracy: (40.000, 92.000)\n",
      "[1,   105] loss: 0.383652\n",
      "[1,   106] accuracy: (32.000, 92.000)\n",
      "[1,   106] loss: 0.373484\n",
      "[1,   107] accuracy: (36.000, 100.000)\n",
      "[1,   107] loss: 0.350191\n",
      "[1,   108] accuracy: (28.000, 100.000)\n",
      "[1,   108] loss: 0.408096\n",
      "[1,   109] accuracy: (40.000, 88.000)\n",
      "[1,   109] loss: 0.368686\n",
      "[1,   110] accuracy: (36.000, 96.000)\n",
      "[1,   110] loss: 0.369860\n",
      "[1,   111] accuracy: (48.000, 96.000)\n",
      "[1,   111] loss: 0.316092\n",
      "[1,   112] accuracy: (36.000, 96.000)\n",
      "[1,   112] loss: 0.453278\n",
      "[1,   113] accuracy: (44.000, 100.000)\n",
      "[1,   113] loss: 0.352131\n",
      "[1,   114] accuracy: (24.000, 96.000)\n",
      "[1,   114] loss: 0.380964\n",
      "[1,   115] accuracy: (44.000, 100.000)\n",
      "[1,   115] loss: 0.301344\n",
      "[1,   116] accuracy: (32.000, 96.000)\n",
      "[1,   116] loss: 0.475131\n",
      "[1,   117] accuracy: (36.000, 92.000)\n",
      "[1,   117] loss: 0.443880\n",
      "[1,   118] accuracy: (40.000, 96.000)\n",
      "[1,   118] loss: 0.363105\n",
      "[1,   119] accuracy: (48.000, 96.000)\n",
      "[1,   119] loss: 0.359826\n",
      "[1,   120] accuracy: (32.000, 100.000)\n",
      "[1,   120] loss: 0.387795\n",
      "[1,   121] accuracy: (28.000, 96.000)\n",
      "[1,   121] loss: 0.365796\n",
      "[1,   122] accuracy: (36.000, 100.000)\n",
      "[1,   122] loss: 0.380838\n",
      "[1,   123] accuracy: (20.000, 100.000)\n",
      "[1,   123] loss: 0.422596\n",
      "[1,   124] accuracy: (32.000, 100.000)\n",
      "[1,   124] loss: 0.311626\n",
      "[1,   125] accuracy: (32.000, 100.000)\n",
      "[1,   125] loss: 0.344822\n",
      "[1,   126] accuracy: (24.000, 96.000)\n",
      "[1,   126] loss: 0.380744\n",
      "[1,   127] accuracy: (28.000, 100.000)\n",
      "[1,   127] loss: 0.368117\n",
      "[1,   128] accuracy: (32.000, 96.000)\n",
      "[1,   128] loss: 0.428655\n",
      "[1,   129] accuracy: (36.000, 92.000)\n",
      "[1,   129] loss: 0.343852\n",
      "[1,   130] accuracy: (16.000, 92.000)\n",
      "[1,   130] loss: 0.441186\n",
      "[1,   131] accuracy: (28.000, 100.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   131] loss: 0.444291\n",
      "[1,   132] accuracy: (32.000, 100.000)\n",
      "[1,   132] loss: 0.347326\n",
      "[1,   133] accuracy: (32.000, 92.000)\n",
      "[1,   133] loss: 0.371265\n",
      "[1,   134] accuracy: (36.000, 96.000)\n",
      "[1,   134] loss: 0.373421\n",
      "[1,   135] accuracy: (24.000, 92.000)\n",
      "[1,   135] loss: 0.469122\n",
      "[1,   136] accuracy: (48.000, 100.000)\n",
      "[1,   136] loss: 0.317712\n",
      "[1,   137] accuracy: (36.000, 100.000)\n",
      "[1,   137] loss: 0.451235\n",
      "[1,   138] accuracy: (36.000, 96.000)\n",
      "[1,   138] loss: 0.418946\n",
      "[1,   139] accuracy: (36.000, 100.000)\n",
      "[1,   139] loss: 0.325803\n",
      "[1,   140] accuracy: (32.000, 92.000)\n",
      "[1,   140] loss: 0.393917\n",
      "[1,   141] accuracy: (24.000, 100.000)\n",
      "[1,   141] loss: 0.379821\n",
      "[1,   142] accuracy: (40.000, 100.000)\n",
      "[1,   142] loss: 0.369715\n",
      "[1,   143] accuracy: (16.000, 92.000)\n",
      "[1,   143] loss: 0.371918\n",
      "[1,   144] accuracy: (40.000, 96.000)\n",
      "[1,   144] loss: 0.371208\n",
      "[1,   145] accuracy: (36.000, 100.000)\n",
      "[1,   145] loss: 0.355020\n",
      "[1,   146] accuracy: (16.000, 92.000)\n",
      "[1,   146] loss: 0.462763\n",
      "[1,   147] accuracy: (32.000, 100.000)\n",
      "[1,   147] loss: 0.295700\n",
      "[1,   148] accuracy: (40.000, 100.000)\n",
      "[1,   148] loss: 0.336944\n",
      "[1,   149] accuracy: (16.000, 100.000)\n",
      "[1,   149] loss: 0.415409\n",
      "[1,   150] accuracy: (36.000, 96.000)\n",
      "[1,   150] loss: 0.332809\n",
      "[1,   151] accuracy: (28.000, 96.000)\n",
      "[1,   151] loss: 0.419998\n",
      "[1,   152] accuracy: (36.000, 100.000)\n",
      "[1,   152] loss: 0.405121\n",
      "[1,   153] accuracy: (24.000, 92.000)\n",
      "[1,   153] loss: 0.403175\n",
      "[1,   154] accuracy: (36.000, 100.000)\n",
      "[1,   154] loss: 0.434334\n",
      "[1,   155] accuracy: (32.000, 100.000)\n",
      "[1,   155] loss: 0.384401\n",
      "[1,   156] accuracy: (28.000, 96.000)\n",
      "[1,   156] loss: 0.410789\n",
      "[1,   157] accuracy: (16.000, 96.000)\n",
      "[1,   157] loss: 0.379546\n",
      "[1,   158] accuracy: (32.000, 96.000)\n",
      "[1,   158] loss: 0.456635\n",
      "[1,   159] accuracy: (36.000, 100.000)\n",
      "[1,   159] loss: 0.328032\n",
      "[1,   160] accuracy: (44.000, 96.000)\n",
      "[1,   160] loss: 0.341948\n",
      "[1,   161] accuracy: (40.000, 100.000)\n",
      "[1,   161] loss: 0.335095\n",
      "[1,   162] accuracy: (24.000, 96.000)\n",
      "[1,   162] loss: 0.384506\n",
      "[1,   163] accuracy: (32.000, 92.000)\n",
      "[1,   163] loss: 0.348017\n",
      "[1,   164] accuracy: (20.000, 96.000)\n",
      "[1,   164] loss: 0.457291\n",
      "[1,   165] accuracy: (28.000, 96.000)\n",
      "[1,   165] loss: 0.455428\n",
      "[1,   166] accuracy: (28.000, 100.000)\n",
      "[1,   166] loss: 0.373229\n",
      "[1,   167] accuracy: (32.000, 96.000)\n",
      "[1,   167] loss: 0.391446\n",
      "[1,   168] accuracy: (36.000, 88.000)\n",
      "[1,   168] loss: 0.443356\n",
      "[1,   169] accuracy: (32.000, 96.000)\n",
      "[1,   169] loss: 0.416307\n",
      "[1,   170] accuracy: (44.000, 96.000)\n",
      "[1,   170] loss: 0.307927\n",
      "[1,   171] accuracy: (44.000, 100.000)\n",
      "[1,   171] loss: 0.305989\n",
      "[1,   172] accuracy: (32.000, 92.000)\n",
      "[1,   172] loss: 0.438912\n",
      "[1,   173] accuracy: (40.000, 100.000)\n",
      "[1,   173] loss: 0.303191\n",
      "[1,   174] accuracy: (36.000, 100.000)\n",
      "[1,   174] loss: 0.394039\n",
      "[1,   175] accuracy: (32.000, 92.000)\n",
      "[1,   175] loss: 0.497682\n",
      "[1,   176] accuracy: (48.000, 92.000)\n",
      "[1,   176] loss: 0.326895\n",
      "[1,   177] accuracy: (24.000, 100.000)\n",
      "[1,   177] loss: 0.425631\n",
      "[1,   178] accuracy: (40.000, 92.000)\n",
      "[1,   178] loss: 0.360721\n",
      "[1,   179] accuracy: (36.000, 96.000)\n",
      "[1,   179] loss: 0.374005\n",
      "[1,   180] accuracy: (32.000, 96.000)\n",
      "[1,   180] loss: 0.382101\n",
      "[1,   181] accuracy: (36.000, 96.000)\n",
      "[1,   181] loss: 0.368535\n",
      "[1,   182] accuracy: (28.000, 92.000)\n",
      "[1,   182] loss: 0.418309\n",
      "[1,   183] accuracy: (24.000, 100.000)\n",
      "[1,   183] loss: 0.302562\n",
      "[1,   184] accuracy: (28.000, 96.000)\n",
      "[1,   184] loss: 0.409858\n",
      "[1,   185] accuracy: (40.000, 96.000)\n",
      "[1,   185] loss: 0.298959\n",
      "[1,   186] accuracy: (28.000, 92.000)\n",
      "[1,   186] loss: 0.406558\n",
      "[1,   187] accuracy: (40.000, 96.000)\n",
      "[1,   187] loss: 0.366401\n",
      "[1,   188] accuracy: (40.000, 92.000)\n",
      "[1,   188] loss: 0.414413\n",
      "[1,   189] accuracy: (36.000, 96.000)\n",
      "[1,   189] loss: 0.354127\n",
      "[1,   190] accuracy: (52.000, 100.000)\n",
      "[1,   190] loss: 0.342635\n",
      "[1,   191] accuracy: (36.000, 96.000)\n",
      "[1,   191] loss: 0.341956\n",
      "[1,   192] accuracy: (16.000, 88.000)\n",
      "[1,   192] loss: 0.408700\n",
      "[1,   193] accuracy: (28.000, 100.000)\n",
      "[1,   193] loss: 0.443708\n",
      "[1,   194] accuracy: (36.000, 100.000)\n",
      "[1,   194] loss: 0.422831\n",
      "[1,   195] accuracy: (52.000, 96.000)\n",
      "[1,   195] loss: 0.337256\n",
      "[1,   196] accuracy: (32.000, 96.000)\n",
      "[1,   196] loss: 0.326537\n",
      "[1,   197] accuracy: (32.000, 92.000)\n",
      "[1,   197] loss: 0.407438\n",
      "[1,   198] accuracy: (32.000, 96.000)\n",
      "[1,   198] loss: 0.348323\n",
      "[1,   199] accuracy: (32.000, 92.000)\n",
      "[1,   199] loss: 0.355795\n",
      "[1,   200] accuracy: (24.000, 92.000)\n",
      "[1,   200] loss: 0.418695\n",
      "[1,   201] accuracy: (32.000, 88.000)\n",
      "[1,   201] loss: 0.324054\n",
      "[1,   202] accuracy: (52.000, 96.000)\n",
      "[1,   202] loss: 0.294015\n",
      "[1,   203] accuracy: (36.000, 96.000)\n",
      "[1,   203] loss: 0.391039\n",
      "[1,   204] accuracy: (48.000, 100.000)\n",
      "[1,   204] loss: 0.347068\n",
      "[1,   205] accuracy: (44.000, 88.000)\n",
      "[1,   205] loss: 0.347969\n",
      "[1,   206] accuracy: (32.000, 100.000)\n",
      "[1,   206] loss: 0.347970\n",
      "[1,   207] accuracy: (32.000, 88.000)\n",
      "[1,   207] loss: 0.388252\n",
      "[1,   208] accuracy: (56.000, 100.000)\n",
      "[1,   208] loss: 0.394800\n",
      "[1,   209] accuracy: (36.000, 92.000)\n",
      "[1,   209] loss: 0.368092\n",
      "[1,   210] accuracy: (24.000, 92.000)\n",
      "[1,   210] loss: 0.419679\n",
      "[1,   211] accuracy: (28.000, 100.000)\n",
      "[1,   211] loss: 0.458526\n",
      "[1,   212] accuracy: (28.000, 84.000)\n",
      "[1,   212] loss: 0.427727\n",
      "[1,   213] accuracy: (20.000, 96.000)\n",
      "[1,   213] loss: 0.389401\n",
      "[1,   214] accuracy: (16.000, 100.000)\n",
      "[1,   214] loss: 0.344115\n",
      "[1,   215] accuracy: (32.000, 100.000)\n",
      "[1,   215] loss: 0.348372\n",
      "[1,   216] accuracy: (40.000, 92.000)\n",
      "[1,   216] loss: 0.347345\n",
      "[1,   217] accuracy: (36.000, 96.000)\n",
      "[1,   217] loss: 0.365090\n",
      "[1,   218] accuracy: (28.000, 96.000)\n",
      "[1,   218] loss: 0.399582\n",
      "[1,   219] accuracy: (16.000, 100.000)\n",
      "[1,   219] loss: 0.410343\n",
      "[1,   220] accuracy: (40.000, 100.000)\n",
      "[1,   220] loss: 0.316369\n",
      "[1,   221] accuracy: (36.000, 100.000)\n",
      "[1,   221] loss: 0.394861\n",
      "[1,   222] accuracy: (28.000, 100.000)\n",
      "[1,   222] loss: 0.387357\n",
      "[1,   223] accuracy: (24.000, 92.000)\n",
      "[1,   223] loss: 0.441014\n",
      "[1,   224] accuracy: (28.000, 88.000)\n",
      "[1,   224] loss: 0.398629\n",
      "[1,   225] accuracy: (44.000, 100.000)\n",
      "[1,   225] loss: 0.252172\n",
      "[1,   226] accuracy: (36.000, 96.000)\n",
      "[1,   226] loss: 0.377011\n",
      "[1,   227] accuracy: (48.000, 92.000)\n",
      "[1,   227] loss: 0.283465\n",
      "[1,   228] accuracy: (36.000, 92.000)\n",
      "[1,   228] loss: 0.339805\n",
      "[1,   229] accuracy: (32.000, 88.000)\n",
      "[1,   229] loss: 0.397886\n",
      "[1,   230] accuracy: (32.000, 96.000)\n",
      "[1,   230] loss: 0.398309\n",
      "[1,   231] accuracy: (40.000, 96.000)\n",
      "[1,   231] loss: 0.308954\n",
      "[1,   232] accuracy: (40.000, 100.000)\n",
      "[1,   232] loss: 0.407657\n",
      "[1,   233] accuracy: (24.000, 84.000)\n",
      "[1,   233] loss: 0.380920\n",
      "[1,   234] accuracy: (28.000, 96.000)\n",
      "[1,   234] loss: 0.350033\n",
      "[1,   235] accuracy: (28.000, 92.000)\n",
      "[1,   235] loss: 0.505378\n",
      "[1,   236] accuracy: (48.000, 88.000)\n",
      "[1,   236] loss: 0.363718\n",
      "[1,   237] accuracy: (20.000, 100.000)\n",
      "[1,   237] loss: 0.353503\n",
      "[1,   238] accuracy: (44.000, 100.000)\n",
      "[1,   238] loss: 0.351347\n",
      "[1,   239] accuracy: (32.000, 96.000)\n",
      "[1,   239] loss: 0.408208\n",
      "[1,   240] accuracy: (48.000, 96.000)\n",
      "[1,   240] loss: 0.281382\n",
      "[1,   241] accuracy: (52.000, 92.000)\n",
      "[1,   241] loss: 0.280282\n",
      "[1,   242] accuracy: (40.000, 100.000)\n",
      "[1,   242] loss: 0.361556\n",
      "[1,   243] accuracy: (48.000, 84.000)\n",
      "[1,   243] loss: 0.356230\n",
      "[1,   244] accuracy: (36.000, 100.000)\n",
      "[1,   244] loss: 0.272484\n",
      "[1,   245] accuracy: (36.000, 100.000)\n",
      "[1,   245] loss: 0.306979\n",
      "[1,   246] accuracy: (40.000, 100.000)\n",
      "[1,   246] loss: 0.320522\n",
      "[1,   247] accuracy: (32.000, 96.000)\n",
      "[1,   247] loss: 0.366817\n",
      "[1,   248] accuracy: (52.000, 96.000)\n",
      "[1,   248] loss: 0.310647\n",
      "[1,   249] accuracy: (48.000, 96.000)\n",
      "[1,   249] loss: 0.350216\n",
      "[1,   250] accuracy: (28.000, 96.000)\n",
      "[1,   250] loss: 0.366110\n",
      "[1,   251] accuracy: (40.000, 96.000)\n",
      "[1,   251] loss: 0.328200\n",
      "[1,   252] accuracy: (40.000, 100.000)\n",
      "[1,   252] loss: 0.295292\n",
      "[1,   253] accuracy: (32.000, 100.000)\n",
      "[1,   253] loss: 0.388206\n",
      "[1,   254] accuracy: (40.000, 96.000)\n",
      "[1,   254] loss: 0.480409\n",
      "[1,   255] accuracy: (48.000, 96.000)\n",
      "[1,   255] loss: 0.344476\n",
      "[1,   256] accuracy: (28.000, 92.000)\n",
      "[1,   256] loss: 0.392907\n",
      "[1,   257] accuracy: (48.000, 100.000)\n",
      "[1,   257] loss: 0.305471\n",
      "[1,   258] accuracy: (48.000, 96.000)\n",
      "[1,   258] loss: 0.341242\n",
      "[1,   259] accuracy: (44.000, 96.000)\n",
      "[1,   259] loss: 0.339829\n",
      "[1,   260] accuracy: (24.000, 96.000)\n",
      "[1,   260] loss: 0.351750\n",
      "[1,   261] accuracy: (40.000, 100.000)\n",
      "[1,   261] loss: 0.366545\n",
      "[1,   262] accuracy: (28.000, 96.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   262] loss: 0.356305\n",
      "[1,   263] accuracy: (40.000, 96.000)\n",
      "[1,   263] loss: 0.307164\n",
      "[1,   264] accuracy: (36.000, 100.000)\n",
      "[1,   264] loss: 0.339702\n",
      "[1,   265] accuracy: (28.000, 96.000)\n",
      "[1,   265] loss: 0.344802\n",
      "[1,   266] accuracy: (44.000, 100.000)\n",
      "[1,   266] loss: 0.414157\n",
      "[1,   267] accuracy: (52.000, 100.000)\n",
      "[1,   267] loss: 0.313030\n",
      "[1,   268] accuracy: (40.000, 100.000)\n",
      "[1,   268] loss: 0.403872\n",
      "[1,   269] accuracy: (44.000, 96.000)\n",
      "[1,   269] loss: 0.318188\n",
      "[1,   270] accuracy: (40.000, 96.000)\n",
      "[1,   270] loss: 0.336914\n",
      "[1,   271] accuracy: (36.000, 100.000)\n",
      "[1,   271] loss: 0.350278\n",
      "[1,   272] accuracy: (52.000, 96.000)\n",
      "[1,   272] loss: 0.279086\n",
      "[1,   273] accuracy: (32.000, 96.000)\n",
      "[1,   273] loss: 0.437383\n",
      "[1,   274] accuracy: (48.000, 92.000)\n",
      "[1,   274] loss: 0.324367\n",
      "[1,   275] accuracy: (40.000, 100.000)\n",
      "[1,   275] loss: 0.332237\n",
      "[1,   276] accuracy: (40.000, 96.000)\n",
      "[1,   276] loss: 0.386240\n",
      "[1,   277] accuracy: (52.000, 100.000)\n",
      "[1,   277] loss: 0.334620\n",
      "[1,   278] accuracy: (16.000, 92.000)\n",
      "[1,   278] loss: 0.439870\n",
      "[1,   279] accuracy: (36.000, 100.000)\n",
      "[1,   279] loss: 0.311300\n",
      "[1,   280] accuracy: (36.000, 92.000)\n",
      "[1,   280] loss: 0.371736\n",
      "[1,   281] accuracy: (40.000, 100.000)\n",
      "[1,   281] loss: 0.410716\n",
      "[1,   282] accuracy: (48.000, 96.000)\n",
      "[1,   282] loss: 0.459747\n",
      "[1,   283] accuracy: (52.000, 100.000)\n",
      "[1,   283] loss: 0.276465\n",
      "[1,   284] accuracy: (48.000, 100.000)\n",
      "[1,   284] loss: 0.309996\n",
      "[1,   285] accuracy: (44.000, 100.000)\n",
      "[1,   285] loss: 0.242159\n",
      "[1,   286] accuracy: (32.000, 92.000)\n",
      "[1,   286] loss: 0.396460\n",
      "[1,   287] accuracy: (40.000, 100.000)\n",
      "[1,   287] loss: 0.296936\n",
      "[1,   288] accuracy: (24.000, 80.000)\n",
      "[1,   288] loss: 0.375343\n",
      "[1,   289] accuracy: (44.000, 92.000)\n",
      "[1,   289] loss: 0.328131\n",
      "[1,   290] accuracy: (24.000, 84.000)\n",
      "[1,   290] loss: 0.388697\n",
      "[1,   291] accuracy: (24.000, 96.000)\n",
      "[1,   291] loss: 0.388800\n",
      "[1,   292] accuracy: (44.000, 96.000)\n",
      "[1,   292] loss: 0.321558\n",
      "[1,   293] accuracy: (36.000, 96.000)\n",
      "[1,   293] loss: 0.347043\n",
      "[1,   294] accuracy: (40.000, 92.000)\n",
      "[1,   294] loss: 0.343533\n",
      "[1,   295] accuracy: (60.000, 100.000)\n",
      "[1,   295] loss: 0.283978\n",
      "[1,   296] accuracy: (52.000, 96.000)\n",
      "[1,   296] loss: 0.297905\n",
      "[1,   297] accuracy: (32.000, 100.000)\n",
      "[1,   297] loss: 0.374491\n",
      "[1,   298] accuracy: (40.000, 92.000)\n",
      "[1,   298] loss: 0.407076\n",
      "[1,   299] accuracy: (24.000, 92.000)\n",
      "[1,   299] loss: 0.325166\n",
      "[1,   300] accuracy: (40.000, 100.000)\n",
      "[1,   300] loss: 0.347436\n",
      "[1,   301] accuracy: (36.000, 100.000)\n",
      "[1,   301] loss: 0.289789\n",
      "[1,   302] accuracy: (44.000, 88.000)\n",
      "[1,   302] loss: 0.449870\n",
      "[1,   303] accuracy: (32.000, 96.000)\n",
      "[1,   303] loss: 0.373196\n",
      "[1,   304] accuracy: (48.000, 100.000)\n",
      "[1,   304] loss: 0.365072\n",
      "[1,   305] accuracy: (32.000, 100.000)\n",
      "[1,   305] loss: 0.416284\n",
      "[1,   306] accuracy: (24.000, 92.000)\n",
      "[1,   306] loss: 0.369486\n",
      "[1,   307] accuracy: (40.000, 88.000)\n",
      "[1,   307] loss: 0.455316\n",
      "[1,   308] accuracy: (32.000, 96.000)\n",
      "[1,   308] loss: 0.329982\n",
      "[1,   309] accuracy: (40.000, 96.000)\n",
      "[1,   309] loss: 0.304016\n",
      "[1,   310] accuracy: (48.000, 96.000)\n",
      "[1,   310] loss: 0.319695\n",
      "[1,   311] accuracy: (32.000, 96.000)\n",
      "[1,   311] loss: 0.368300\n",
      "[1,   312] accuracy: (24.000, 92.000)\n",
      "[1,   312] loss: 0.339455\n",
      "[1,   313] accuracy: (40.000, 92.000)\n",
      "[1,   313] loss: 0.392209\n",
      "[1,   314] accuracy: (40.000, 100.000)\n",
      "[1,   314] loss: 0.365391\n",
      "[1,   315] accuracy: (44.000, 96.000)\n",
      "[1,   315] loss: 0.367469\n",
      "[1,   316] accuracy: (40.000, 92.000)\n",
      "[1,   316] loss: 0.382046\n",
      "[1,   317] accuracy: (32.000, 96.000)\n",
      "[1,   317] loss: 0.411572\n",
      "[1,   318] accuracy: (32.000, 96.000)\n",
      "[1,   318] loss: 0.369517\n",
      "[1,   319] accuracy: (28.000, 96.000)\n",
      "[1,   319] loss: 0.342718\n",
      "[1,   320] accuracy: (36.000, 88.000)\n",
      "[1,   320] loss: 0.351347\n",
      "[1,   321] accuracy: (60.000, 100.000)\n",
      "[1,   321] loss: 0.419057\n",
      "[1,   322] accuracy: (32.000, 92.000)\n",
      "[1,   322] loss: 0.354875\n",
      "[1,   323] accuracy: (40.000, 92.000)\n",
      "[1,   323] loss: 0.379365\n",
      "[1,   324] accuracy: (40.000, 88.000)\n",
      "[1,   324] loss: 0.428243\n",
      "[1,   325] accuracy: (40.000, 96.000)\n",
      "[1,   325] loss: 0.381714\n",
      "[1,   326] accuracy: (32.000, 92.000)\n",
      "[1,   326] loss: 0.409209\n",
      "[1,   327] accuracy: (36.000, 100.000)\n",
      "[1,   327] loss: 0.298600\n",
      "[1,   328] accuracy: (60.000, 88.000)\n",
      "[1,   328] loss: 0.395136\n",
      "[1,   329] accuracy: (60.000, 96.000)\n",
      "[1,   329] loss: 0.292596\n",
      "[1,   330] accuracy: (36.000, 100.000)\n",
      "[1,   330] loss: 0.381081\n",
      "[1,   331] accuracy: (44.000, 100.000)\n",
      "[1,   331] loss: 0.314330\n",
      "[1,   332] accuracy: (36.000, 96.000)\n",
      "[1,   332] loss: 0.336165\n",
      "[1,   333] accuracy: (40.000, 100.000)\n",
      "[1,   333] loss: 0.369172\n",
      "[1,   334] accuracy: (40.000, 96.000)\n",
      "[1,   334] loss: 0.326624\n",
      "[1,   335] accuracy: (32.000, 96.000)\n",
      "[1,   335] loss: 0.379264\n",
      "[1,   336] accuracy: (48.000, 96.000)\n",
      "[1,   336] loss: 0.334543\n",
      "[1,   337] accuracy: (60.000, 96.000)\n",
      "[1,   337] loss: 0.228179\n",
      "[1,   338] accuracy: (48.000, 96.000)\n",
      "[1,   338] loss: 0.308104\n",
      "[1,   339] accuracy: (52.000, 92.000)\n",
      "[1,   339] loss: 0.343975\n",
      "[1,   340] accuracy: (32.000, 96.000)\n",
      "[1,   340] loss: 0.369744\n",
      "[1,   341] accuracy: (44.000, 92.000)\n",
      "[1,   341] loss: 0.352986\n",
      "[1,   342] accuracy: (24.000, 96.000)\n",
      "[1,   342] loss: 0.414809\n",
      "[1,   343] accuracy: (32.000, 88.000)\n",
      "[1,   343] loss: 0.375379\n",
      "[1,   344] accuracy: (36.000, 100.000)\n",
      "[1,   344] loss: 0.316625\n",
      "[1,   345] accuracy: (60.000, 100.000)\n",
      "[1,   345] loss: 0.326491\n",
      "[1,   346] accuracy: (52.000, 96.000)\n",
      "[1,   346] loss: 0.319076\n",
      "[1,   347] accuracy: (36.000, 100.000)\n",
      "[1,   347] loss: 0.289842\n",
      "[1,   348] accuracy: (24.000, 84.000)\n",
      "[1,   348] loss: 0.522636\n",
      "[1,   349] accuracy: (44.000, 96.000)\n",
      "[1,   349] loss: 0.314492\n",
      "[1,   350] accuracy: (40.000, 100.000)\n",
      "[1,   350] loss: 0.317526\n",
      "[1,   351] accuracy: (48.000, 92.000)\n",
      "[1,   351] loss: 0.347005\n",
      "[1,   352] accuracy: (44.000, 100.000)\n",
      "[1,   352] loss: 0.386155\n",
      "[1,   353] accuracy: (40.000, 100.000)\n",
      "[1,   353] loss: 0.457162\n",
      "[1,   354] accuracy: (40.000, 96.000)\n",
      "[1,   354] loss: 0.488526\n",
      "[1,   355] accuracy: (56.000, 100.000)\n",
      "[1,   355] loss: 0.234246\n",
      "[1,   356] accuracy: (44.000, 92.000)\n",
      "[1,   356] loss: 0.311636\n",
      "[1,   357] accuracy: (60.000, 96.000)\n",
      "[1,   357] loss: 0.345164\n",
      "[1,   358] accuracy: (56.000, 100.000)\n",
      "[1,   358] loss: 0.265253\n",
      "[1,   359] accuracy: (40.000, 96.000)\n",
      "[1,   359] loss: 0.276068\n",
      "[1,   360] accuracy: (40.000, 100.000)\n",
      "[1,   360] loss: 0.315130\n",
      "[1,   361] accuracy: (36.000, 92.000)\n",
      "[1,   361] loss: 0.428795\n",
      "[1,   362] accuracy: (28.000, 96.000)\n",
      "[1,   362] loss: 0.402273\n",
      "[1,   363] accuracy: (48.000, 96.000)\n",
      "[1,   363] loss: 0.286093\n",
      "[1,   364] accuracy: (32.000, 88.000)\n",
      "[1,   364] loss: 0.365722\n",
      "[1,   365] accuracy: (36.000, 96.000)\n",
      "[1,   365] loss: 0.436005\n",
      "[1,   366] accuracy: (36.000, 96.000)\n",
      "[1,   366] loss: 0.397610\n",
      "[1,   367] accuracy: (20.000, 88.000)\n",
      "[1,   367] loss: 0.371783\n",
      "[1,   368] accuracy: (32.000, 88.000)\n",
      "[1,   368] loss: 0.456965\n",
      "[1,   369] accuracy: (32.000, 92.000)\n",
      "[1,   369] loss: 0.375898\n",
      "[1,   370] accuracy: (48.000, 92.000)\n",
      "[1,   370] loss: 0.379195\n",
      "[1,   371] accuracy: (40.000, 96.000)\n",
      "[1,   371] loss: 0.382437\n",
      "[1,   372] accuracy: (52.000, 92.000)\n",
      "[1,   372] loss: 0.317058\n",
      "[1,   373] accuracy: (32.000, 96.000)\n",
      "[1,   373] loss: 0.391429\n",
      "[1,   374] accuracy: (44.000, 92.000)\n",
      "[1,   374] loss: 0.404501\n",
      "[1,   375] accuracy: (28.000, 100.000)\n",
      "[1,   375] loss: 0.441500\n",
      "[1,   376] accuracy: (44.000, 96.000)\n",
      "[1,   376] loss: 0.421768\n",
      "[1,   377] accuracy: (36.000, 96.000)\n",
      "[1,   377] loss: 0.390348\n",
      "[1,   378] accuracy: (48.000, 100.000)\n",
      "[1,   378] loss: 0.383047\n",
      "[1,   379] accuracy: (48.000, 96.000)\n",
      "[1,   379] loss: 0.363757\n",
      "[1,   380] accuracy: (48.000, 100.000)\n",
      "[1,   380] loss: 0.310797\n",
      "[1,   381] accuracy: (64.000, 92.000)\n",
      "[1,   381] loss: 0.275414\n",
      "[1,   382] accuracy: (36.000, 100.000)\n",
      "[1,   382] loss: 0.404534\n",
      "[1,   383] accuracy: (40.000, 96.000)\n",
      "[1,   383] loss: 0.368380\n",
      "[1,   384] accuracy: (40.000, 96.000)\n",
      "[1,   384] loss: 0.387746\n",
      "[1,   385] accuracy: (40.000, 92.000)\n",
      "[1,   385] loss: 0.372774\n",
      "[1,   386] accuracy: (36.000, 100.000)\n",
      "[1,   386] loss: 0.293439\n",
      "[1,   387] accuracy: (32.000, 92.000)\n",
      "[1,   387] loss: 0.402814\n",
      "[1,   388] accuracy: (40.000, 96.000)\n",
      "[1,   388] loss: 0.372285\n",
      "[1,   389] accuracy: (36.000, 100.000)\n",
      "[1,   389] loss: 0.401347\n",
      "[1,   390] accuracy: (40.000, 96.000)\n",
      "[1,   390] loss: 0.332910\n",
      "[1,   391] accuracy: (37.500, 100.000)\n",
      "[1,   391] loss: 0.448711\n",
      "COMPLETED EPOCH 0001... checkpointing here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] accuracy: (44.000, 100.000)\n",
      "[2,     1] loss: 0.358566\n",
      "[2,     2] accuracy: (52.000, 96.000)\n",
      "[2,     2] loss: 0.317998\n",
      "[2,     3] accuracy: (52.000, 100.000)\n",
      "[2,     3] loss: 0.343272\n",
      "[2,     4] accuracy: (52.000, 88.000)\n",
      "[2,     4] loss: 0.362794\n",
      "[2,     5] accuracy: (32.000, 92.000)\n",
      "[2,     5] loss: 0.320419\n",
      "[2,     6] accuracy: (36.000, 88.000)\n",
      "[2,     6] loss: 0.320074\n",
      "[2,     7] accuracy: (44.000, 92.000)\n",
      "[2,     7] loss: 0.287974\n",
      "[2,     8] accuracy: (52.000, 100.000)\n",
      "[2,     8] loss: 0.283936\n",
      "[2,     9] accuracy: (44.000, 92.000)\n",
      "[2,     9] loss: 0.285370\n",
      "[2,    10] accuracy: (32.000, 100.000)\n",
      "[2,    10] loss: 0.328862\n",
      "[2,    11] accuracy: (24.000, 100.000)\n",
      "[2,    11] loss: 0.312143\n",
      "[2,    12] accuracy: (36.000, 96.000)\n",
      "[2,    12] loss: 0.436794\n",
      "[2,    13] accuracy: (48.000, 92.000)\n",
      "[2,    13] loss: 0.318468\n",
      "[2,    14] accuracy: (24.000, 96.000)\n",
      "[2,    14] loss: 0.406765\n",
      "[2,    15] accuracy: (48.000, 96.000)\n",
      "[2,    15] loss: 0.327211\n",
      "[2,    16] accuracy: (28.000, 96.000)\n",
      "[2,    16] loss: 0.379180\n",
      "[2,    17] accuracy: (32.000, 96.000)\n",
      "[2,    17] loss: 0.360674\n",
      "[2,    18] accuracy: (44.000, 84.000)\n",
      "[2,    18] loss: 0.343220\n",
      "[2,    19] accuracy: (32.000, 96.000)\n",
      "[2,    19] loss: 0.332976\n",
      "[2,    20] accuracy: (28.000, 92.000)\n",
      "[2,    20] loss: 0.447955\n",
      "[2,    21] accuracy: (32.000, 88.000)\n",
      "[2,    21] loss: 0.350581\n",
      "[2,    22] accuracy: (32.000, 92.000)\n",
      "[2,    22] loss: 0.363648\n",
      "[2,    23] accuracy: (48.000, 92.000)\n",
      "[2,    23] loss: 0.324552\n",
      "[2,    24] accuracy: (36.000, 96.000)\n",
      "[2,    24] loss: 0.371303\n",
      "[2,    25] accuracy: (36.000, 96.000)\n",
      "[2,    25] loss: 0.383875\n",
      "[2,    26] accuracy: (40.000, 96.000)\n",
      "[2,    26] loss: 0.338602\n",
      "[2,    27] accuracy: (40.000, 96.000)\n",
      "[2,    27] loss: 0.359738\n",
      "[2,    28] accuracy: (40.000, 88.000)\n",
      "[2,    28] loss: 0.381136\n",
      "[2,    29] accuracy: (24.000, 96.000)\n",
      "[2,    29] loss: 0.404890\n",
      "[2,    30] accuracy: (32.000, 92.000)\n",
      "[2,    30] loss: 0.396718\n",
      "[2,    31] accuracy: (44.000, 96.000)\n",
      "[2,    31] loss: 0.330107\n",
      "[2,    32] accuracy: (40.000, 84.000)\n",
      "[2,    32] loss: 0.338848\n",
      "[2,    33] accuracy: (48.000, 100.000)\n",
      "[2,    33] loss: 0.293349\n",
      "[2,    34] accuracy: (40.000, 100.000)\n",
      "[2,    34] loss: 0.336011\n",
      "[2,    35] accuracy: (28.000, 100.000)\n",
      "[2,    35] loss: 0.351105\n",
      "[2,    36] accuracy: (44.000, 100.000)\n",
      "[2,    36] loss: 0.303100\n",
      "[2,    37] accuracy: (40.000, 100.000)\n",
      "[2,    37] loss: 0.305147\n",
      "[2,    38] accuracy: (52.000, 96.000)\n",
      "[2,    38] loss: 0.289439\n",
      "[2,    39] accuracy: (36.000, 96.000)\n",
      "[2,    39] loss: 0.306360\n",
      "[2,    40] accuracy: (24.000, 96.000)\n",
      "[2,    40] loss: 0.331631\n",
      "[2,    41] accuracy: (28.000, 92.000)\n",
      "[2,    41] loss: 0.454944\n",
      "[2,    42] accuracy: (52.000, 100.000)\n",
      "[2,    42] loss: 0.279292\n",
      "[2,    43] accuracy: (48.000, 100.000)\n",
      "[2,    43] loss: 0.335359\n",
      "[2,    44] accuracy: (48.000, 92.000)\n",
      "[2,    44] loss: 0.300811\n",
      "[2,    45] accuracy: (44.000, 96.000)\n",
      "[2,    45] loss: 0.414786\n",
      "[2,    46] accuracy: (40.000, 96.000)\n",
      "[2,    46] loss: 0.333352\n",
      "[2,    47] accuracy: (40.000, 92.000)\n",
      "[2,    47] loss: 0.296363\n",
      "[2,    48] accuracy: (20.000, 96.000)\n",
      "[2,    48] loss: 0.391446\n",
      "[2,    49] accuracy: (36.000, 100.000)\n",
      "[2,    49] loss: 0.348577\n",
      "[2,    50] accuracy: (48.000, 100.000)\n",
      "[2,    50] loss: 0.326950\n",
      "[2,    51] accuracy: (52.000, 96.000)\n",
      "[2,    51] loss: 0.347667\n",
      "[2,    52] accuracy: (52.000, 96.000)\n",
      "[2,    52] loss: 0.242924\n",
      "[2,    53] accuracy: (44.000, 96.000)\n",
      "[2,    53] loss: 0.384053\n",
      "[2,    54] accuracy: (40.000, 100.000)\n",
      "[2,    54] loss: 0.334383\n",
      "[2,    55] accuracy: (36.000, 100.000)\n",
      "[2,    55] loss: 0.306625\n",
      "[2,    56] accuracy: (52.000, 92.000)\n",
      "[2,    56] loss: 0.243823\n",
      "[2,    57] accuracy: (44.000, 100.000)\n",
      "[2,    57] loss: 0.372809\n",
      "[2,    58] accuracy: (36.000, 100.000)\n",
      "[2,    58] loss: 0.406952\n",
      "[2,    59] accuracy: (56.000, 96.000)\n",
      "[2,    59] loss: 0.318658\n",
      "[2,    60] accuracy: (52.000, 92.000)\n",
      "[2,    60] loss: 0.396183\n",
      "[2,    61] accuracy: (40.000, 100.000)\n",
      "[2,    61] loss: 0.265216\n",
      "[2,    62] accuracy: (40.000, 96.000)\n",
      "[2,    62] loss: 0.261563\n",
      "[2,    63] accuracy: (48.000, 96.000)\n",
      "[2,    63] loss: 0.371188\n",
      "[2,    64] accuracy: (56.000, 92.000)\n",
      "[2,    64] loss: 0.257331\n",
      "[2,    65] accuracy: (56.000, 100.000)\n",
      "[2,    65] loss: 0.350811\n",
      "[2,    66] accuracy: (48.000, 100.000)\n",
      "[2,    66] loss: 0.372282\n",
      "[2,    67] accuracy: (36.000, 100.000)\n",
      "[2,    67] loss: 0.371201\n",
      "[2,    68] accuracy: (44.000, 96.000)\n",
      "[2,    68] loss: 0.301929\n",
      "[2,    69] accuracy: (36.000, 96.000)\n",
      "[2,    69] loss: 0.455312\n",
      "[2,    70] accuracy: (48.000, 100.000)\n",
      "[2,    70] loss: 0.349909\n",
      "[2,    71] accuracy: (44.000, 96.000)\n",
      "[2,    71] loss: 0.340216\n",
      "[2,    72] accuracy: (44.000, 100.000)\n",
      "[2,    72] loss: 0.297502\n",
      "[2,    73] accuracy: (36.000, 100.000)\n",
      "[2,    73] loss: 0.410538\n",
      "[2,    74] accuracy: (44.000, 96.000)\n",
      "[2,    74] loss: 0.365421\n",
      "[2,    75] accuracy: (44.000, 92.000)\n",
      "[2,    75] loss: 0.324108\n",
      "[2,    76] accuracy: (40.000, 96.000)\n",
      "[2,    76] loss: 0.303204\n",
      "[2,    77] accuracy: (52.000, 96.000)\n",
      "[2,    77] loss: 0.357150\n",
      "[2,    78] accuracy: (56.000, 100.000)\n",
      "[2,    78] loss: 0.274142\n",
      "[2,    79] accuracy: (40.000, 96.000)\n",
      "[2,    79] loss: 0.412302\n",
      "[2,    80] accuracy: (52.000, 100.000)\n",
      "[2,    80] loss: 0.348229\n",
      "[2,    81] accuracy: (36.000, 96.000)\n",
      "[2,    81] loss: 0.386914\n",
      "[2,    82] accuracy: (56.000, 96.000)\n",
      "[2,    82] loss: 0.275499\n",
      "[2,    83] accuracy: (60.000, 96.000)\n",
      "[2,    83] loss: 0.273224\n",
      "[2,    84] accuracy: (40.000, 96.000)\n",
      "[2,    84] loss: 0.365419\n",
      "[2,    85] accuracy: (52.000, 96.000)\n",
      "[2,    85] loss: 0.310107\n",
      "[2,    86] accuracy: (28.000, 96.000)\n",
      "[2,    86] loss: 0.392644\n",
      "[2,    87] accuracy: (24.000, 100.000)\n",
      "[2,    87] loss: 0.320231\n",
      "[2,    88] accuracy: (36.000, 96.000)\n",
      "[2,    88] loss: 0.327255\n",
      "[2,    89] accuracy: (36.000, 96.000)\n",
      "[2,    89] loss: 0.379669\n",
      "[2,    90] accuracy: (40.000, 100.000)\n",
      "[2,    90] loss: 0.287078\n",
      "[2,    91] accuracy: (24.000, 92.000)\n",
      "[2,    91] loss: 0.406857\n",
      "[2,    92] accuracy: (56.000, 92.000)\n",
      "[2,    92] loss: 0.329040\n",
      "[2,    93] accuracy: (52.000, 100.000)\n",
      "[2,    93] loss: 0.305059\n",
      "[2,    94] accuracy: (40.000, 100.000)\n",
      "[2,    94] loss: 0.265390\n",
      "[2,    95] accuracy: (32.000, 88.000)\n",
      "[2,    95] loss: 0.350816\n",
      "[2,    96] accuracy: (44.000, 100.000)\n",
      "[2,    96] loss: 0.327380\n",
      "[2,    97] accuracy: (32.000, 84.000)\n",
      "[2,    97] loss: 0.445040\n",
      "[2,    98] accuracy: (40.000, 96.000)\n",
      "[2,    98] loss: 0.372166\n",
      "[2,    99] accuracy: (20.000, 100.000)\n",
      "[2,    99] loss: 0.449270\n",
      "[2,   100] accuracy: (48.000, 100.000)\n",
      "[2,   100] loss: 0.236596\n",
      "[2,   101] accuracy: (32.000, 100.000)\n",
      "[2,   101] loss: 0.384227\n",
      "[2,   102] accuracy: (36.000, 92.000)\n",
      "[2,   102] loss: 0.425006\n",
      "[2,   103] accuracy: (52.000, 92.000)\n",
      "[2,   103] loss: 0.322842\n",
      "[2,   104] accuracy: (36.000, 100.000)\n",
      "[2,   104] loss: 0.339849\n",
      "[2,   105] accuracy: (44.000, 96.000)\n",
      "[2,   105] loss: 0.313127\n",
      "[2,   106] accuracy: (48.000, 96.000)\n",
      "[2,   106] loss: 0.413721\n",
      "[2,   107] accuracy: (52.000, 96.000)\n",
      "[2,   107] loss: 0.323165\n",
      "[2,   108] accuracy: (36.000, 92.000)\n",
      "[2,   108] loss: 0.380423\n",
      "[2,   109] accuracy: (48.000, 100.000)\n",
      "[2,   109] loss: 0.346164\n",
      "[2,   110] accuracy: (32.000, 100.000)\n",
      "[2,   110] loss: 0.267663\n",
      "[2,   111] accuracy: (40.000, 96.000)\n",
      "[2,   111] loss: 0.307807\n",
      "[2,   112] accuracy: (40.000, 100.000)\n",
      "[2,   112] loss: 0.311013\n",
      "[2,   113] accuracy: (40.000, 100.000)\n",
      "[2,   113] loss: 0.379621\n",
      "[2,   114] accuracy: (48.000, 100.000)\n",
      "[2,   114] loss: 0.333367\n",
      "[2,   115] accuracy: (48.000, 92.000)\n",
      "[2,   115] loss: 0.307995\n",
      "[2,   116] accuracy: (52.000, 96.000)\n",
      "[2,   116] loss: 0.312034\n",
      "[2,   117] accuracy: (24.000, 92.000)\n",
      "[2,   117] loss: 0.355186\n",
      "[2,   118] accuracy: (40.000, 100.000)\n",
      "[2,   118] loss: 0.304652\n",
      "[2,   119] accuracy: (32.000, 100.000)\n",
      "[2,   119] loss: 0.346083\n",
      "[2,   120] accuracy: (56.000, 100.000)\n",
      "[2,   120] loss: 0.299273\n",
      "[2,   121] accuracy: (40.000, 92.000)\n",
      "[2,   121] loss: 0.457914\n",
      "[2,   122] accuracy: (28.000, 96.000)\n",
      "[2,   122] loss: 0.478275\n",
      "[2,   123] accuracy: (24.000, 100.000)\n",
      "[2,   123] loss: 0.418603\n",
      "[2,   124] accuracy: (44.000, 100.000)\n",
      "[2,   124] loss: 0.331493\n",
      "[2,   125] accuracy: (44.000, 100.000)\n",
      "[2,   125] loss: 0.298193\n",
      "[2,   126] accuracy: (48.000, 100.000)\n",
      "[2,   126] loss: 0.308450\n",
      "[2,   127] accuracy: (40.000, 96.000)\n",
      "[2,   127] loss: 0.349708\n",
      "[2,   128] accuracy: (48.000, 96.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   128] loss: 0.344942\n",
      "[2,   129] accuracy: (24.000, 96.000)\n",
      "[2,   129] loss: 0.336713\n",
      "[2,   130] accuracy: (40.000, 100.000)\n",
      "[2,   130] loss: 0.372564\n",
      "[2,   131] accuracy: (52.000, 100.000)\n",
      "[2,   131] loss: 0.318337\n",
      "[2,   132] accuracy: (56.000, 100.000)\n",
      "[2,   132] loss: 0.273954\n",
      "[2,   133] accuracy: (56.000, 96.000)\n",
      "[2,   133] loss: 0.357604\n",
      "[2,   134] accuracy: (36.000, 100.000)\n",
      "[2,   134] loss: 0.398126\n",
      "[2,   135] accuracy: (48.000, 88.000)\n",
      "[2,   135] loss: 0.383062\n",
      "[2,   136] accuracy: (44.000, 96.000)\n",
      "[2,   136] loss: 0.285561\n",
      "[2,   137] accuracy: (36.000, 96.000)\n",
      "[2,   137] loss: 0.315573\n",
      "[2,   138] accuracy: (36.000, 96.000)\n",
      "[2,   138] loss: 0.334689\n",
      "[2,   139] accuracy: (56.000, 92.000)\n",
      "[2,   139] loss: 0.376251\n",
      "[2,   140] accuracy: (32.000, 96.000)\n",
      "[2,   140] loss: 0.309359\n",
      "[2,   141] accuracy: (60.000, 92.000)\n",
      "[2,   141] loss: 0.236054\n",
      "[2,   142] accuracy: (56.000, 92.000)\n",
      "[2,   142] loss: 0.284827\n",
      "[2,   143] accuracy: (48.000, 100.000)\n",
      "[2,   143] loss: 0.364904\n",
      "[2,   144] accuracy: (56.000, 96.000)\n",
      "[2,   144] loss: 0.310285\n",
      "[2,   145] accuracy: (36.000, 100.000)\n",
      "[2,   145] loss: 0.378833\n",
      "[2,   146] accuracy: (40.000, 92.000)\n",
      "[2,   146] loss: 0.428458\n",
      "[2,   147] accuracy: (48.000, 92.000)\n",
      "[2,   147] loss: 0.336239\n",
      "[2,   148] accuracy: (40.000, 96.000)\n",
      "[2,   148] loss: 0.330623\n",
      "[2,   149] accuracy: (52.000, 96.000)\n",
      "[2,   149] loss: 0.326336\n",
      "[2,   150] accuracy: (64.000, 100.000)\n",
      "[2,   150] loss: 0.211948\n",
      "[2,   151] accuracy: (44.000, 92.000)\n",
      "[2,   151] loss: 0.339336\n",
      "[2,   152] accuracy: (32.000, 100.000)\n",
      "[2,   152] loss: 0.340186\n",
      "[2,   153] accuracy: (32.000, 88.000)\n",
      "[2,   153] loss: 0.420684\n",
      "[2,   154] accuracy: (52.000, 100.000)\n",
      "[2,   154] loss: 0.298266\n",
      "[2,   155] accuracy: (40.000, 96.000)\n",
      "[2,   155] loss: 0.275055\n",
      "[2,   156] accuracy: (32.000, 100.000)\n",
      "[2,   156] loss: 0.376807\n",
      "[2,   157] accuracy: (68.000, 100.000)\n",
      "[2,   157] loss: 0.227603\n",
      "[2,   158] accuracy: (32.000, 92.000)\n",
      "[2,   158] loss: 0.347506\n",
      "[2,   159] accuracy: (44.000, 84.000)\n",
      "[2,   159] loss: 0.313958\n",
      "[2,   160] accuracy: (44.000, 88.000)\n",
      "[2,   160] loss: 0.344462\n",
      "[2,   161] accuracy: (28.000, 92.000)\n",
      "[2,   161] loss: 0.383855\n",
      "[2,   162] accuracy: (36.000, 100.000)\n",
      "[2,   162] loss: 0.326057\n",
      "[2,   163] accuracy: (44.000, 100.000)\n",
      "[2,   163] loss: 0.340339\n",
      "[2,   164] accuracy: (52.000, 92.000)\n",
      "[2,   164] loss: 0.316392\n",
      "[2,   165] accuracy: (24.000, 96.000)\n",
      "[2,   165] loss: 0.386329\n",
      "[2,   166] accuracy: (56.000, 96.000)\n",
      "[2,   166] loss: 0.310280\n",
      "[2,   167] accuracy: (36.000, 92.000)\n",
      "[2,   167] loss: 0.374339\n",
      "[2,   168] accuracy: (56.000, 96.000)\n",
      "[2,   168] loss: 0.304365\n",
      "[2,   169] accuracy: (40.000, 100.000)\n",
      "[2,   169] loss: 0.330139\n",
      "[2,   170] accuracy: (40.000, 100.000)\n",
      "[2,   170] loss: 0.348609\n",
      "[2,   171] accuracy: (52.000, 96.000)\n",
      "[2,   171] loss: 0.266101\n",
      "[2,   172] accuracy: (40.000, 96.000)\n",
      "[2,   172] loss: 0.323181\n",
      "[2,   173] accuracy: (64.000, 100.000)\n",
      "[2,   173] loss: 0.248913\n",
      "[2,   174] accuracy: (44.000, 100.000)\n",
      "[2,   174] loss: 0.252769\n",
      "[2,   175] accuracy: (56.000, 100.000)\n",
      "[2,   175] loss: 0.347515\n",
      "[2,   176] accuracy: (32.000, 96.000)\n",
      "[2,   176] loss: 0.365383\n",
      "[2,   177] accuracy: (24.000, 100.000)\n",
      "[2,   177] loss: 0.350166\n",
      "[2,   178] accuracy: (36.000, 96.000)\n",
      "[2,   178] loss: 0.350160\n",
      "[2,   179] accuracy: (32.000, 100.000)\n",
      "[2,   179] loss: 0.340791\n",
      "[2,   180] accuracy: (44.000, 96.000)\n",
      "[2,   180] loss: 0.324407\n",
      "[2,   181] accuracy: (44.000, 96.000)\n",
      "[2,   181] loss: 0.325431\n",
      "[2,   182] accuracy: (32.000, 96.000)\n",
      "[2,   182] loss: 0.379426\n",
      "[2,   183] accuracy: (48.000, 100.000)\n",
      "[2,   183] loss: 0.309308\n",
      "[2,   184] accuracy: (44.000, 84.000)\n",
      "[2,   184] loss: 0.402518\n",
      "[2,   185] accuracy: (40.000, 100.000)\n",
      "[2,   185] loss: 0.299110\n",
      "[2,   186] accuracy: (56.000, 100.000)\n",
      "[2,   186] loss: 0.238523\n",
      "[2,   187] accuracy: (28.000, 100.000)\n",
      "[2,   187] loss: 0.318121\n",
      "[2,   188] accuracy: (56.000, 96.000)\n",
      "[2,   188] loss: 0.301281\n",
      "[2,   189] accuracy: (52.000, 100.000)\n",
      "[2,   189] loss: 0.324990\n",
      "[2,   190] accuracy: (52.000, 96.000)\n",
      "[2,   190] loss: 0.251797\n",
      "[2,   191] accuracy: (60.000, 100.000)\n",
      "[2,   191] loss: 0.305441\n",
      "[2,   192] accuracy: (44.000, 88.000)\n",
      "[2,   192] loss: 0.383650\n",
      "[2,   193] accuracy: (56.000, 96.000)\n",
      "[2,   193] loss: 0.268860\n",
      "[2,   194] accuracy: (24.000, 88.000)\n",
      "[2,   194] loss: 0.402507\n",
      "[2,   195] accuracy: (48.000, 100.000)\n",
      "[2,   195] loss: 0.294351\n",
      "[2,   196] accuracy: (32.000, 96.000)\n",
      "[2,   196] loss: 0.303291\n",
      "[2,   197] accuracy: (32.000, 88.000)\n",
      "[2,   197] loss: 0.462244\n",
      "[2,   198] accuracy: (40.000, 96.000)\n",
      "[2,   198] loss: 0.454357\n",
      "[2,   199] accuracy: (48.000, 96.000)\n",
      "[2,   199] loss: 0.279869\n",
      "[2,   200] accuracy: (40.000, 92.000)\n",
      "[2,   200] loss: 0.304318\n",
      "[2,   201] accuracy: (44.000, 100.000)\n",
      "[2,   201] loss: 0.366881\n",
      "[2,   202] accuracy: (32.000, 96.000)\n",
      "[2,   202] loss: 0.339639\n",
      "[2,   203] accuracy: (36.000, 100.000)\n",
      "[2,   203] loss: 0.347716\n",
      "[2,   204] accuracy: (56.000, 96.000)\n",
      "[2,   204] loss: 0.267553\n",
      "[2,   205] accuracy: (60.000, 92.000)\n",
      "[2,   205] loss: 0.276894\n",
      "[2,   206] accuracy: (36.000, 100.000)\n",
      "[2,   206] loss: 0.378653\n",
      "[2,   207] accuracy: (56.000, 96.000)\n",
      "[2,   207] loss: 0.264806\n",
      "[2,   208] accuracy: (56.000, 100.000)\n",
      "[2,   208] loss: 0.233134\n",
      "[2,   209] accuracy: (36.000, 100.000)\n",
      "[2,   209] loss: 0.357184\n",
      "[2,   210] accuracy: (48.000, 92.000)\n",
      "[2,   210] loss: 0.318314\n",
      "[2,   211] accuracy: (40.000, 88.000)\n",
      "[2,   211] loss: 0.344364\n",
      "[2,   212] accuracy: (28.000, 96.000)\n",
      "[2,   212] loss: 0.391967\n",
      "[2,   213] accuracy: (40.000, 96.000)\n",
      "[2,   213] loss: 0.315058\n",
      "[2,   214] accuracy: (32.000, 96.000)\n",
      "[2,   214] loss: 0.401672\n",
      "[2,   215] accuracy: (52.000, 96.000)\n",
      "[2,   215] loss: 0.327372\n",
      "[2,   216] accuracy: (40.000, 96.000)\n",
      "[2,   216] loss: 0.319611\n",
      "[2,   217] accuracy: (24.000, 96.000)\n",
      "[2,   217] loss: 0.405237\n",
      "[2,   218] accuracy: (44.000, 96.000)\n",
      "[2,   218] loss: 0.306551\n",
      "[2,   219] accuracy: (64.000, 100.000)\n",
      "[2,   219] loss: 0.234313\n",
      "[2,   220] accuracy: (56.000, 96.000)\n",
      "[2,   220] loss: 0.389275\n",
      "[2,   221] accuracy: (48.000, 96.000)\n",
      "[2,   221] loss: 0.324178\n",
      "[2,   222] accuracy: (52.000, 96.000)\n",
      "[2,   222] loss: 0.332581\n",
      "[2,   223] accuracy: (20.000, 96.000)\n",
      "[2,   223] loss: 0.314066\n",
      "[2,   224] accuracy: (52.000, 92.000)\n",
      "[2,   224] loss: 0.287830\n",
      "[2,   225] accuracy: (56.000, 96.000)\n",
      "[2,   225] loss: 0.284397\n",
      "[2,   226] accuracy: (40.000, 92.000)\n",
      "[2,   226] loss: 0.296743\n",
      "[2,   227] accuracy: (44.000, 100.000)\n",
      "[2,   227] loss: 0.290165\n",
      "[2,   228] accuracy: (64.000, 96.000)\n",
      "[2,   228] loss: 0.322992\n",
      "[2,   229] accuracy: (44.000, 96.000)\n",
      "[2,   229] loss: 0.300673\n",
      "[2,   230] accuracy: (44.000, 92.000)\n",
      "[2,   230] loss: 0.364581\n",
      "[2,   231] accuracy: (40.000, 100.000)\n",
      "[2,   231] loss: 0.365351\n",
      "[2,   232] accuracy: (28.000, 96.000)\n",
      "[2,   232] loss: 0.350459\n",
      "[2,   233] accuracy: (32.000, 96.000)\n",
      "[2,   233] loss: 0.386216\n",
      "[2,   234] accuracy: (52.000, 96.000)\n",
      "[2,   234] loss: 0.380564\n",
      "[2,   235] accuracy: (60.000, 96.000)\n",
      "[2,   235] loss: 0.309401\n",
      "[2,   236] accuracy: (36.000, 96.000)\n",
      "[2,   236] loss: 0.344393\n",
      "[2,   237] accuracy: (48.000, 96.000)\n",
      "[2,   237] loss: 0.321971\n",
      "[2,   238] accuracy: (44.000, 100.000)\n",
      "[2,   238] loss: 0.282774\n",
      "[2,   239] accuracy: (52.000, 92.000)\n",
      "[2,   239] loss: 0.276753\n",
      "[2,   240] accuracy: (32.000, 100.000)\n",
      "[2,   240] loss: 0.304302\n",
      "[2,   241] accuracy: (32.000, 96.000)\n",
      "[2,   241] loss: 0.297000\n",
      "[2,   242] accuracy: (40.000, 100.000)\n",
      "[2,   242] loss: 0.332787\n",
      "[2,   243] accuracy: (60.000, 100.000)\n",
      "[2,   243] loss: 0.268351\n",
      "[2,   244] accuracy: (40.000, 100.000)\n",
      "[2,   244] loss: 0.299835\n",
      "[2,   245] accuracy: (48.000, 96.000)\n",
      "[2,   245] loss: 0.299916\n",
      "[2,   246] accuracy: (56.000, 96.000)\n",
      "[2,   246] loss: 0.328219\n",
      "[2,   247] accuracy: (44.000, 96.000)\n",
      "[2,   247] loss: 0.424006\n",
      "[2,   248] accuracy: (40.000, 100.000)\n",
      "[2,   248] loss: 0.281440\n",
      "[2,   249] accuracy: (36.000, 100.000)\n",
      "[2,   249] loss: 0.359529\n",
      "[2,   250] accuracy: (44.000, 96.000)\n",
      "[2,   250] loss: 0.299062\n",
      "[2,   251] accuracy: (52.000, 96.000)\n",
      "[2,   251] loss: 0.269569\n",
      "[2,   252] accuracy: (44.000, 96.000)\n",
      "[2,   252] loss: 0.416217\n",
      "[2,   253] accuracy: (40.000, 92.000)\n",
      "[2,   253] loss: 0.330742\n",
      "[2,   254] accuracy: (36.000, 96.000)\n",
      "[2,   254] loss: 0.275126\n",
      "[2,   255] accuracy: (60.000, 96.000)\n",
      "[2,   255] loss: 0.293602\n",
      "[2,   256] accuracy: (28.000, 96.000)\n",
      "[2,   256] loss: 0.417777\n",
      "[2,   257] accuracy: (44.000, 100.000)\n",
      "[2,   257] loss: 0.364362\n",
      "[2,   258] accuracy: (40.000, 92.000)\n",
      "[2,   258] loss: 0.336276\n",
      "[2,   259] accuracy: (32.000, 96.000)\n",
      "[2,   259] loss: 0.396217\n",
      "[2,   260] accuracy: (52.000, 96.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   260] loss: 0.294453\n",
      "[2,   261] accuracy: (28.000, 88.000)\n",
      "[2,   261] loss: 0.371126\n",
      "[2,   262] accuracy: (52.000, 100.000)\n",
      "[2,   262] loss: 0.298275\n",
      "[2,   263] accuracy: (44.000, 96.000)\n",
      "[2,   263] loss: 0.376838\n",
      "[2,   264] accuracy: (24.000, 96.000)\n",
      "[2,   264] loss: 0.365166\n",
      "[2,   265] accuracy: (48.000, 96.000)\n",
      "[2,   265] loss: 0.355683\n",
      "[2,   266] accuracy: (32.000, 92.000)\n",
      "[2,   266] loss: 0.348284\n",
      "[2,   267] accuracy: (48.000, 100.000)\n",
      "[2,   267] loss: 0.293166\n",
      "[2,   268] accuracy: (56.000, 100.000)\n",
      "[2,   268] loss: 0.250850\n",
      "[2,   269] accuracy: (28.000, 92.000)\n",
      "[2,   269] loss: 0.388128\n",
      "[2,   270] accuracy: (48.000, 100.000)\n",
      "[2,   270] loss: 0.309348\n",
      "[2,   271] accuracy: (44.000, 96.000)\n",
      "[2,   271] loss: 0.327537\n",
      "[2,   272] accuracy: (32.000, 92.000)\n",
      "[2,   272] loss: 0.368654\n",
      "[2,   273] accuracy: (64.000, 100.000)\n",
      "[2,   273] loss: 0.273836\n",
      "[2,   274] accuracy: (40.000, 96.000)\n",
      "[2,   274] loss: 0.414680\n",
      "[2,   275] accuracy: (48.000, 96.000)\n",
      "[2,   275] loss: 0.314269\n",
      "[2,   276] accuracy: (52.000, 96.000)\n",
      "[2,   276] loss: 0.350883\n",
      "[2,   277] accuracy: (56.000, 96.000)\n",
      "[2,   277] loss: 0.302481\n",
      "[2,   278] accuracy: (44.000, 96.000)\n",
      "[2,   278] loss: 0.339612\n",
      "[2,   279] accuracy: (36.000, 96.000)\n",
      "[2,   279] loss: 0.386069\n",
      "[2,   280] accuracy: (44.000, 100.000)\n",
      "[2,   280] loss: 0.301808\n",
      "[2,   281] accuracy: (52.000, 96.000)\n",
      "[2,   281] loss: 0.315597\n",
      "[2,   282] accuracy: (48.000, 96.000)\n",
      "[2,   282] loss: 0.342345\n",
      "[2,   283] accuracy: (32.000, 88.000)\n",
      "[2,   283] loss: 0.395357\n",
      "[2,   284] accuracy: (40.000, 96.000)\n",
      "[2,   284] loss: 0.283557\n",
      "[2,   285] accuracy: (28.000, 96.000)\n",
      "[2,   285] loss: 0.447073\n",
      "[2,   286] accuracy: (32.000, 96.000)\n",
      "[2,   286] loss: 0.362884\n",
      "[2,   287] accuracy: (44.000, 100.000)\n",
      "[2,   287] loss: 0.269413\n",
      "[2,   288] accuracy: (40.000, 96.000)\n",
      "[2,   288] loss: 0.333680\n",
      "[2,   289] accuracy: (36.000, 96.000)\n",
      "[2,   289] loss: 0.352688\n",
      "[2,   290] accuracy: (48.000, 100.000)\n",
      "[2,   290] loss: 0.270198\n",
      "[2,   291] accuracy: (44.000, 100.000)\n",
      "[2,   291] loss: 0.331358\n",
      "[2,   292] accuracy: (32.000, 84.000)\n",
      "[2,   292] loss: 0.417522\n",
      "[2,   293] accuracy: (36.000, 84.000)\n",
      "[2,   293] loss: 0.385362\n",
      "[2,   294] accuracy: (56.000, 100.000)\n",
      "[2,   294] loss: 0.340970\n",
      "[2,   295] accuracy: (44.000, 100.000)\n",
      "[2,   295] loss: 0.332503\n",
      "[2,   296] accuracy: (28.000, 100.000)\n",
      "[2,   296] loss: 0.316188\n",
      "[2,   297] accuracy: (36.000, 92.000)\n",
      "[2,   297] loss: 0.353539\n",
      "[2,   298] accuracy: (40.000, 92.000)\n",
      "[2,   298] loss: 0.296591\n",
      "[2,   299] accuracy: (36.000, 96.000)\n",
      "[2,   299] loss: 0.294657\n",
      "[2,   300] accuracy: (48.000, 96.000)\n",
      "[2,   300] loss: 0.329875\n",
      "[2,   301] accuracy: (36.000, 96.000)\n",
      "[2,   301] loss: 0.322138\n",
      "[2,   302] accuracy: (40.000, 92.000)\n",
      "[2,   302] loss: 0.343673\n",
      "[2,   303] accuracy: (44.000, 96.000)\n",
      "[2,   303] loss: 0.269502\n",
      "[2,   304] accuracy: (32.000, 100.000)\n",
      "[2,   304] loss: 0.383320\n",
      "[2,   305] accuracy: (44.000, 100.000)\n",
      "[2,   305] loss: 0.316496\n",
      "[2,   306] accuracy: (40.000, 96.000)\n",
      "[2,   306] loss: 0.374694\n",
      "[2,   307] accuracy: (28.000, 100.000)\n",
      "[2,   307] loss: 0.410208\n",
      "[2,   308] accuracy: (36.000, 100.000)\n",
      "[2,   308] loss: 0.344804\n",
      "[2,   309] accuracy: (36.000, 96.000)\n",
      "[2,   309] loss: 0.393197\n",
      "[2,   310] accuracy: (48.000, 96.000)\n",
      "[2,   310] loss: 0.339176\n",
      "[2,   311] accuracy: (40.000, 88.000)\n",
      "[2,   311] loss: 0.314879\n",
      "[2,   312] accuracy: (28.000, 100.000)\n",
      "[2,   312] loss: 0.404043\n",
      "[2,   313] accuracy: (36.000, 92.000)\n",
      "[2,   313] loss: 0.290310\n",
      "[2,   314] accuracy: (36.000, 96.000)\n",
      "[2,   314] loss: 0.356677\n",
      "[2,   315] accuracy: (52.000, 96.000)\n",
      "[2,   315] loss: 0.381212\n",
      "[2,   316] accuracy: (36.000, 100.000)\n",
      "[2,   316] loss: 0.340549\n",
      "[2,   317] accuracy: (32.000, 96.000)\n",
      "[2,   317] loss: 0.368145\n",
      "[2,   318] accuracy: (44.000, 92.000)\n",
      "[2,   318] loss: 0.398038\n",
      "[2,   319] accuracy: (40.000, 96.000)\n",
      "[2,   319] loss: 0.385741\n",
      "[2,   320] accuracy: (36.000, 96.000)\n",
      "[2,   320] loss: 0.452510\n",
      "[2,   321] accuracy: (40.000, 96.000)\n",
      "[2,   321] loss: 0.333206\n",
      "[2,   322] accuracy: (40.000, 100.000)\n",
      "[2,   322] loss: 0.355940\n",
      "[2,   323] accuracy: (40.000, 96.000)\n",
      "[2,   323] loss: 0.365633\n",
      "[2,   324] accuracy: (36.000, 100.000)\n",
      "[2,   324] loss: 0.314132\n",
      "[2,   325] accuracy: (28.000, 92.000)\n",
      "[2,   325] loss: 0.371471\n",
      "[2,   326] accuracy: (48.000, 92.000)\n",
      "[2,   326] loss: 0.377867\n",
      "[2,   327] accuracy: (24.000, 100.000)\n",
      "[2,   327] loss: 0.352186\n",
      "[2,   328] accuracy: (44.000, 96.000)\n",
      "[2,   328] loss: 0.294940\n",
      "[2,   329] accuracy: (32.000, 100.000)\n",
      "[2,   329] loss: 0.322359\n",
      "[2,   330] accuracy: (52.000, 96.000)\n",
      "[2,   330] loss: 0.321556\n",
      "[2,   331] accuracy: (32.000, 96.000)\n",
      "[2,   331] loss: 0.374764\n",
      "[2,   332] accuracy: (56.000, 100.000)\n",
      "[2,   332] loss: 0.274935\n",
      "[2,   333] accuracy: (28.000, 100.000)\n",
      "[2,   333] loss: 0.389849\n",
      "[2,   334] accuracy: (36.000, 96.000)\n",
      "[2,   334] loss: 0.450840\n",
      "[2,   335] accuracy: (48.000, 96.000)\n",
      "[2,   335] loss: 0.344203\n",
      "[2,   336] accuracy: (64.000, 92.000)\n",
      "[2,   336] loss: 0.287186\n",
      "[2,   337] accuracy: (36.000, 92.000)\n",
      "[2,   337] loss: 0.310985\n",
      "[2,   338] accuracy: (40.000, 100.000)\n",
      "[2,   338] loss: 0.342196\n",
      "[2,   339] accuracy: (56.000, 92.000)\n",
      "[2,   339] loss: 0.345252\n",
      "[2,   340] accuracy: (20.000, 96.000)\n",
      "[2,   340] loss: 0.427034\n",
      "[2,   341] accuracy: (44.000, 100.000)\n",
      "[2,   341] loss: 0.361183\n",
      "[2,   342] accuracy: (60.000, 100.000)\n",
      "[2,   342] loss: 0.320189\n",
      "[2,   343] accuracy: (48.000, 96.000)\n",
      "[2,   343] loss: 0.366896\n",
      "[2,   344] accuracy: (64.000, 96.000)\n",
      "[2,   344] loss: 0.299010\n",
      "[2,   345] accuracy: (40.000, 92.000)\n",
      "[2,   345] loss: 0.365288\n",
      "[2,   346] accuracy: (28.000, 100.000)\n",
      "[2,   346] loss: 0.363930\n",
      "[2,   347] accuracy: (56.000, 100.000)\n",
      "[2,   347] loss: 0.361889\n",
      "[2,   348] accuracy: (8.000, 88.000)\n",
      "[2,   348] loss: 0.461896\n",
      "[2,   349] accuracy: (48.000, 92.000)\n",
      "[2,   349] loss: 0.351056\n",
      "[2,   350] accuracy: (44.000, 84.000)\n",
      "[2,   350] loss: 0.287117\n",
      "[2,   351] accuracy: (44.000, 88.000)\n",
      "[2,   351] loss: 0.339637\n",
      "[2,   352] accuracy: (44.000, 96.000)\n",
      "[2,   352] loss: 0.303399\n",
      "[2,   353] accuracy: (52.000, 100.000)\n",
      "[2,   353] loss: 0.265207\n",
      "[2,   354] accuracy: (60.000, 96.000)\n",
      "[2,   354] loss: 0.290079\n",
      "[2,   355] accuracy: (36.000, 96.000)\n",
      "[2,   355] loss: 0.343824\n",
      "[2,   356] accuracy: (44.000, 96.000)\n",
      "[2,   356] loss: 0.387398\n",
      "[2,   357] accuracy: (56.000, 92.000)\n",
      "[2,   357] loss: 0.305803\n",
      "[2,   358] accuracy: (24.000, 88.000)\n",
      "[2,   358] loss: 0.354772\n",
      "[2,   359] accuracy: (40.000, 100.000)\n",
      "[2,   359] loss: 0.350547\n",
      "[2,   360] accuracy: (40.000, 96.000)\n",
      "[2,   360] loss: 0.346847\n",
      "[2,   361] accuracy: (56.000, 100.000)\n",
      "[2,   361] loss: 0.305306\n",
      "[2,   362] accuracy: (56.000, 100.000)\n",
      "[2,   362] loss: 0.318815\n",
      "[2,   363] accuracy: (20.000, 96.000)\n",
      "[2,   363] loss: 0.474575\n",
      "[2,   364] accuracy: (48.000, 96.000)\n",
      "[2,   364] loss: 0.262691\n",
      "[2,   365] accuracy: (32.000, 100.000)\n",
      "[2,   365] loss: 0.377450\n",
      "[2,   366] accuracy: (48.000, 100.000)\n",
      "[2,   366] loss: 0.255917\n",
      "[2,   367] accuracy: (52.000, 92.000)\n",
      "[2,   367] loss: 0.299900\n",
      "[2,   368] accuracy: (24.000, 100.000)\n",
      "[2,   368] loss: 0.330970\n",
      "[2,   369] accuracy: (40.000, 96.000)\n",
      "[2,   369] loss: 0.405447\n",
      "[2,   370] accuracy: (52.000, 96.000)\n",
      "[2,   370] loss: 0.303618\n",
      "[2,   371] accuracy: (52.000, 96.000)\n",
      "[2,   371] loss: 0.361813\n",
      "[2,   372] accuracy: (52.000, 92.000)\n",
      "[2,   372] loss: 0.438747\n",
      "[2,   373] accuracy: (32.000, 100.000)\n",
      "[2,   373] loss: 0.363698\n",
      "[2,   374] accuracy: (40.000, 88.000)\n",
      "[2,   374] loss: 0.342018\n",
      "[2,   375] accuracy: (48.000, 96.000)\n",
      "[2,   375] loss: 0.277735\n",
      "[2,   376] accuracy: (44.000, 96.000)\n",
      "[2,   376] loss: 0.314472\n",
      "[2,   377] accuracy: (40.000, 100.000)\n",
      "[2,   377] loss: 0.343768\n",
      "[2,   378] accuracy: (40.000, 96.000)\n",
      "[2,   378] loss: 0.381902\n",
      "[2,   379] accuracy: (48.000, 100.000)\n",
      "[2,   379] loss: 0.367775\n",
      "[2,   380] accuracy: (44.000, 84.000)\n",
      "[2,   380] loss: 0.420082\n",
      "[2,   381] accuracy: (48.000, 100.000)\n",
      "[2,   381] loss: 0.382188\n",
      "[2,   382] accuracy: (52.000, 100.000)\n",
      "[2,   382] loss: 0.295518\n",
      "[2,   383] accuracy: (36.000, 88.000)\n",
      "[2,   383] loss: 0.319544\n",
      "[2,   384] accuracy: (60.000, 100.000)\n",
      "[2,   384] loss: 0.298342\n",
      "[2,   385] accuracy: (44.000, 100.000)\n",
      "[2,   385] loss: 0.308974\n",
      "[2,   386] accuracy: (32.000, 92.000)\n",
      "[2,   386] loss: 0.351783\n",
      "[2,   387] accuracy: (36.000, 92.000)\n",
      "[2,   387] loss: 0.394707\n",
      "[2,   388] accuracy: (52.000, 100.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   388] loss: 0.290752\n",
      "[2,   389] accuracy: (36.000, 92.000)\n",
      "[2,   389] loss: 0.402330\n",
      "[2,   390] accuracy: (48.000, 84.000)\n",
      "[2,   390] loss: 0.296287\n",
      "[2,   391] accuracy: (43.750, 93.750)\n",
      "[2,   391] loss: 0.466125\n",
      "COMPLETED EPOCH 0002... checkpointing here\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_loss = nn.CrossEntropyLoss() # just use standard XEntropy to train\n",
    "training_logger = training_obj.train(cifar_trainset, 2, train_loss, \n",
    "                                     attack_parameters=attack_params, \n",
    "                                     verbosity='snoop', loglevel='snoop') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2f47665c030f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinearize_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m         \"\"\"\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \"\"\"\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_logger.linearize_series('training_loss', return_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printouts look like:\n",
    "``` \n",
    "[epoch_no, minibatch_no] accuracy: (X, Y) \n",
    "[epoch_no, minibatch_no] loss: Z\n",
    "```\n",
    "\n",
    "- X is the percent of successfully classified *adversarial* examples generated from that minibatch only\n",
    "- Y is the percent of successfully classified *original* examples on that minibatch only\n",
    "- Z is the value of the loss function after that minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training completes, you can verify that the checkpoints are indeed stored in wherever you have set up pretrained models to be stored. By default this is `mister_ed/pretrained_models/`, so you should have a `tutorial_fgsm.resnet20.000002.path.tar` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restarting from Checkpoint\n",
    "When training, sometimes @#\\$& happens and things break. This is why we checkpoint. Here we'll show how to restart from checkpoint in training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to pick back up from where we left off with the experiment/architecture pair defined above `(tutorial_fgsm, resnet20)`. Then we want to do the following steps:\n",
    "\n",
    "1. Instantiate a model of the same architecture (weights don't matter, since we'll load from the checkpoint) \n",
    "2. Build an `AdversarialTraining` object using this model, its normalizer, and the same experiment name, architecture name \n",
    "3. Build a loss function, attack_parameters object, and all other identical kwargs from the first (aborted) training run \n",
    "4. Run the training using the training object's `train_from_checkpoint` method instead of `train`. All the kwargs are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20, return_normalizer=True)\n",
    "new_train_obj = advtrain.AdversarialTraining(naive_model, normalizer, experiment_name, architecture)\n",
    "\n",
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              {'lp_style': 'inf', \n",
    "                               'lp_bound': 8.0 / 255})\n",
    "attack_loss = plf.VanillaXentropy(naive_model, normalizer)\n",
    "attack_object = aa.FGSM(naive_model, normalizer, delta_threat, attack_loss)\n",
    "attack_kwargs = {'verbose': False} # kwargs to be called in attack_object.attack(...)\n",
    "attack_params = advtrain.AdversarialAttackParameters(attack_object, proportion_attacked=0.2, \n",
    "                                                     attack_specific_params={'attack_kwargs': attack_kwargs})\n",
    "\n",
    "new_train_obj.train_from_checkpoint(cifar_trainset, 4, train_loss, attack_parameters=attack_params, \n",
    "                                    verbosity='high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this finishes, notice that you should now have a file \n",
    "`tutorial_fgsm.resnet20.000004.path.tar` in your pretrained_models directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the training script \n",
    "Using an ipython notebook isn't typically ideal for training, since it mandates you keep your browser window open. To this end, we've built a script to perform adversarial training in a tmux/screen background. This is located in `scripts/advtrain.py`. Here's what we've found are best practices for doing this:\n",
    "\n",
    "- Copy `scripts/advtrain.py` into `scripts/advtrain_<DESCRIPTIVE_EXPERIMENT_NAME>.py`\n",
    "- Modify the `build_attack_params` method in `scripts/advtrain_<DESCRIPTIVE_EXPERIMENT_NAME>.py` to use the attack parameters that you want. There's plenty of prebuilt attack parameters in that file to choose from. \n",
    "- In a tmux/screen, from `mister_ed`, run \n",
    "\n",
    "```python -m scripts.advtrain_DESCRIPTIVE_EXPERIMENT_NAME --exp <DESCRIPTIVE_EXPERIMENT_NAME> --arch <ARCHITECTURE_CHOICE> --verbosity [snoop/high/medium]```\n",
    "\n",
    "- To resume, you can optionally add the `-r` or `--resume` flag to the script call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note on GPU Usage\n",
    "If you have access to a GPU on your machine, you'll probably want to leverage its power when doing training and attacks. `mister_ed` has been designed so \"standard\" GPU behavior should be supported without any extra effort. By \"standard\" GPU behavior, I mean that all objects reside on the same device: either all on the GPU or none on the GPU. If there is a GPU on your machine, which one can check from the output of \n",
    "```\n",
    "import torch.cuda as cuda \n",
    "print(cuda.is_available()) \n",
    "```\n",
    "Globally, unless otherwise specified, all objects will be initialized in GPU-mode if this output is `True`. This is done behind-the-scenes by setting the environment variable `MISTER_ED_GPU`. If you have access to a GPU, but wouldn't like to use it, you can manually override this environment variable by calling:\n",
    "```\n",
    "import utils.pytorch_utils as utils \n",
    "utils.set_global_gpu(False)\n",
    "```\n",
    "And then none of your objects will be in GPU-mode by default. \n",
    "\n",
    "For nonstandard GPU behavior, you should initialize any object that differs from the default gpu status (as defined by `MISTER_ED_GPU`) with the kwarg `manual_gpu=<True/False>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
