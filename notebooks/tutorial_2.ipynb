{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training with `mister_ed`\n",
    "This file will contain the basics on how to perform adversarial training under the `mister_ed` framework. It's highly recommended that you have walked through tutorial_1 before going through this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we'll start by importing everything we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTERNAL LIBRARY IMPORTS\n",
    "import numpy as np \n",
    "import scipy \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch # Need torch version >=0.3\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "assert float(torch.__version__[:3]) >= 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISTER ED SPECIFIC IMPORT BLOCK\n",
    "# (here we do things so relative imports work )\n",
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os\n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import config\n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import utils.checkpoints as checkpoints\n",
    "import adversarial_perturbations as ap \n",
    "import adversarial_attacks as aa\n",
    "import spatial_transformers as st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define what we want to do here:\n",
    "\n",
    "Our goal is to run through a few training epochs of a pretrained classifier where we augment the training data with a set of adversarial examples. For simplicity's sake, let's just try and train a few epochs of a 20-layer ResNet trained on CIFAR-10, defended against an FGSM attack of $\\epsilon=8$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's instatiate our pretrained classifier and our training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_trainset = cifar_loader.load_cifar_data('train')\n",
    "model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20, return_normalizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's build the attack parameters: an object that contains all the information to perform an attack on a minibatch. So first let's build an attack object and then furnish it with the necessary kwargs. \n",
    "\n",
    "Like in tutorial 1, to create an attack object, we'll need to create a threat model and a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              {'lp_style': 'inf', \n",
    "                               'lp_bound': 8.0 / 255})\n",
    "attack_loss = plf.VanillaXentropy(model, normalizer)\n",
    "attack_object = aa.FGSM(model, normalizer, delta_threat, attack_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we build the `AttackParameters` object, which just wraps the attack object with the kwargs needed to call the `attack(...)` method on attack. For FGSM attacks, we just want to turn the verbosity off, but for more complicated attacks, this will be more involved. Typically in training, we generate a single adversarial example per training point, but to be speedy here, let's only create 1 example per every 5 training points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_kwargs = {'verbose': False} # kwargs to be called in attack_object.attack(...)\n",
    "attack_params = advtrain.AdversarialAttackParameters(attack_object, proportion_attacked=0.2, \n",
    "                                                     attack_specific_params={'attack_kwargs': attack_kwargs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our attack parameters built, we can build the object that handles training for us: this is instatiated with knowledge of the classifier, normalizer and some identifying features such as the *name* of the experiment and architecture. It's worthwhile to be informative with these so you keep which attacks this model is trained against straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'tutorial_fgsm'\n",
    "architecture = 'resnet20'\n",
    "training_obj = advtrain.AdversarialTraining(model, normalizer, experiment_name, architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you start training though, you'll need to furnish the trainer with some extra arguments:\n",
    "    - the data loader \n",
    "    - the number of epochs to train for \n",
    "    - a loss function (not one of the `mister_ed` custom loss functions though!)\n",
    "    - which optimizer to use (defaults to Adam with decent hyperparams)\n",
    "    - the attack parameters object \n",
    "    - whether or not to use the gpu (defaults to not using GPU)\n",
    "    - the verbosity level (ranging from ['low', 'medium', 'high', 'snoop'] (defaults to 'medium')\n",
    "    - whether or not to save the generated adversarial examples as images (defaults to false)\n",
    "    \n",
    "To be cute, we'll just train for two epochs so you get the picture. Also note that unless the verbosity is set to `low`, a checkpoint will be saved after every epoch. By default, these checkpoints are named like `<experiment_name>.<architecture_name>.<epoch>.path.tar`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: LOGGER IS NOT EMPTY! BE CAREFUL!\n",
      "[1,     1] accuracy: (48.000, 96.000)\n",
      "[1,     1] loss: 0.359370\n",
      "[1,     2] accuracy: (40.000, 100.000)\n",
      "[1,     2] loss: 0.308328\n",
      "[1,     3] accuracy: (24.000, 88.000)\n",
      "[1,     3] loss: 0.370927\n",
      "[1,     4] accuracy: (24.000, 100.000)\n",
      "[1,     4] loss: 0.317369\n",
      "[1,     5] accuracy: (36.000, 100.000)\n",
      "[1,     5] loss: 0.351738\n",
      "[1,     6] accuracy: (44.000, 88.000)\n",
      "[1,     6] loss: 0.318250\n",
      "[1,     7] accuracy: (44.000, 100.000)\n",
      "[1,     7] loss: 0.273458\n",
      "[1,     8] accuracy: (44.000, 100.000)\n",
      "[1,     8] loss: 0.341295\n",
      "[1,     9] accuracy: (36.000, 96.000)\n",
      "[1,     9] loss: 0.403555\n",
      "[1,    10] accuracy: (32.000, 92.000)\n",
      "[1,    10] loss: 0.450216\n",
      "[1,    11] accuracy: (56.000, 100.000)\n",
      "[1,    11] loss: 0.354675\n",
      "[1,    12] accuracy: (48.000, 96.000)\n",
      "[1,    12] loss: 0.338677\n",
      "[1,    13] accuracy: (36.000, 100.000)\n",
      "[1,    13] loss: 0.381816\n",
      "[1,    14] accuracy: (44.000, 96.000)\n",
      "[1,    14] loss: 0.338495\n",
      "[1,    15] accuracy: (44.000, 100.000)\n",
      "[1,    15] loss: 0.296192\n",
      "[1,    16] accuracy: (36.000, 92.000)\n",
      "[1,    16] loss: 0.374570\n",
      "[1,    17] accuracy: (56.000, 88.000)\n",
      "[1,    17] loss: 0.395072\n",
      "[1,    18] accuracy: (36.000, 88.000)\n",
      "[1,    18] loss: 0.356856\n",
      "[1,    19] accuracy: (36.000, 96.000)\n",
      "[1,    19] loss: 0.385574\n",
      "[1,    20] accuracy: (28.000, 96.000)\n",
      "[1,    20] loss: 0.356503\n",
      "[1,    21] accuracy: (44.000, 92.000)\n",
      "[1,    21] loss: 0.336911\n",
      "[1,    22] accuracy: (28.000, 88.000)\n",
      "[1,    22] loss: 0.428268\n",
      "[1,    23] accuracy: (24.000, 80.000)\n",
      "[1,    23] loss: 0.428243\n",
      "[1,    24] accuracy: (52.000, 96.000)\n",
      "[1,    24] loss: 0.425954\n",
      "[1,    25] accuracy: (44.000, 92.000)\n",
      "[1,    25] loss: 0.452149\n",
      "[1,    26] accuracy: (48.000, 92.000)\n",
      "[1,    26] loss: 0.301823\n",
      "[1,    27] accuracy: (44.000, 92.000)\n",
      "[1,    27] loss: 0.338863\n",
      "[1,    28] accuracy: (40.000, 88.000)\n",
      "[1,    28] loss: 0.294889\n",
      "[1,    29] accuracy: (48.000, 100.000)\n",
      "[1,    29] loss: 0.290670\n",
      "[1,    30] accuracy: (36.000, 96.000)\n",
      "[1,    30] loss: 0.411315\n",
      "[1,    31] accuracy: (40.000, 100.000)\n",
      "[1,    31] loss: 0.308446\n",
      "[1,    32] accuracy: (40.000, 100.000)\n",
      "[1,    32] loss: 0.378503\n",
      "[1,    33] accuracy: (32.000, 96.000)\n",
      "[1,    33] loss: 0.471234\n",
      "[1,    34] accuracy: (52.000, 92.000)\n",
      "[1,    34] loss: 0.334098\n",
      "[1,    35] accuracy: (48.000, 92.000)\n",
      "[1,    35] loss: 0.392012\n",
      "[1,    36] accuracy: (64.000, 92.000)\n",
      "[1,    36] loss: 0.330238\n",
      "[1,    37] accuracy: (44.000, 92.000)\n",
      "[1,    37] loss: 0.343252\n",
      "[1,    38] accuracy: (40.000, 88.000)\n",
      "[1,    38] loss: 0.354822\n",
      "[1,    39] accuracy: (24.000, 96.000)\n",
      "[1,    39] loss: 0.422987\n",
      "[1,    40] accuracy: (24.000, 92.000)\n",
      "[1,    40] loss: 0.457864\n",
      "[1,    41] accuracy: (48.000, 96.000)\n",
      "[1,    41] loss: 0.384159\n",
      "[1,    42] accuracy: (56.000, 100.000)\n",
      "[1,    42] loss: 0.253415\n",
      "[1,    43] accuracy: (40.000, 100.000)\n",
      "[1,    43] loss: 0.412833\n",
      "[1,    44] accuracy: (48.000, 96.000)\n",
      "[1,    44] loss: 0.292482\n",
      "[1,    45] accuracy: (48.000, 96.000)\n",
      "[1,    45] loss: 0.406415\n",
      "[1,    46] accuracy: (40.000, 96.000)\n",
      "[1,    46] loss: 0.377905\n",
      "[1,    47] accuracy: (48.000, 88.000)\n",
      "[1,    47] loss: 0.401710\n",
      "[1,    48] accuracy: (56.000, 96.000)\n",
      "[1,    48] loss: 0.303753\n",
      "[1,    49] accuracy: (48.000, 96.000)\n",
      "[1,    49] loss: 0.406359\n",
      "[1,    50] accuracy: (64.000, 96.000)\n",
      "[1,    50] loss: 0.249273\n",
      "[1,    51] accuracy: (44.000, 100.000)\n",
      "[1,    51] loss: 0.337093\n",
      "[1,    52] accuracy: (60.000, 92.000)\n",
      "[1,    52] loss: 0.375666\n",
      "[1,    53] accuracy: (48.000, 100.000)\n",
      "[1,    53] loss: 0.327976\n",
      "[1,    54] accuracy: (48.000, 96.000)\n",
      "[1,    54] loss: 0.318329\n",
      "[1,    55] accuracy: (56.000, 100.000)\n",
      "[1,    55] loss: 0.335042\n",
      "[1,    56] accuracy: (36.000, 96.000)\n",
      "[1,    56] loss: 0.308090\n",
      "[1,    57] accuracy: (44.000, 96.000)\n",
      "[1,    57] loss: 0.291753\n",
      "[1,    58] accuracy: (40.000, 96.000)\n",
      "[1,    58] loss: 0.306143\n",
      "[1,    59] accuracy: (40.000, 96.000)\n",
      "[1,    59] loss: 0.310461\n",
      "[1,    60] accuracy: (44.000, 92.000)\n",
      "[1,    60] loss: 0.360779\n",
      "[1,    61] accuracy: (36.000, 96.000)\n",
      "[1,    61] loss: 0.403624\n",
      "[1,    62] accuracy: (64.000, 100.000)\n",
      "[1,    62] loss: 0.248152\n",
      "[1,    63] accuracy: (48.000, 92.000)\n",
      "[1,    63] loss: 0.264288\n",
      "[1,    64] accuracy: (48.000, 92.000)\n",
      "[1,    64] loss: 0.320182\n",
      "[1,    65] accuracy: (56.000, 100.000)\n",
      "[1,    65] loss: 0.373331\n",
      "[1,    66] accuracy: (56.000, 96.000)\n",
      "[1,    66] loss: 0.258920\n",
      "[1,    67] accuracy: (52.000, 96.000)\n",
      "[1,    67] loss: 0.326130\n",
      "[1,    68] accuracy: (16.000, 92.000)\n",
      "[1,    68] loss: 0.582862\n",
      "[1,    69] accuracy: (44.000, 96.000)\n",
      "[1,    69] loss: 0.328187\n",
      "[1,    70] accuracy: (40.000, 92.000)\n",
      "[1,    70] loss: 0.356026\n",
      "[1,    71] accuracy: (56.000, 100.000)\n",
      "[1,    71] loss: 0.344646\n",
      "[1,    72] accuracy: (40.000, 96.000)\n",
      "[1,    72] loss: 0.331032\n",
      "[1,    73] accuracy: (64.000, 92.000)\n",
      "[1,    73] loss: 0.369224\n",
      "[1,    74] accuracy: (40.000, 96.000)\n",
      "[1,    74] loss: 0.477764\n",
      "[1,    75] accuracy: (44.000, 100.000)\n",
      "[1,    75] loss: 0.329910\n",
      "[1,    76] accuracy: (44.000, 100.000)\n",
      "[1,    76] loss: 0.311699\n",
      "[1,    77] accuracy: (48.000, 92.000)\n",
      "[1,    77] loss: 0.355940\n",
      "[1,    78] accuracy: (36.000, 92.000)\n",
      "[1,    78] loss: 0.306682\n",
      "[1,    79] accuracy: (52.000, 100.000)\n",
      "[1,    79] loss: 0.207934\n",
      "[1,    80] accuracy: (44.000, 92.000)\n",
      "[1,    80] loss: 0.301298\n",
      "[1,    81] accuracy: (44.000, 96.000)\n",
      "[1,    81] loss: 0.378561\n",
      "[1,    82] accuracy: (40.000, 100.000)\n",
      "[1,    82] loss: 0.328048\n",
      "[1,    83] accuracy: (52.000, 88.000)\n",
      "[1,    83] loss: 0.412009\n",
      "[1,    84] accuracy: (60.000, 100.000)\n",
      "[1,    84] loss: 0.314140\n",
      "[1,    85] accuracy: (40.000, 92.000)\n",
      "[1,    85] loss: 0.355036\n",
      "[1,    86] accuracy: (52.000, 96.000)\n",
      "[1,    86] loss: 0.382848\n",
      "[1,    87] accuracy: (40.000, 100.000)\n",
      "[1,    87] loss: 0.324231\n",
      "[1,    88] accuracy: (52.000, 92.000)\n",
      "[1,    88] loss: 0.282093\n",
      "[1,    89] accuracy: (44.000, 96.000)\n",
      "[1,    89] loss: 0.374742\n",
      "[1,    90] accuracy: (32.000, 92.000)\n",
      "[1,    90] loss: 0.335078\n",
      "[1,    91] accuracy: (36.000, 92.000)\n",
      "[1,    91] loss: 0.381004\n",
      "[1,    92] accuracy: (40.000, 96.000)\n",
      "[1,    92] loss: 0.399395\n",
      "[1,    93] accuracy: (40.000, 100.000)\n",
      "[1,    93] loss: 0.343657\n",
      "[1,    94] accuracy: (64.000, 96.000)\n",
      "[1,    94] loss: 0.324270\n",
      "[1,    95] accuracy: (48.000, 96.000)\n",
      "[1,    95] loss: 0.299806\n",
      "[1,    96] accuracy: (52.000, 92.000)\n",
      "[1,    96] loss: 0.298946\n",
      "[1,    97] accuracy: (48.000, 92.000)\n",
      "[1,    97] loss: 0.323484\n",
      "[1,    98] accuracy: (48.000, 100.000)\n",
      "[1,    98] loss: 0.298642\n",
      "[1,    99] accuracy: (48.000, 100.000)\n",
      "[1,    99] loss: 0.356583\n",
      "[1,   100] accuracy: (32.000, 96.000)\n",
      "[1,   100] loss: 0.310292\n",
      "[1,   101] accuracy: (28.000, 100.000)\n",
      "[1,   101] loss: 0.331529\n",
      "[1,   102] accuracy: (64.000, 100.000)\n",
      "[1,   102] loss: 0.281739\n",
      "[1,   103] accuracy: (40.000, 96.000)\n",
      "[1,   103] loss: 0.338375\n",
      "[1,   104] accuracy: (36.000, 96.000)\n",
      "[1,   104] loss: 0.380919\n",
      "[1,   105] accuracy: (60.000, 96.000)\n",
      "[1,   105] loss: 0.311303\n",
      "[1,   106] accuracy: (48.000, 96.000)\n",
      "[1,   106] loss: 0.292143\n",
      "[1,   107] accuracy: (44.000, 96.000)\n",
      "[1,   107] loss: 0.353771\n",
      "[1,   108] accuracy: (44.000, 96.000)\n",
      "[1,   108] loss: 0.361769\n",
      "[1,   109] accuracy: (40.000, 100.000)\n",
      "[1,   109] loss: 0.297375\n",
      "[1,   110] accuracy: (36.000, 96.000)\n",
      "[1,   110] loss: 0.418931\n",
      "[1,   111] accuracy: (44.000, 96.000)\n",
      "[1,   111] loss: 0.338942\n",
      "[1,   112] accuracy: (60.000, 100.000)\n",
      "[1,   112] loss: 0.265738\n",
      "[1,   113] accuracy: (24.000, 96.000)\n",
      "[1,   113] loss: 0.342735\n",
      "[1,   114] accuracy: (48.000, 100.000)\n",
      "[1,   114] loss: 0.365750\n",
      "[1,   115] accuracy: (40.000, 92.000)\n",
      "[1,   115] loss: 0.348949\n",
      "[1,   116] accuracy: (64.000, 96.000)\n",
      "[1,   116] loss: 0.343983\n",
      "[1,   117] accuracy: (40.000, 100.000)\n",
      "[1,   117] loss: 0.355495\n",
      "[1,   118] accuracy: (56.000, 88.000)\n",
      "[1,   118] loss: 0.359257\n",
      "[1,   119] accuracy: (52.000, 92.000)\n",
      "[1,   119] loss: 0.295569\n",
      "[1,   120] accuracy: (52.000, 88.000)\n",
      "[1,   120] loss: 0.407329\n",
      "[1,   121] accuracy: (44.000, 96.000)\n",
      "[1,   121] loss: 0.271925\n",
      "[1,   122] accuracy: (52.000, 88.000)\n",
      "[1,   122] loss: 0.293292\n",
      "[1,   123] accuracy: (44.000, 96.000)\n",
      "[1,   123] loss: 0.358289\n",
      "[1,   124] accuracy: (36.000, 88.000)\n",
      "[1,   124] loss: 0.442006\n",
      "[1,   125] accuracy: (40.000, 96.000)\n",
      "[1,   125] loss: 0.315147\n",
      "[1,   126] accuracy: (44.000, 100.000)\n",
      "[1,   126] loss: 0.398958\n",
      "[1,   127] accuracy: (44.000, 88.000)\n",
      "[1,   127] loss: 0.384054\n",
      "[1,   128] accuracy: (32.000, 96.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   128] loss: 0.324646\n",
      "[1,   129] accuracy: (36.000, 92.000)\n",
      "[1,   129] loss: 0.453300\n",
      "[1,   130] accuracy: (52.000, 96.000)\n",
      "[1,   130] loss: 0.274612\n",
      "[1,   131] accuracy: (56.000, 100.000)\n",
      "[1,   131] loss: 0.299975\n",
      "[1,   132] accuracy: (56.000, 92.000)\n",
      "[1,   132] loss: 0.331249\n",
      "[1,   133] accuracy: (28.000, 92.000)\n",
      "[1,   133] loss: 0.338712\n",
      "[1,   134] accuracy: (40.000, 96.000)\n",
      "[1,   134] loss: 0.340625\n",
      "[1,   135] accuracy: (52.000, 96.000)\n",
      "[1,   135] loss: 0.380498\n",
      "[1,   136] accuracy: (40.000, 88.000)\n",
      "[1,   136] loss: 0.420739\n",
      "[1,   137] accuracy: (56.000, 100.000)\n",
      "[1,   137] loss: 0.337408\n",
      "[1,   138] accuracy: (56.000, 96.000)\n",
      "[1,   138] loss: 0.326675\n",
      "[1,   139] accuracy: (32.000, 92.000)\n",
      "[1,   139] loss: 0.417188\n",
      "[1,   140] accuracy: (36.000, 92.000)\n",
      "[1,   140] loss: 0.340222\n",
      "[1,   141] accuracy: (72.000, 100.000)\n",
      "[1,   141] loss: 0.351880\n",
      "[1,   142] accuracy: (56.000, 100.000)\n",
      "[1,   142] loss: 0.372170\n",
      "[1,   143] accuracy: (32.000, 100.000)\n",
      "[1,   143] loss: 0.327759\n",
      "[1,   144] accuracy: (44.000, 100.000)\n",
      "[1,   144] loss: 0.333787\n",
      "[1,   145] accuracy: (32.000, 100.000)\n",
      "[1,   145] loss: 0.350033\n",
      "[1,   146] accuracy: (44.000, 84.000)\n",
      "[1,   146] loss: 0.308223\n",
      "[1,   147] accuracy: (32.000, 100.000)\n",
      "[1,   147] loss: 0.296496\n",
      "[1,   148] accuracy: (40.000, 96.000)\n",
      "[1,   148] loss: 0.364043\n",
      "[1,   149] accuracy: (48.000, 100.000)\n",
      "[1,   149] loss: 0.248136\n",
      "[1,   150] accuracy: (64.000, 88.000)\n",
      "[1,   150] loss: 0.284831\n",
      "[1,   151] accuracy: (44.000, 80.000)\n",
      "[1,   151] loss: 0.361694\n",
      "[1,   152] accuracy: (40.000, 92.000)\n",
      "[1,   152] loss: 0.407362\n",
      "[1,   153] accuracy: (40.000, 100.000)\n",
      "[1,   153] loss: 0.324916\n",
      "[1,   154] accuracy: (40.000, 96.000)\n",
      "[1,   154] loss: 0.398086\n",
      "[1,   155] accuracy: (44.000, 96.000)\n",
      "[1,   155] loss: 0.250297\n",
      "[1,   156] accuracy: (52.000, 100.000)\n",
      "[1,   156] loss: 0.263736\n",
      "[1,   157] accuracy: (40.000, 92.000)\n",
      "[1,   157] loss: 0.342290\n",
      "[1,   158] accuracy: (56.000, 100.000)\n",
      "[1,   158] loss: 0.308748\n",
      "[1,   159] accuracy: (40.000, 100.000)\n",
      "[1,   159] loss: 0.265882\n",
      "[1,   160] accuracy: (48.000, 100.000)\n",
      "[1,   160] loss: 0.364679\n",
      "[1,   161] accuracy: (48.000, 96.000)\n",
      "[1,   161] loss: 0.364354\n",
      "[1,   162] accuracy: (64.000, 96.000)\n",
      "[1,   162] loss: 0.320300\n",
      "[1,   163] accuracy: (44.000, 88.000)\n",
      "[1,   163] loss: 0.362572\n",
      "[1,   164] accuracy: (44.000, 96.000)\n",
      "[1,   164] loss: 0.348217\n",
      "[1,   165] accuracy: (32.000, 100.000)\n",
      "[1,   165] loss: 0.389682\n",
      "[1,   166] accuracy: (44.000, 92.000)\n",
      "[1,   166] loss: 0.342062\n",
      "[1,   167] accuracy: (56.000, 100.000)\n",
      "[1,   167] loss: 0.264396\n",
      "[1,   168] accuracy: (64.000, 100.000)\n",
      "[1,   168] loss: 0.269019\n",
      "[1,   169] accuracy: (40.000, 92.000)\n",
      "[1,   169] loss: 0.368794\n",
      "[1,   170] accuracy: (40.000, 96.000)\n",
      "[1,   170] loss: 0.361813\n",
      "[1,   171] accuracy: (52.000, 96.000)\n",
      "[1,   171] loss: 0.345049\n",
      "[1,   172] accuracy: (52.000, 100.000)\n",
      "[1,   172] loss: 0.323517\n",
      "[1,   173] accuracy: (24.000, 88.000)\n",
      "[1,   173] loss: 0.492386\n",
      "[1,   174] accuracy: (28.000, 96.000)\n",
      "[1,   174] loss: 0.422211\n",
      "[1,   175] accuracy: (40.000, 96.000)\n",
      "[1,   175] loss: 0.430208\n",
      "[1,   176] accuracy: (52.000, 96.000)\n",
      "[1,   176] loss: 0.307841\n",
      "[1,   177] accuracy: (44.000, 100.000)\n",
      "[1,   177] loss: 0.353524\n",
      "[1,   178] accuracy: (36.000, 100.000)\n",
      "[1,   178] loss: 0.265178\n",
      "[1,   179] accuracy: (52.000, 100.000)\n",
      "[1,   179] loss: 0.327729\n",
      "[1,   180] accuracy: (44.000, 92.000)\n",
      "[1,   180] loss: 0.417061\n",
      "[1,   181] accuracy: (48.000, 96.000)\n",
      "[1,   181] loss: 0.334617\n",
      "[1,   182] accuracy: (44.000, 100.000)\n",
      "[1,   182] loss: 0.455829\n",
      "[1,   183] accuracy: (60.000, 88.000)\n",
      "[1,   183] loss: 0.374639\n",
      "[1,   184] accuracy: (36.000, 100.000)\n",
      "[1,   184] loss: 0.348341\n",
      "[1,   185] accuracy: (64.000, 92.000)\n",
      "[1,   185] loss: 0.237964\n",
      "[1,   186] accuracy: (48.000, 96.000)\n",
      "[1,   186] loss: 0.301956\n",
      "[1,   187] accuracy: (68.000, 96.000)\n",
      "[1,   187] loss: 0.329392\n",
      "[1,   188] accuracy: (64.000, 96.000)\n",
      "[1,   188] loss: 0.323159\n",
      "[1,   189] accuracy: (52.000, 96.000)\n",
      "[1,   189] loss: 0.353314\n",
      "[1,   190] accuracy: (56.000, 96.000)\n",
      "[1,   190] loss: 0.306162\n",
      "[1,   191] accuracy: (52.000, 100.000)\n",
      "[1,   191] loss: 0.257009\n",
      "[1,   192] accuracy: (44.000, 96.000)\n",
      "[1,   192] loss: 0.310295\n",
      "[1,   193] accuracy: (56.000, 96.000)\n",
      "[1,   193] loss: 0.333289\n",
      "[1,   194] accuracy: (36.000, 100.000)\n",
      "[1,   194] loss: 0.312716\n",
      "[1,   195] accuracy: (52.000, 84.000)\n",
      "[1,   195] loss: 0.401576\n",
      "[1,   196] accuracy: (44.000, 96.000)\n",
      "[1,   196] loss: 0.341758\n",
      "[1,   197] accuracy: (48.000, 96.000)\n",
      "[1,   197] loss: 0.361779\n",
      "[1,   198] accuracy: (40.000, 96.000)\n",
      "[1,   198] loss: 0.390060\n",
      "[1,   199] accuracy: (56.000, 96.000)\n",
      "[1,   199] loss: 0.265821\n",
      "[1,   200] accuracy: (56.000, 92.000)\n",
      "[1,   200] loss: 0.299063\n",
      "[1,   201] accuracy: (44.000, 96.000)\n",
      "[1,   201] loss: 0.367381\n",
      "[1,   202] accuracy: (52.000, 100.000)\n",
      "[1,   202] loss: 0.419840\n",
      "[1,   203] accuracy: (40.000, 96.000)\n",
      "[1,   203] loss: 0.336184\n",
      "[1,   204] accuracy: (36.000, 96.000)\n",
      "[1,   204] loss: 0.332054\n",
      "[1,   205] accuracy: (48.000, 92.000)\n",
      "[1,   205] loss: 0.334244\n",
      "[1,   206] accuracy: (44.000, 96.000)\n",
      "[1,   206] loss: 0.302330\n",
      "[1,   207] accuracy: (56.000, 96.000)\n",
      "[1,   207] loss: 0.333000\n",
      "[1,   208] accuracy: (48.000, 96.000)\n",
      "[1,   208] loss: 0.313327\n",
      "[1,   209] accuracy: (52.000, 96.000)\n",
      "[1,   209] loss: 0.335111\n",
      "[1,   210] accuracy: (76.000, 88.000)\n",
      "[1,   210] loss: 0.296730\n",
      "[1,   211] accuracy: (44.000, 88.000)\n",
      "[1,   211] loss: 0.356818\n",
      "[1,   212] accuracy: (52.000, 100.000)\n",
      "[1,   212] loss: 0.272208\n",
      "[1,   213] accuracy: (52.000, 100.000)\n",
      "[1,   213] loss: 0.344797\n",
      "[1,   214] accuracy: (52.000, 88.000)\n",
      "[1,   214] loss: 0.304433\n",
      "[1,   215] accuracy: (36.000, 88.000)\n",
      "[1,   215] loss: 0.345024\n",
      "[1,   216] accuracy: (48.000, 100.000)\n",
      "[1,   216] loss: 0.285534\n",
      "[1,   217] accuracy: (44.000, 100.000)\n",
      "[1,   217] loss: 0.316305\n",
      "[1,   218] accuracy: (28.000, 88.000)\n",
      "[1,   218] loss: 0.391729\n",
      "[1,   219] accuracy: (56.000, 100.000)\n",
      "[1,   219] loss: 0.299224\n",
      "[1,   220] accuracy: (60.000, 96.000)\n",
      "[1,   220] loss: 0.304241\n",
      "[1,   221] accuracy: (56.000, 100.000)\n",
      "[1,   221] loss: 0.280942\n",
      "[1,   222] accuracy: (36.000, 96.000)\n",
      "[1,   222] loss: 0.403942\n",
      "[1,   223] accuracy: (44.000, 88.000)\n",
      "[1,   223] loss: 0.316067\n",
      "[1,   224] accuracy: (48.000, 88.000)\n",
      "[1,   224] loss: 0.433008\n",
      "[1,   225] accuracy: (48.000, 100.000)\n",
      "[1,   225] loss: 0.267538\n",
      "[1,   226] accuracy: (44.000, 92.000)\n",
      "[1,   226] loss: 0.359503\n",
      "[1,   227] accuracy: (48.000, 92.000)\n",
      "[1,   227] loss: 0.332944\n",
      "[1,   228] accuracy: (40.000, 92.000)\n",
      "[1,   228] loss: 0.390721\n",
      "[1,   229] accuracy: (56.000, 96.000)\n",
      "[1,   229] loss: 0.240892\n",
      "[1,   230] accuracy: (44.000, 100.000)\n",
      "[1,   230] loss: 0.277671\n",
      "[1,   231] accuracy: (36.000, 100.000)\n",
      "[1,   231] loss: 0.378562\n",
      "[1,   232] accuracy: (20.000, 92.000)\n",
      "[1,   232] loss: 0.466685\n",
      "[1,   233] accuracy: (60.000, 96.000)\n",
      "[1,   233] loss: 0.319402\n",
      "[1,   234] accuracy: (52.000, 100.000)\n",
      "[1,   234] loss: 0.270750\n",
      "[1,   235] accuracy: (64.000, 92.000)\n",
      "[1,   235] loss: 0.315858\n",
      "[1,   236] accuracy: (48.000, 92.000)\n",
      "[1,   236] loss: 0.407616\n",
      "[1,   237] accuracy: (32.000, 100.000)\n",
      "[1,   237] loss: 0.298620\n",
      "[1,   238] accuracy: (52.000, 96.000)\n",
      "[1,   238] loss: 0.306299\n",
      "[1,   239] accuracy: (40.000, 88.000)\n",
      "[1,   239] loss: 0.340046\n",
      "[1,   240] accuracy: (60.000, 100.000)\n",
      "[1,   240] loss: 0.268250\n",
      "[1,   241] accuracy: (32.000, 100.000)\n",
      "[1,   241] loss: 0.449184\n",
      "[1,   242] accuracy: (56.000, 96.000)\n",
      "[1,   242] loss: 0.259706\n",
      "[1,   243] accuracy: (40.000, 88.000)\n",
      "[1,   243] loss: 0.367595\n",
      "[1,   244] accuracy: (24.000, 92.000)\n",
      "[1,   244] loss: 0.512370\n",
      "[1,   245] accuracy: (48.000, 92.000)\n",
      "[1,   245] loss: 0.391972\n",
      "[1,   246] accuracy: (56.000, 92.000)\n",
      "[1,   246] loss: 0.371172\n",
      "[1,   247] accuracy: (48.000, 88.000)\n",
      "[1,   247] loss: 0.305654\n",
      "[1,   248] accuracy: (40.000, 80.000)\n",
      "[1,   248] loss: 0.446973\n",
      "[1,   249] accuracy: (28.000, 96.000)\n",
      "[1,   249] loss: 0.349834\n",
      "[1,   250] accuracy: (56.000, 100.000)\n",
      "[1,   250] loss: 0.302390\n",
      "[1,   251] accuracy: (36.000, 96.000)\n",
      "[1,   251] loss: 0.479490\n",
      "[1,   252] accuracy: (40.000, 100.000)\n",
      "[1,   252] loss: 0.283947\n",
      "[1,   253] accuracy: (28.000, 96.000)\n",
      "[1,   253] loss: 0.408341\n",
      "[1,   254] accuracy: (60.000, 92.000)\n",
      "[1,   254] loss: 0.309721\n",
      "[1,   255] accuracy: (52.000, 100.000)\n",
      "[1,   255] loss: 0.273641\n",
      "[1,   256] accuracy: (48.000, 96.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   256] loss: 0.312985\n",
      "[1,   257] accuracy: (40.000, 100.000)\n",
      "[1,   257] loss: 0.318875\n",
      "[1,   258] accuracy: (32.000, 100.000)\n",
      "[1,   258] loss: 0.334218\n",
      "[1,   259] accuracy: (36.000, 92.000)\n",
      "[1,   259] loss: 0.410454\n",
      "[1,   260] accuracy: (48.000, 96.000)\n",
      "[1,   260] loss: 0.327219\n",
      "[1,   261] accuracy: (56.000, 96.000)\n",
      "[1,   261] loss: 0.314524\n",
      "[1,   262] accuracy: (44.000, 96.000)\n",
      "[1,   262] loss: 0.442953\n",
      "[1,   263] accuracy: (52.000, 88.000)\n",
      "[1,   263] loss: 0.436650\n",
      "[1,   264] accuracy: (40.000, 92.000)\n",
      "[1,   264] loss: 0.319648\n",
      "[1,   265] accuracy: (60.000, 100.000)\n",
      "[1,   265] loss: 0.296856\n",
      "[1,   266] accuracy: (48.000, 96.000)\n",
      "[1,   266] loss: 0.321136\n",
      "[1,   267] accuracy: (44.000, 96.000)\n",
      "[1,   267] loss: 0.476226\n",
      "[1,   268] accuracy: (44.000, 92.000)\n",
      "[1,   268] loss: 0.393263\n",
      "[1,   269] accuracy: (36.000, 100.000)\n",
      "[1,   269] loss: 0.299720\n",
      "[1,   270] accuracy: (56.000, 100.000)\n",
      "[1,   270] loss: 0.269755\n",
      "[1,   271] accuracy: (48.000, 92.000)\n",
      "[1,   271] loss: 0.362542\n",
      "[1,   272] accuracy: (40.000, 100.000)\n",
      "[1,   272] loss: 0.338506\n",
      "[1,   273] accuracy: (36.000, 96.000)\n",
      "[1,   273] loss: 0.282877\n",
      "[1,   274] accuracy: (44.000, 96.000)\n",
      "[1,   274] loss: 0.409661\n",
      "[1,   275] accuracy: (40.000, 92.000)\n",
      "[1,   275] loss: 0.370632\n",
      "[1,   276] accuracy: (44.000, 96.000)\n",
      "[1,   276] loss: 0.279493\n",
      "[1,   277] accuracy: (52.000, 96.000)\n",
      "[1,   277] loss: 0.334238\n",
      "[1,   278] accuracy: (32.000, 100.000)\n",
      "[1,   278] loss: 0.281586\n",
      "[1,   279] accuracy: (40.000, 96.000)\n",
      "[1,   279] loss: 0.315369\n",
      "[1,   280] accuracy: (44.000, 96.000)\n",
      "[1,   280] loss: 0.329947\n",
      "[1,   281] accuracy: (48.000, 96.000)\n",
      "[1,   281] loss: 0.372846\n",
      "[1,   282] accuracy: (48.000, 96.000)\n",
      "[1,   282] loss: 0.344191\n",
      "[1,   283] accuracy: (44.000, 100.000)\n",
      "[1,   283] loss: 0.275981\n",
      "[1,   284] accuracy: (36.000, 92.000)\n",
      "[1,   284] loss: 0.364056\n",
      "[1,   285] accuracy: (56.000, 96.000)\n",
      "[1,   285] loss: 0.324392\n",
      "[1,   286] accuracy: (56.000, 100.000)\n",
      "[1,   286] loss: 0.312699\n",
      "[1,   287] accuracy: (44.000, 96.000)\n",
      "[1,   287] loss: 0.356969\n",
      "[1,   288] accuracy: (44.000, 100.000)\n",
      "[1,   288] loss: 0.291017\n",
      "[1,   289] accuracy: (48.000, 96.000)\n",
      "[1,   289] loss: 0.337771\n",
      "[1,   290] accuracy: (56.000, 100.000)\n",
      "[1,   290] loss: 0.233348\n",
      "[1,   291] accuracy: (28.000, 88.000)\n",
      "[1,   291] loss: 0.382757\n",
      "[1,   292] accuracy: (44.000, 92.000)\n",
      "[1,   292] loss: 0.369684\n",
      "[1,   293] accuracy: (48.000, 96.000)\n",
      "[1,   293] loss: 0.399243\n",
      "[1,   294] accuracy: (64.000, 92.000)\n",
      "[1,   294] loss: 0.381836\n",
      "[1,   295] accuracy: (52.000, 100.000)\n",
      "[1,   295] loss: 0.283751\n",
      "[1,   296] accuracy: (56.000, 96.000)\n",
      "[1,   296] loss: 0.325442\n",
      "[1,   297] accuracy: (56.000, 96.000)\n",
      "[1,   297] loss: 0.339474\n",
      "[1,   298] accuracy: (52.000, 96.000)\n",
      "[1,   298] loss: 0.371267\n",
      "[1,   299] accuracy: (56.000, 92.000)\n",
      "[1,   299] loss: 0.329627\n",
      "[1,   300] accuracy: (40.000, 88.000)\n",
      "[1,   300] loss: 0.350358\n",
      "[1,   301] accuracy: (44.000, 92.000)\n",
      "[1,   301] loss: 0.355294\n",
      "[1,   302] accuracy: (52.000, 88.000)\n",
      "[1,   302] loss: 0.424073\n",
      "[1,   303] accuracy: (48.000, 88.000)\n",
      "[1,   303] loss: 0.392263\n",
      "[1,   304] accuracy: (60.000, 96.000)\n",
      "[1,   304] loss: 0.248989\n",
      "[1,   305] accuracy: (52.000, 96.000)\n",
      "[1,   305] loss: 0.324035\n",
      "[1,   306] accuracy: (32.000, 88.000)\n",
      "[1,   306] loss: 0.544940\n",
      "[1,   307] accuracy: (52.000, 92.000)\n",
      "[1,   307] loss: 0.332926\n",
      "[1,   308] accuracy: (44.000, 96.000)\n",
      "[1,   308] loss: 0.316944\n",
      "[1,   309] accuracy: (48.000, 92.000)\n",
      "[1,   309] loss: 0.342335\n",
      "[1,   310] accuracy: (36.000, 96.000)\n",
      "[1,   310] loss: 0.425578\n",
      "[1,   311] accuracy: (32.000, 100.000)\n",
      "[1,   311] loss: 0.333603\n",
      "[1,   312] accuracy: (24.000, 100.000)\n",
      "[1,   312] loss: 0.389221\n",
      "[1,   313] accuracy: (44.000, 96.000)\n",
      "[1,   313] loss: 0.350040\n",
      "[1,   314] accuracy: (36.000, 88.000)\n",
      "[1,   314] loss: 0.346272\n",
      "[1,   315] accuracy: (36.000, 92.000)\n",
      "[1,   315] loss: 0.339167\n",
      "[1,   316] accuracy: (44.000, 96.000)\n",
      "[1,   316] loss: 0.291371\n",
      "[1,   317] accuracy: (52.000, 92.000)\n",
      "[1,   317] loss: 0.256152\n",
      "[1,   318] accuracy: (52.000, 100.000)\n",
      "[1,   318] loss: 0.280891\n",
      "[1,   319] accuracy: (68.000, 100.000)\n",
      "[1,   319] loss: 0.282779\n",
      "[1,   320] accuracy: (44.000, 92.000)\n",
      "[1,   320] loss: 0.355299\n",
      "[1,   321] accuracy: (48.000, 92.000)\n",
      "[1,   321] loss: 0.401884\n",
      "[1,   322] accuracy: (44.000, 96.000)\n",
      "[1,   322] loss: 0.298839\n",
      "[1,   323] accuracy: (68.000, 88.000)\n",
      "[1,   323] loss: 0.247501\n",
      "[1,   324] accuracy: (44.000, 100.000)\n",
      "[1,   324] loss: 0.339812\n",
      "[1,   325] accuracy: (44.000, 88.000)\n",
      "[1,   325] loss: 0.382435\n",
      "[1,   326] accuracy: (56.000, 92.000)\n",
      "[1,   326] loss: 0.295048\n",
      "[1,   327] accuracy: (44.000, 92.000)\n",
      "[1,   327] loss: 0.329494\n",
      "[1,   328] accuracy: (68.000, 100.000)\n",
      "[1,   328] loss: 0.274685\n",
      "[1,   329] accuracy: (48.000, 92.000)\n",
      "[1,   329] loss: 0.375326\n",
      "[1,   330] accuracy: (48.000, 100.000)\n",
      "[1,   330] loss: 0.287684\n",
      "[1,   331] accuracy: (52.000, 96.000)\n",
      "[1,   331] loss: 0.240707\n",
      "[1,   332] accuracy: (24.000, 96.000)\n",
      "[1,   332] loss: 0.484029\n",
      "[1,   333] accuracy: (48.000, 96.000)\n",
      "[1,   333] loss: 0.401805\n",
      "[1,   334] accuracy: (40.000, 92.000)\n",
      "[1,   334] loss: 0.294800\n",
      "[1,   335] accuracy: (44.000, 84.000)\n",
      "[1,   335] loss: 0.393322\n",
      "[1,   336] accuracy: (44.000, 92.000)\n",
      "[1,   336] loss: 0.349154\n",
      "[1,   337] accuracy: (52.000, 96.000)\n",
      "[1,   337] loss: 0.274941\n",
      "[1,   338] accuracy: (40.000, 92.000)\n",
      "[1,   338] loss: 0.413407\n",
      "[1,   339] accuracy: (44.000, 96.000)\n",
      "[1,   339] loss: 0.321851\n",
      "[1,   340] accuracy: (36.000, 80.000)\n",
      "[1,   340] loss: 0.367211\n",
      "[1,   341] accuracy: (44.000, 96.000)\n",
      "[1,   341] loss: 0.395311\n",
      "[1,   342] accuracy: (28.000, 100.000)\n",
      "[1,   342] loss: 0.390355\n",
      "[1,   343] accuracy: (60.000, 96.000)\n",
      "[1,   343] loss: 0.303157\n",
      "[1,   344] accuracy: (24.000, 96.000)\n",
      "[1,   344] loss: 0.362653\n",
      "[1,   345] accuracy: (60.000, 100.000)\n",
      "[1,   345] loss: 0.254058\n",
      "[1,   346] accuracy: (44.000, 100.000)\n",
      "[1,   346] loss: 0.371107\n",
      "[1,   347] accuracy: (40.000, 100.000)\n",
      "[1,   347] loss: 0.258286\n",
      "[1,   348] accuracy: (44.000, 96.000)\n",
      "[1,   348] loss: 0.338502\n",
      "[1,   349] accuracy: (52.000, 100.000)\n",
      "[1,   349] loss: 0.278123\n",
      "[1,   350] accuracy: (68.000, 96.000)\n",
      "[1,   350] loss: 0.283248\n",
      "[1,   351] accuracy: (48.000, 96.000)\n",
      "[1,   351] loss: 0.301703\n",
      "[1,   352] accuracy: (48.000, 96.000)\n",
      "[1,   352] loss: 0.329420\n",
      "[1,   353] accuracy: (56.000, 100.000)\n",
      "[1,   353] loss: 0.270290\n",
      "[1,   354] accuracy: (40.000, 92.000)\n",
      "[1,   354] loss: 0.317880\n",
      "[1,   355] accuracy: (32.000, 100.000)\n",
      "[1,   355] loss: 0.340320\n",
      "[1,   356] accuracy: (52.000, 96.000)\n",
      "[1,   356] loss: 0.271528\n",
      "[1,   357] accuracy: (32.000, 100.000)\n",
      "[1,   357] loss: 0.354235\n",
      "[1,   358] accuracy: (56.000, 96.000)\n",
      "[1,   358] loss: 0.257805\n",
      "[1,   359] accuracy: (56.000, 96.000)\n",
      "[1,   359] loss: 0.242239\n",
      "[1,   360] accuracy: (28.000, 100.000)\n",
      "[1,   360] loss: 0.310886\n",
      "[1,   361] accuracy: (60.000, 100.000)\n",
      "[1,   361] loss: 0.281717\n",
      "[1,   362] accuracy: (56.000, 100.000)\n",
      "[1,   362] loss: 0.263960\n",
      "[1,   363] accuracy: (52.000, 100.000)\n",
      "[1,   363] loss: 0.336989\n",
      "[1,   364] accuracy: (52.000, 100.000)\n",
      "[1,   364] loss: 0.254319\n",
      "[1,   365] accuracy: (48.000, 100.000)\n",
      "[1,   365] loss: 0.333076\n",
      "[1,   366] accuracy: (48.000, 92.000)\n",
      "[1,   366] loss: 0.281462\n",
      "[1,   367] accuracy: (60.000, 100.000)\n",
      "[1,   367] loss: 0.321759\n",
      "[1,   368] accuracy: (64.000, 96.000)\n",
      "[1,   368] loss: 0.308668\n",
      "[1,   369] accuracy: (56.000, 96.000)\n",
      "[1,   369] loss: 0.269977\n",
      "[1,   370] accuracy: (48.000, 96.000)\n",
      "[1,   370] loss: 0.388752\n",
      "[1,   371] accuracy: (60.000, 96.000)\n",
      "[1,   371] loss: 0.303461\n",
      "[1,   372] accuracy: (64.000, 100.000)\n",
      "[1,   372] loss: 0.294734\n",
      "[1,   373] accuracy: (40.000, 96.000)\n",
      "[1,   373] loss: 0.299693\n",
      "[1,   374] accuracy: (48.000, 100.000)\n",
      "[1,   374] loss: 0.281156\n",
      "[1,   375] accuracy: (40.000, 96.000)\n",
      "[1,   375] loss: 0.299708\n",
      "[1,   376] accuracy: (68.000, 100.000)\n",
      "[1,   376] loss: 0.234009\n",
      "[1,   377] accuracy: (56.000, 100.000)\n",
      "[1,   377] loss: 0.322424\n",
      "[1,   378] accuracy: (48.000, 100.000)\n",
      "[1,   378] loss: 0.325247\n",
      "[1,   379] accuracy: (60.000, 96.000)\n",
      "[1,   379] loss: 0.284512\n",
      "[1,   380] accuracy: (40.000, 100.000)\n",
      "[1,   380] loss: 0.377366\n",
      "[1,   381] accuracy: (52.000, 100.000)\n",
      "[1,   381] loss: 0.316058\n",
      "[1,   382] accuracy: (44.000, 92.000)\n",
      "[1,   382] loss: 0.301309\n",
      "[1,   383] accuracy: (44.000, 88.000)\n",
      "[1,   383] loss: 0.361910\n",
      "[1,   384] accuracy: (52.000, 88.000)\n",
      "[1,   384] loss: 0.380794\n",
      "[1,   385] accuracy: (40.000, 100.000)\n",
      "[1,   385] loss: 0.262402\n",
      "[1,   386] accuracy: (32.000, 100.000)\n",
      "[1,   386] loss: 0.349775\n",
      "[1,   387] accuracy: (44.000, 100.000)\n",
      "[1,   387] loss: 0.342271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   388] accuracy: (44.000, 96.000)\n",
      "[1,   388] loss: 0.389356\n",
      "[1,   389] accuracy: (48.000, 96.000)\n",
      "[1,   389] loss: 0.350460\n",
      "[1,   390] accuracy: (24.000, 88.000)\n",
      "[1,   390] loss: 0.431381\n",
      "[1,   391] accuracy: (37.500, 100.000)\n",
      "[1,   391] loss: 0.326515\n",
      "COMPLETED EPOCH 0001... checkpointing here\n",
      "[2,     1] accuracy: (40.000, 100.000)\n",
      "[2,     1] loss: 0.352001\n",
      "[2,     2] accuracy: (52.000, 100.000)\n",
      "[2,     2] loss: 0.255962\n",
      "[2,     3] accuracy: (40.000, 88.000)\n",
      "[2,     3] loss: 0.378638\n",
      "[2,     4] accuracy: (60.000, 96.000)\n",
      "[2,     4] loss: 0.295902\n",
      "[2,     5] accuracy: (28.000, 96.000)\n",
      "[2,     5] loss: 0.364539\n",
      "[2,     6] accuracy: (40.000, 92.000)\n",
      "[2,     6] loss: 0.297084\n",
      "[2,     7] accuracy: (44.000, 92.000)\n",
      "[2,     7] loss: 0.330333\n",
      "[2,     8] accuracy: (56.000, 96.000)\n",
      "[2,     8] loss: 0.417643\n",
      "[2,     9] accuracy: (36.000, 92.000)\n",
      "[2,     9] loss: 0.377433\n",
      "[2,    10] accuracy: (52.000, 100.000)\n",
      "[2,    10] loss: 0.321050\n",
      "[2,    11] accuracy: (44.000, 96.000)\n",
      "[2,    11] loss: 0.332834\n",
      "[2,    12] accuracy: (48.000, 100.000)\n",
      "[2,    12] loss: 0.329275\n",
      "[2,    13] accuracy: (44.000, 92.000)\n",
      "[2,    13] loss: 0.336648\n",
      "[2,    14] accuracy: (40.000, 100.000)\n",
      "[2,    14] loss: 0.288322\n",
      "[2,    15] accuracy: (36.000, 92.000)\n",
      "[2,    15] loss: 0.413141\n",
      "[2,    16] accuracy: (52.000, 96.000)\n",
      "[2,    16] loss: 0.289779\n",
      "[2,    17] accuracy: (48.000, 92.000)\n",
      "[2,    17] loss: 0.258901\n",
      "[2,    18] accuracy: (44.000, 96.000)\n",
      "[2,    18] loss: 0.273698\n",
      "[2,    19] accuracy: (52.000, 92.000)\n",
      "[2,    19] loss: 0.229217\n",
      "[2,    20] accuracy: (56.000, 100.000)\n",
      "[2,    20] loss: 0.314959\n",
      "[2,    21] accuracy: (68.000, 100.000)\n",
      "[2,    21] loss: 0.277288\n",
      "[2,    22] accuracy: (48.000, 100.000)\n",
      "[2,    22] loss: 0.341802\n",
      "[2,    23] accuracy: (72.000, 96.000)\n",
      "[2,    23] loss: 0.267823\n",
      "[2,    24] accuracy: (48.000, 100.000)\n",
      "[2,    24] loss: 0.334491\n",
      "[2,    25] accuracy: (60.000, 100.000)\n",
      "[2,    25] loss: 0.253435\n",
      "[2,    26] accuracy: (36.000, 100.000)\n",
      "[2,    26] loss: 0.350642\n",
      "[2,    27] accuracy: (56.000, 96.000)\n",
      "[2,    27] loss: 0.264945\n",
      "[2,    28] accuracy: (28.000, 92.000)\n",
      "[2,    28] loss: 0.377627\n",
      "[2,    29] accuracy: (44.000, 100.000)\n",
      "[2,    29] loss: 0.357549\n",
      "[2,    30] accuracy: (56.000, 96.000)\n",
      "[2,    30] loss: 0.291032\n",
      "[2,    31] accuracy: (36.000, 100.000)\n",
      "[2,    31] loss: 0.323934\n",
      "[2,    32] accuracy: (60.000, 100.000)\n",
      "[2,    32] loss: 0.302313\n",
      "[2,    33] accuracy: (44.000, 84.000)\n",
      "[2,    33] loss: 0.394963\n",
      "[2,    34] accuracy: (44.000, 96.000)\n",
      "[2,    34] loss: 0.399392\n",
      "[2,    35] accuracy: (48.000, 92.000)\n",
      "[2,    35] loss: 0.360994\n",
      "[2,    36] accuracy: (48.000, 96.000)\n",
      "[2,    36] loss: 0.353434\n",
      "[2,    37] accuracy: (40.000, 100.000)\n",
      "[2,    37] loss: 0.281819\n",
      "[2,    38] accuracy: (52.000, 100.000)\n",
      "[2,    38] loss: 0.252268\n",
      "[2,    39] accuracy: (48.000, 92.000)\n",
      "[2,    39] loss: 0.373698\n",
      "[2,    40] accuracy: (56.000, 96.000)\n",
      "[2,    40] loss: 0.268449\n",
      "[2,    41] accuracy: (36.000, 92.000)\n",
      "[2,    41] loss: 0.355132\n",
      "[2,    42] accuracy: (48.000, 92.000)\n",
      "[2,    42] loss: 0.300456\n",
      "[2,    43] accuracy: (28.000, 92.000)\n",
      "[2,    43] loss: 0.311889\n",
      "[2,    44] accuracy: (52.000, 100.000)\n",
      "[2,    44] loss: 0.296941\n",
      "[2,    45] accuracy: (56.000, 96.000)\n",
      "[2,    45] loss: 0.350145\n",
      "[2,    46] accuracy: (48.000, 96.000)\n",
      "[2,    46] loss: 0.371545\n",
      "[2,    47] accuracy: (60.000, 92.000)\n",
      "[2,    47] loss: 0.340202\n",
      "[2,    48] accuracy: (52.000, 96.000)\n",
      "[2,    48] loss: 0.352767\n",
      "[2,    49] accuracy: (40.000, 96.000)\n",
      "[2,    49] loss: 0.304255\n",
      "[2,    50] accuracy: (48.000, 100.000)\n",
      "[2,    50] loss: 0.403616\n",
      "[2,    51] accuracy: (52.000, 96.000)\n",
      "[2,    51] loss: 0.319132\n",
      "[2,    52] accuracy: (48.000, 96.000)\n",
      "[2,    52] loss: 0.258570\n",
      "[2,    53] accuracy: (52.000, 100.000)\n",
      "[2,    53] loss: 0.288559\n",
      "[2,    54] accuracy: (52.000, 96.000)\n",
      "[2,    54] loss: 0.355508\n",
      "[2,    55] accuracy: (40.000, 88.000)\n",
      "[2,    55] loss: 0.437633\n",
      "[2,    56] accuracy: (60.000, 96.000)\n",
      "[2,    56] loss: 0.302023\n",
      "[2,    57] accuracy: (56.000, 100.000)\n",
      "[2,    57] loss: 0.304707\n",
      "[2,    58] accuracy: (28.000, 88.000)\n",
      "[2,    58] loss: 0.365926\n",
      "[2,    59] accuracy: (56.000, 96.000)\n",
      "[2,    59] loss: 0.294658\n",
      "[2,    60] accuracy: (48.000, 100.000)\n",
      "[2,    60] loss: 0.284686\n",
      "[2,    61] accuracy: (48.000, 100.000)\n",
      "[2,    61] loss: 0.238084\n",
      "[2,    62] accuracy: (52.000, 96.000)\n",
      "[2,    62] loss: 0.292033\n",
      "[2,    63] accuracy: (44.000, 100.000)\n",
      "[2,    63] loss: 0.361026\n",
      "[2,    64] accuracy: (56.000, 100.000)\n",
      "[2,    64] loss: 0.292524\n",
      "[2,    65] accuracy: (44.000, 96.000)\n",
      "[2,    65] loss: 0.382593\n",
      "[2,    66] accuracy: (52.000, 92.000)\n",
      "[2,    66] loss: 0.349436\n",
      "[2,    67] accuracy: (48.000, 96.000)\n",
      "[2,    67] loss: 0.274558\n",
      "[2,    68] accuracy: (40.000, 96.000)\n",
      "[2,    68] loss: 0.301604\n",
      "[2,    69] accuracy: (52.000, 100.000)\n",
      "[2,    69] loss: 0.267764\n",
      "[2,    70] accuracy: (44.000, 88.000)\n",
      "[2,    70] loss: 0.375351\n",
      "[2,    71] accuracy: (40.000, 92.000)\n",
      "[2,    71] loss: 0.314506\n",
      "[2,    72] accuracy: (48.000, 100.000)\n",
      "[2,    72] loss: 0.260559\n",
      "[2,    73] accuracy: (48.000, 84.000)\n",
      "[2,    73] loss: 0.319624\n",
      "[2,    74] accuracy: (52.000, 92.000)\n",
      "[2,    74] loss: 0.310191\n",
      "[2,    75] accuracy: (20.000, 92.000)\n",
      "[2,    75] loss: 0.491867\n",
      "[2,    76] accuracy: (36.000, 96.000)\n",
      "[2,    76] loss: 0.411136\n",
      "[2,    77] accuracy: (36.000, 92.000)\n",
      "[2,    77] loss: 0.326077\n",
      "[2,    78] accuracy: (32.000, 92.000)\n",
      "[2,    78] loss: 0.334507\n",
      "[2,    79] accuracy: (40.000, 96.000)\n",
      "[2,    79] loss: 0.330574\n",
      "[2,    80] accuracy: (32.000, 92.000)\n",
      "[2,    80] loss: 0.310578\n",
      "[2,    81] accuracy: (56.000, 100.000)\n",
      "[2,    81] loss: 0.294140\n",
      "[2,    82] accuracy: (48.000, 92.000)\n",
      "[2,    82] loss: 0.347703\n",
      "[2,    83] accuracy: (48.000, 96.000)\n",
      "[2,    83] loss: 0.329951\n",
      "[2,    84] accuracy: (24.000, 96.000)\n",
      "[2,    84] loss: 0.411237\n",
      "[2,    85] accuracy: (44.000, 96.000)\n",
      "[2,    85] loss: 0.349149\n",
      "[2,    86] accuracy: (52.000, 96.000)\n",
      "[2,    86] loss: 0.357266\n",
      "[2,    87] accuracy: (56.000, 100.000)\n",
      "[2,    87] loss: 0.376455\n",
      "[2,    88] accuracy: (36.000, 100.000)\n",
      "[2,    88] loss: 0.374074\n",
      "[2,    89] accuracy: (48.000, 96.000)\n",
      "[2,    89] loss: 0.278969\n",
      "[2,    90] accuracy: (56.000, 100.000)\n",
      "[2,    90] loss: 0.272660\n",
      "[2,    91] accuracy: (64.000, 100.000)\n",
      "[2,    91] loss: 0.291740\n",
      "[2,    92] accuracy: (44.000, 96.000)\n",
      "[2,    92] loss: 0.311224\n",
      "[2,    93] accuracy: (60.000, 92.000)\n",
      "[2,    93] loss: 0.296200\n",
      "[2,    94] accuracy: (56.000, 96.000)\n",
      "[2,    94] loss: 0.309951\n",
      "[2,    95] accuracy: (64.000, 92.000)\n",
      "[2,    95] loss: 0.295660\n",
      "[2,    96] accuracy: (40.000, 96.000)\n",
      "[2,    96] loss: 0.305812\n",
      "[2,    97] accuracy: (56.000, 100.000)\n",
      "[2,    97] loss: 0.276397\n",
      "[2,    98] accuracy: (48.000, 100.000)\n",
      "[2,    98] loss: 0.347914\n",
      "[2,    99] accuracy: (52.000, 92.000)\n",
      "[2,    99] loss: 0.312882\n",
      "[2,   100] accuracy: (52.000, 96.000)\n",
      "[2,   100] loss: 0.338595\n",
      "[2,   101] accuracy: (64.000, 92.000)\n",
      "[2,   101] loss: 0.340286\n",
      "[2,   102] accuracy: (48.000, 88.000)\n",
      "[2,   102] loss: 0.376260\n",
      "[2,   103] accuracy: (60.000, 96.000)\n",
      "[2,   103] loss: 0.331674\n",
      "[2,   104] accuracy: (76.000, 96.000)\n",
      "[2,   104] loss: 0.319985\n",
      "[2,   105] accuracy: (44.000, 100.000)\n",
      "[2,   105] loss: 0.377684\n",
      "[2,   106] accuracy: (52.000, 100.000)\n",
      "[2,   106] loss: 0.281876\n",
      "[2,   107] accuracy: (44.000, 100.000)\n",
      "[2,   107] loss: 0.362172\n",
      "[2,   108] accuracy: (40.000, 96.000)\n",
      "[2,   108] loss: 0.309339\n",
      "[2,   109] accuracy: (48.000, 100.000)\n",
      "[2,   109] loss: 0.336794\n",
      "[2,   110] accuracy: (48.000, 92.000)\n",
      "[2,   110] loss: 0.432618\n",
      "[2,   111] accuracy: (40.000, 96.000)\n",
      "[2,   111] loss: 0.331360\n",
      "[2,   112] accuracy: (60.000, 100.000)\n",
      "[2,   112] loss: 0.236733\n",
      "[2,   113] accuracy: (40.000, 88.000)\n",
      "[2,   113] loss: 0.373078\n",
      "[2,   114] accuracy: (56.000, 100.000)\n",
      "[2,   114] loss: 0.352719\n",
      "[2,   115] accuracy: (52.000, 96.000)\n",
      "[2,   115] loss: 0.361840\n",
      "[2,   116] accuracy: (64.000, 92.000)\n",
      "[2,   116] loss: 0.267083\n",
      "[2,   117] accuracy: (40.000, 88.000)\n",
      "[2,   117] loss: 0.379223\n",
      "[2,   118] accuracy: (52.000, 92.000)\n",
      "[2,   118] loss: 0.282785\n",
      "[2,   119] accuracy: (36.000, 96.000)\n",
      "[2,   119] loss: 0.346162\n",
      "[2,   120] accuracy: (52.000, 92.000)\n",
      "[2,   120] loss: 0.288916\n",
      "[2,   121] accuracy: (56.000, 100.000)\n",
      "[2,   121] loss: 0.321025\n",
      "[2,   122] accuracy: (40.000, 100.000)\n",
      "[2,   122] loss: 0.293744\n",
      "[2,   123] accuracy: (60.000, 100.000)\n",
      "[2,   123] loss: 0.231074\n",
      "[2,   124] accuracy: (60.000, 84.000)\n",
      "[2,   124] loss: 0.322037\n",
      "[2,   125] accuracy: (40.000, 100.000)\n",
      "[2,   125] loss: 0.330865\n",
      "[2,   126] accuracy: (48.000, 100.000)\n",
      "[2,   126] loss: 0.284583\n",
      "[2,   127] accuracy: (60.000, 96.000)\n",
      "[2,   127] loss: 0.246089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   128] accuracy: (56.000, 100.000)\n",
      "[2,   128] loss: 0.270638\n",
      "[2,   129] accuracy: (36.000, 100.000)\n",
      "[2,   129] loss: 0.329888\n",
      "[2,   130] accuracy: (24.000, 96.000)\n",
      "[2,   130] loss: 0.318928\n",
      "[2,   131] accuracy: (28.000, 100.000)\n",
      "[2,   131] loss: 0.352655\n",
      "[2,   132] accuracy: (64.000, 96.000)\n",
      "[2,   132] loss: 0.336952\n",
      "[2,   133] accuracy: (40.000, 88.000)\n",
      "[2,   133] loss: 0.398387\n",
      "[2,   134] accuracy: (56.000, 92.000)\n",
      "[2,   134] loss: 0.375803\n",
      "[2,   135] accuracy: (28.000, 92.000)\n",
      "[2,   135] loss: 0.401924\n",
      "[2,   136] accuracy: (44.000, 100.000)\n",
      "[2,   136] loss: 0.376128\n",
      "[2,   137] accuracy: (56.000, 96.000)\n",
      "[2,   137] loss: 0.296430\n",
      "[2,   138] accuracy: (56.000, 100.000)\n",
      "[2,   138] loss: 0.316026\n",
      "[2,   139] accuracy: (48.000, 92.000)\n",
      "[2,   139] loss: 0.386375\n",
      "[2,   140] accuracy: (44.000, 96.000)\n",
      "[2,   140] loss: 0.325530\n",
      "[2,   141] accuracy: (64.000, 96.000)\n",
      "[2,   141] loss: 0.272427\n",
      "[2,   142] accuracy: (44.000, 88.000)\n",
      "[2,   142] loss: 0.393410\n",
      "[2,   143] accuracy: (56.000, 88.000)\n",
      "[2,   143] loss: 0.338915\n",
      "[2,   144] accuracy: (56.000, 96.000)\n",
      "[2,   144] loss: 0.312938\n",
      "[2,   145] accuracy: (56.000, 96.000)\n",
      "[2,   145] loss: 0.249083\n",
      "[2,   146] accuracy: (52.000, 100.000)\n",
      "[2,   146] loss: 0.335726\n",
      "[2,   147] accuracy: (40.000, 96.000)\n",
      "[2,   147] loss: 0.378475\n",
      "[2,   148] accuracy: (44.000, 96.000)\n",
      "[2,   148] loss: 0.361946\n",
      "[2,   149] accuracy: (52.000, 92.000)\n",
      "[2,   149] loss: 0.312107\n",
      "[2,   150] accuracy: (52.000, 100.000)\n",
      "[2,   150] loss: 0.197108\n",
      "[2,   151] accuracy: (44.000, 96.000)\n",
      "[2,   151] loss: 0.395299\n",
      "[2,   152] accuracy: (48.000, 100.000)\n",
      "[2,   152] loss: 0.304343\n",
      "[2,   153] accuracy: (60.000, 100.000)\n",
      "[2,   153] loss: 0.189531\n",
      "[2,   154] accuracy: (44.000, 92.000)\n",
      "[2,   154] loss: 0.317317\n",
      "[2,   155] accuracy: (56.000, 96.000)\n",
      "[2,   155] loss: 0.322484\n",
      "[2,   156] accuracy: (44.000, 92.000)\n",
      "[2,   156] loss: 0.342200\n",
      "[2,   157] accuracy: (64.000, 100.000)\n",
      "[2,   157] loss: 0.243441\n",
      "[2,   158] accuracy: (36.000, 96.000)\n",
      "[2,   158] loss: 0.273239\n",
      "[2,   159] accuracy: (56.000, 96.000)\n",
      "[2,   159] loss: 0.325695\n",
      "[2,   160] accuracy: (48.000, 96.000)\n",
      "[2,   160] loss: 0.360808\n",
      "[2,   161] accuracy: (44.000, 92.000)\n",
      "[2,   161] loss: 0.274929\n",
      "[2,   162] accuracy: (40.000, 92.000)\n",
      "[2,   162] loss: 0.342101\n",
      "[2,   163] accuracy: (60.000, 100.000)\n",
      "[2,   163] loss: 0.279844\n",
      "[2,   164] accuracy: (36.000, 100.000)\n",
      "[2,   164] loss: 0.284820\n",
      "[2,   165] accuracy: (52.000, 96.000)\n",
      "[2,   165] loss: 0.285838\n",
      "[2,   166] accuracy: (36.000, 96.000)\n",
      "[2,   166] loss: 0.297791\n",
      "[2,   167] accuracy: (48.000, 92.000)\n",
      "[2,   167] loss: 0.348251\n",
      "[2,   168] accuracy: (40.000, 92.000)\n",
      "[2,   168] loss: 0.390308\n",
      "[2,   169] accuracy: (48.000, 96.000)\n",
      "[2,   169] loss: 0.264049\n",
      "[2,   170] accuracy: (44.000, 92.000)\n",
      "[2,   170] loss: 0.368641\n",
      "[2,   171] accuracy: (48.000, 88.000)\n",
      "[2,   171] loss: 0.368610\n",
      "[2,   172] accuracy: (44.000, 96.000)\n",
      "[2,   172] loss: 0.340637\n",
      "[2,   173] accuracy: (36.000, 96.000)\n",
      "[2,   173] loss: 0.377517\n",
      "[2,   174] accuracy: (52.000, 100.000)\n",
      "[2,   174] loss: 0.348338\n",
      "[2,   175] accuracy: (48.000, 88.000)\n",
      "[2,   175] loss: 0.300303\n",
      "[2,   176] accuracy: (48.000, 96.000)\n",
      "[2,   176] loss: 0.288908\n",
      "[2,   177] accuracy: (60.000, 92.000)\n",
      "[2,   177] loss: 0.264428\n",
      "[2,   178] accuracy: (48.000, 100.000)\n",
      "[2,   178] loss: 0.337210\n",
      "[2,   179] accuracy: (52.000, 92.000)\n",
      "[2,   179] loss: 0.356835\n",
      "[2,   180] accuracy: (56.000, 96.000)\n",
      "[2,   180] loss: 0.389553\n",
      "[2,   181] accuracy: (48.000, 92.000)\n",
      "[2,   181] loss: 0.360262\n",
      "[2,   182] accuracy: (56.000, 88.000)\n",
      "[2,   182] loss: 0.392978\n",
      "[2,   183] accuracy: (24.000, 96.000)\n",
      "[2,   183] loss: 0.378394\n",
      "[2,   184] accuracy: (56.000, 96.000)\n",
      "[2,   184] loss: 0.287543\n",
      "[2,   185] accuracy: (56.000, 100.000)\n",
      "[2,   185] loss: 0.302303\n",
      "[2,   186] accuracy: (40.000, 96.000)\n",
      "[2,   186] loss: 0.328622\n",
      "[2,   187] accuracy: (40.000, 92.000)\n",
      "[2,   187] loss: 0.297176\n",
      "[2,   188] accuracy: (40.000, 88.000)\n",
      "[2,   188] loss: 0.336026\n",
      "[2,   189] accuracy: (40.000, 92.000)\n",
      "[2,   189] loss: 0.429743\n",
      "[2,   190] accuracy: (52.000, 96.000)\n",
      "[2,   190] loss: 0.276816\n",
      "[2,   191] accuracy: (56.000, 96.000)\n",
      "[2,   191] loss: 0.280310\n",
      "[2,   192] accuracy: (48.000, 96.000)\n",
      "[2,   192] loss: 0.338351\n",
      "[2,   193] accuracy: (56.000, 96.000)\n",
      "[2,   193] loss: 0.294446\n",
      "[2,   194] accuracy: (52.000, 96.000)\n",
      "[2,   194] loss: 0.339188\n",
      "[2,   195] accuracy: (44.000, 100.000)\n",
      "[2,   195] loss: 0.299539\n",
      "[2,   196] accuracy: (48.000, 96.000)\n",
      "[2,   196] loss: 0.319972\n",
      "[2,   197] accuracy: (40.000, 92.000)\n",
      "[2,   197] loss: 0.409926\n",
      "[2,   198] accuracy: (48.000, 96.000)\n",
      "[2,   198] loss: 0.312894\n",
      "[2,   199] accuracy: (40.000, 92.000)\n",
      "[2,   199] loss: 0.372608\n",
      "[2,   200] accuracy: (56.000, 96.000)\n",
      "[2,   200] loss: 0.363937\n",
      "[2,   201] accuracy: (48.000, 96.000)\n",
      "[2,   201] loss: 0.296241\n",
      "[2,   202] accuracy: (36.000, 100.000)\n",
      "[2,   202] loss: 0.403135\n",
      "[2,   203] accuracy: (60.000, 96.000)\n",
      "[2,   203] loss: 0.330818\n",
      "[2,   204] accuracy: (40.000, 96.000)\n",
      "[2,   204] loss: 0.340007\n",
      "[2,   205] accuracy: (56.000, 92.000)\n",
      "[2,   205] loss: 0.310122\n",
      "[2,   206] accuracy: (40.000, 96.000)\n",
      "[2,   206] loss: 0.292429\n",
      "[2,   207] accuracy: (44.000, 96.000)\n",
      "[2,   207] loss: 0.322655\n",
      "[2,   208] accuracy: (60.000, 96.000)\n",
      "[2,   208] loss: 0.272812\n",
      "[2,   209] accuracy: (56.000, 100.000)\n",
      "[2,   209] loss: 0.275857\n",
      "[2,   210] accuracy: (40.000, 96.000)\n",
      "[2,   210] loss: 0.364920\n",
      "[2,   211] accuracy: (56.000, 100.000)\n",
      "[2,   211] loss: 0.225007\n",
      "[2,   212] accuracy: (52.000, 100.000)\n",
      "[2,   212] loss: 0.342400\n",
      "[2,   213] accuracy: (56.000, 100.000)\n",
      "[2,   213] loss: 0.285479\n",
      "[2,   214] accuracy: (48.000, 100.000)\n",
      "[2,   214] loss: 0.304933\n",
      "[2,   215] accuracy: (48.000, 92.000)\n",
      "[2,   215] loss: 0.291535\n",
      "[2,   216] accuracy: (40.000, 100.000)\n",
      "[2,   216] loss: 0.347117\n",
      "[2,   217] accuracy: (60.000, 96.000)\n",
      "[2,   217] loss: 0.298516\n",
      "[2,   218] accuracy: (48.000, 92.000)\n",
      "[2,   218] loss: 0.414012\n",
      "[2,   219] accuracy: (32.000, 96.000)\n",
      "[2,   219] loss: 0.353633\n",
      "[2,   220] accuracy: (48.000, 100.000)\n"
     ]
    }
   ],
   "source": [
    "train_loss = nn.CrossEntropyLoss() # just use standard XEntropy to train\n",
    "training_logger = training_obj.train(cifar_trainset, 2, train_loss, \n",
    "                                     attack_parameters=attack_params, \n",
    "                                     verbosity='snoop', loglevel='snoop') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printouts look like:\n",
    "``` \n",
    "[epoch_no, minibatch_no] accuracy: (X, Y) \n",
    "[epoch_no, minibatch_no] loss: Z\n",
    "```\n",
    "\n",
    "- X is the percent of successfully classified *adversarial* examples generated from that minibatch only\n",
    "- Y is the percent of successfully classified *original* examples on that minibatch only\n",
    "- Z is the value of the loss function after that minibatch\n",
    "\n",
    "The output of training is a `TrainingLogger` class that stores essentially what was printed, and is separately controlled by its own `loglevel` argument. This can be accessed (and just to be safe, sorted using `sort_series`) and plotted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(training_logger.sort_series('training_loss', return_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot adversarial accuracy as we train \n",
    "# This should be noisy, but generally going UP\n",
    "plt.plot([_[0] for _ in training_logger.sort_series('attack', return_keys=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training completes, you can verify that the checkpoints are indeed stored in wherever you have set up pretrained models to be stored. By default this is `mister_ed/pretrained_models/`, so you should have a `tutorial_fgsm.resnet20.000002.path.tar` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restarting from Checkpoint\n",
    "When training, sometimes @#\\$& happens and things break. This is why we checkpoint. Here we'll show how to restart from checkpoint in training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to pick back up from where we left off with the experiment/architecture pair defined above `(tutorial_fgsm, resnet20)`. Then we want to do the following steps:\n",
    "\n",
    "1. Instantiate a model of the same architecture (weights don't matter, since we'll load from the checkpoint) \n",
    "2. Build an `AdversarialTraining` object using this model, its normalizer, and the same experiment name, architecture name \n",
    "3. Build a loss function, attack_parameters object, and all other identical kwargs from the first (aborted) training run \n",
    "4. Run the training using the training object's `train_from_checkpoint` method instead of `train`. All the kwargs are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20, return_normalizer=True)\n",
    "new_train_obj = advtrain.AdversarialTraining(naive_model, normalizer, experiment_name, architecture)\n",
    "\n",
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              {'lp_style': 'inf', \n",
    "                               'lp_bound': 8.0 / 255})\n",
    "attack_loss = plf.VanillaXentropy(naive_model, normalizer)\n",
    "attack_object = aa.FGSM(naive_model, normalizer, delta_threat, attack_loss)\n",
    "attack_kwargs = {'verbose': False} # kwargs to be called in attack_object.attack(...)\n",
    "attack_params = advtrain.AdversarialAttackParameters(attack_object, proportion_attacked=0.2, \n",
    "                                                     attack_specific_params={'attack_kwargs': attack_kwargs})\n",
    "\n",
    "new_train_obj.train_from_checkpoint(cifar_trainset, 4, train_loss, attack_parameters=attack_params, \n",
    "                                    verbosity='high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this finishes, notice that you should now have a file \n",
    "`tutorial_fgsm.resnet20.000004.path.tar` in your pretrained_models directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the training script \n",
    "Using an ipython notebook isn't typically ideal for training, since it mandates you keep your browser window open. To this end, we've built a script to perform adversarial training in a tmux/screen background. This is located in `scripts/advtrain.py`. Here's what we've found are best practices for doing this:\n",
    "\n",
    "- Copy `scripts/advtrain.py` into `scripts/advtrain_<DESCRIPTIVE_EXPERIMENT_NAME>.py`\n",
    "- Modify the `build_attack_params` method in `scripts/advtrain_<DESCRIPTIVE_EXPERIMENT_NAME>.py` to use the attack parameters that you want. There's plenty of prebuilt attack parameters in that file to choose from. \n",
    "- In a tmux/screen, from `mister_ed`, run \n",
    "\n",
    "```python -m scripts.advtrain_DESCRIPTIVE_EXPERIMENT_NAME --exp <DESCRIPTIVE_EXPERIMENT_NAME> --arch <ARCHITECTURE_CHOICE> --verbosity [snoop/high/medium]```\n",
    "\n",
    "- To resume, you can optionally add the `-r` or `--resume` flag to the script call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note on GPU Usage\n",
    "If you have access to a GPU on your machine, you'll probably want to leverage its power when doing training and attacks. `mister_ed` has been designed so \"standard\" GPU behavior should be supported without any extra effort. By \"standard\" GPU behavior, I mean that all objects reside on the same device: either all on the GPU or none on the GPU. If there is a GPU on your machine, which one can check from the output of \n",
    "```\n",
    "import torch.cuda as cuda \n",
    "print(cuda.is_available()) \n",
    "```\n",
    "Globally, unless otherwise specified, all objects will be initialized in GPU-mode if this output is `True`. This is done behind-the-scenes by setting the environment variable `MISTER_ED_GPU`. If you have access to a GPU, but wouldn't like to use it, you can manually override this environment variable by calling:\n",
    "```\n",
    "import utils.pytorch_utils as utils \n",
    "utils.set_global_gpu(False)\n",
    "```\n",
    "And then none of your objects will be in GPU-mode by default. \n",
    "\n",
    "For nonstandard GPU behavior, you should initialize any object that differs from the default gpu status (as defined by `MISTER_ED_GPU`) with the kwarg `manual_gpu=<True/False>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
