{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "BATCH NUMBER: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type Variable[torch.FloatTensor] but found type Variable[torch.cuda.FloatTensor] for argument #1 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3a6df9213f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#   BREAK THE PLANET BLOCK                                               #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m##########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mmemout_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"SOMEHOW THIS WORKED??\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3a6df9213f08>\u001b[0m in \u001b[0;36mmemout_example\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         adv_images = pgd_attack_obj.attack(batch, labels, l_inf_bound =8.0/255.0, \n\u001b[0;32m---> 58\u001b[0;31m                                            step_size=1.0/255.0, num_iterations=16, verbose=False)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# push things to cpu (in hopes it gets them out of the cache)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mjordan/git_repos/mister_ed/adversarial_attacks.pyc\u001b[0m in \u001b[0;36mattack\u001b[0;34m(self, examples, labels, l_inf_bound, step_size, num_iterations, random_init, signed, verbose)\u001b[0m\n\u001b[1;32m    399\u001b[0m             var_examples = self._do_iteration(var_examples, var_labels, signed,\n\u001b[1;32m    400\u001b[0m                                               \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_inf_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                                               reference_var)\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mjordan/git_repos/mister_ed/adversarial_attacks.pyc\u001b[0m in \u001b[0;36m_do_iteration\u001b[0;34m(self, intermed_images, var_labels, signed, step_size, l_inf_bound, reference_var)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lpips_reg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_im\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mintermed_images\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermed_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mjordan/git_repos/mister_ed/loss_functions.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, examples, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# assert scalar is either a...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mjordan/git_repos/mister_ed/loss_functions.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, examples, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mxform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         perceptual_loss = self.dist_model.forward_var(examples,\n\u001b[0;32m--> 250\u001b[0;31m                                                       self.fix_im)\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mperceptual_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mjordan/git_repos/mister_ed/custom_lpips/custom_dist_model.pyc\u001b[0m in \u001b[0;36mforward_var\u001b[0;34m(self, input_0, input_1)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# input_0 and input_1 are both NxCxHxW VARIABLES!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mjordan/git_repos/mister_ed/custom_lpips/custom_dist_model.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in0, in1)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0min0_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0min1_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0min1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type Variable[torch.FloatTensor] but found type Variable[torch.cuda.FloatTensor] for argument #1 'other'"
     ]
    }
   ],
   "source": [
    "# Self contained memout assertion \n",
    "\n",
    "##########################################################################\n",
    "#   IMPORT BLOCK                                                         #\n",
    "##########################################################################\n",
    "import gc \n",
    "import os\n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import config\n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_attacks as aa\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import checkpoints\n",
    "\n",
    "##########################################################################\n",
    "#   FUNCTION BLOCK                                                       #\n",
    "##########################################################################\n",
    "def memout_example():    \n",
    "    assert vars() == {}\n",
    "    # empty slate \n",
    "\n",
    "    # build persistent data \n",
    "    val_loader = cifar_loader.load_cifar_data('val', normalize=False, batch_size=16, use_gpu=False)\n",
    "    \n",
    "    # now loop through batches and show that there's something hanging somewhere...\n",
    "    for batch_no, (batch, labels) in enumerate(val_loader):\n",
    "        \n",
    "        # clean up garbage and clear cuda cache as much as possible \n",
    "        gc.collect()\n",
    "        print \"BATCH NUMBER: %s\" % batch_no\n",
    "        assert sorted(vars().keys()) == sorted(['labels', 'val_loader', 'batch', 'batch_no'])\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        # load things needed for attack \n",
    "        base_model = cifar_resnets.resnet32()\n",
    "        adv_trained_net = checkpoints.load_state_dict_from_filename('half_trained_madry.th', base_model)\n",
    "        #adv_trained_net.cuda()\n",
    "        cifar_normer = utils.DifferentiableNormalize(mean=config.CIFAR10_MEANS,\n",
    "                                           std=config.CIFAR10_STDS)        \n",
    "        pgd_perceptual_loss = plf.PerceptualXentropy(adv_trained_net, normalizer=cifar_normer, use_gpu=True)            \n",
    "        pgd_attack_obj = aa.LInfPGD(adv_trained_net, cifar_normer, pgd_perceptual_loss)\n",
    "        \n",
    "        adv_images = pgd_attack_obj.attack(batch, labels, l_inf_bound =8.0/255.0, \n",
    "                                           step_size=1.0/255.0, num_iterations=16, verbose=False)\n",
    "        \n",
    "        # push things to cpu (in hopes it gets them out of the cache)\n",
    "        # also delete everything and be sure to collect garbage before next batch \n",
    "        batch.cpu()\n",
    "        labels.cpu()\n",
    "        del adv_images\n",
    "        del batch \n",
    "        del labels \n",
    "        del pgd_attack_obj \n",
    "        del pgd_perceptual_loss\n",
    "        del cifar_normer\n",
    "        adv_trained_net.cpu()\n",
    "        del adv_trained_net \n",
    "        del base_model \n",
    "    return\n",
    "    \n",
    "    \n",
    "##########################################################################\n",
    "#   BREAK THE PLANET BLOCK                                               #\n",
    "##########################################################################\n",
    "print memout_example()\n",
    "print \"SOMEHOW THIS WORKED??\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
